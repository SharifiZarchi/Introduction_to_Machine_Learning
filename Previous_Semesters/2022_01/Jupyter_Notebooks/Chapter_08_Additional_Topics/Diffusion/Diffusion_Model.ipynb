{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzleJf0VYQiu"
   },
   "source": [
    "<font face=\"XB Zar\" size=5><div dir=rtl align=center>\n",
    "<font face=\"IranNastaliq\" size=5>\n",
    "به نام خدا\n",
    "</font>\n",
    "<br>\n",
    "<font size=3>\n",
    "دانشگاه صنعتی شریف - دانشکده مهندسی کامپیوتر\n",
    "</font>\n",
    "<br>\n",
    "<font color=blue size=5>\n",
    "مقدمه‌ای بر یادگیری ماشین\n",
    "</font>\n",
    "<br>\n",
    "<hr/>\n",
    "<font color=red size=6>\n",
    "فصل هشتم: مدل‌های انتشاری </font>\n",
    "<br>\n",
    "نویسنده:‌ علی حاتمی تاجیک\n",
    "<hr>\n",
    "</div></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure id=\"fig1\">\n",
    "  <img style=\"display: block;margin-left: auto;margin-right: auto;width: 70%;\" src=\"https://cvpr2022-tutorial-diffusion-models.github.io/img/diffusion.png\">\n",
    "    <figcaption style=\"text-align: center\">شکل ۱: فرآیند کار مدل‌های انتشاری (<a href=\"https://cvpr2022-tutorial-diffusion-models.github.io\">منبع</a>)</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl",
    "id": "MzNxbmAZDhQz"
   },
   "source": [
    "# ۱. مقدمه\n",
    "\n",
    "تا کنون در درس درباره مدل‌های مولد VAE و GAN یاد‌گرفته‌اید. هرکدام از این مدل‌ها موفقیت‌های بزرگی بوده‌اند اما هرکدام محدودیت‌هایی دارند. برای مثال مدل‌های GAN به خاطر ذات متخاصمانه خود در فرآیند یادگیری ناپایدار هستند. \n",
    "\n",
    "در این نوت‌بوک راجع به **DDPM** ها یا مدل‌های Denoising Diffusion Probabilistic Models (یا به طور خلاصه مدل‌های Diffusion) خواهیم نوشت. این مدل‌ها نوع دیگری از مدل‌های مولد (Generative) هستند که به تازگی (در سال ۲۰۱۵) معرفی شده‌اند. از مدل‌های معروفی که بر این پایه تولید شده‌اند می‌توان به [DALL-E 2](https://openai.com/dall-e-2/) توسط OpenAI و [ImageGen](https://imagen.research.google/) توسط Google Brain اشاره کرد. در ادامه به مقاله اصلی ([Ho et al., 2020](https://arxiv.org/abs/2006.11239))، اصول آن و پیاده‌سازی ساده‌ای از آن در PyTorch خواهیم پرداخت. (*دقت کنید که چندین دیدگاه در مورد مدل‌های دیفیوژن وجود دارد که در اینجا به مدل زمان‌ناپیوسته (discrete-time) می‌پردازیم*).\n",
    "\n",
    "ایده اصلی که این مدل‌ها برپایه آن بنا شده‌اند این است که در طی چندین مرحله به تصویر نویز اضافه می‌کنند (مانند انتشار دادن مواد شیمیایی به یک سطح) و اگر میزان این نویز مقدار کمی باشد، می‌توان به صورت تقریبی مدل را یک مدل مارکوف در نظر گرفت که وضعیت فعلی آن تنها به وضعیت قبلی آن مرتبط است. ما به دنبال این هستیم تا مدلی عمیق بسازیم تا یاد بگیرد فرایند عکس کردن نویز را یاد بگیرد و با استفاده از وضعیت فعلی، وضعیت قبلی را بسازد (<a href=\"#fig1\">شکل ۱</a>). برخلاف مدل VAE، مدل انتشاری متغیر‌های پنهانی با سایز ورودی اصلی را می‌سازد و یاد می‌گیرد (<a href=\"#fig2\">شکل ۲</a>).\n",
    "\n",
    "<figure id=\"fig2\">\n",
    "  <img style=\"display: block;margin-left: auto;margin-right: auto;width: 70%;\" src=\"./graphics/generative-overview.png\" >\n",
    "    <figcaption style=\"text-align: center\">شکل ۲: تفاوت مدل‌های انتشاری با مدل‌های VAE و GAN (<a href=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\">منبع</a>)</figcaption>\n",
    "</figure>\n",
    "\n",
    "پس از اینکه این پروسه نویز‌زدایی (رسیدن از نویز به دیتای ورودی) را یاد گرفتیم، با ورودی دادن یک نمونه تصادفی از نویز به مدل نویز‌زدا می‌توانیم دیتای جدید تولید کنیم.\n",
    "\n",
    "به طور دقیق‌تر، مدل‌های انتشاری مدل‌هایی با لایه میانی (Latent Variable) هستند که به وسیله یک زنجیره مارکوف **ثابت** فضای ورودی را به فضای میانی (Latent Space) متصل می‌کند (<a href=\"#fig3\">شکل ۳</a>) \n",
    "\n",
    "<figure id=\"fig3\">\n",
    "  <img src=\"./graphics/x-to-noise.png\" style=\"display: block;margin-left: auto;margin-right: auto;width: 70%;\">\n",
    "    <figcaption style=\"text-align: center\">شکل ۳: فرآیند Forward (<a href=\"https://arxiv.org/pdf/2006.11239.pdf\">منبع</a>)</figcaption>\n",
    "</figure>\n",
    "\n",
    "در نهایت مدل با استفاده از در‌ نظر گرفتن این نکته که هر لایه میانی به صورت مجانبی لایه قبلی است ([تحلیل مجانبی](https://fa.wikipedia.org/wiki/%D8%AA%D8%AD%D9%84%DB%8C%D9%84_%D9%85%D8%AC%D8%A7%D9%86%D8%A8%DB%8C) یا Asymptotic analysis) به صورت تدریجی می‌توان ورودی را از روی خروجی ساخت (<a href=\"#fig4\">شکل ۴</a>). هدف از فرآیند یادگیری، یادگرفتن نحوه بازگشت به صورت مجانبی است یا به عبارتی یادگرفتن تابع $p_{\\theta}(x_{t-1}\\mid x_t)$ است.\n",
    "\n",
    "\n",
    "<figure id=\"fig4\">\n",
    "  <img src=\"./graphics/noise-to-x.png\" style=\"display: block;margin-left: auto;margin-right: auto;width: 70%;\">\n",
    "    <figcaption style=\"text-align: center\">شکل ۴: فرآیند Revers (<a href=\"https://arxiv.org/pdf/2006.11239.pdf\">منبع</a>)</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۱.۱. زنجیره مارکوف (Markov Chain)\n",
    "\n",
    "«زنجیره مارکوف» (Markov Chain) یا «فرآیند مارکوف» (Markov Process)، مدلی برای نمایش دنباله‌ای از متغیرهای تصادفی است که در آن احتمال رویداد هر پیشامد فقط به پیشامد قبلی وابسته است. به این ترتیب احتمال رخداد پیشامدها در چنین مدلی فقط به زمان قبل وابسته بوده و بقیه پیشامدها در میزان احتمال دخالت نمی‌کنند. چنین وضعیتی را برای فرایند تصادفی گاهی خاصیت «عدم حافظه» (Memoryless) نیز می‌نامند. با فرض مارکوف بودن مدل احتمالاتی می‌توان از پیچیدگی‌های آن کاست. در رابطه زیر $X_i$ را متغیر تصادفی در لحظه $i$ فرض کنید:\n",
    "\n",
    "$$\\large \\Pr(X_{t+1}=x\\mid X_{1}=x_{1},X_{2}=x_{2},\\ldots ,X_{n}=x_{t})=\\Pr(X_{t+1}=x\\mid X_{t}=x_{t})$$\n",
    "\n",
    "در عبارت بالا ما این فرض را داریم که مقدار متغیر تصادفی $X_{t+1}$ تنها به وضعیت قبلی سیستم ($X_{t}$) است."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "# ۲. چگونگی کار مدل"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۱.۲. پروسه Forward \n",
    "\n",
    "\n",
    "همانطور که پیش‌تر گفت شد، در فرایند Forward ما به صورت تدریجی نویزی به ورودی (که معمولا تصویر است) وارد می‌کنیم. در ابتدای کار ما یک نقطه (یک تصویر) از توزیع داده اصلی (تصاویر اصلی) نمونه‌گیری می‌کنیم: $x_0\\sim q(x)$. سپس با استفاده از زنجیره‌ای که تعریف می‌کنیم و اضافه کردن مقدار کمی نویز\n",
    "<a href=\"https://en.wikipedia.org/wiki/Multivariate_normal_distribution\">گاوسی</a> در $T$ قدم زمانی یک دنباله از نمونه‌های نویزی شده تولید می‌کنیم. اندازه این قدم‌های زمانی توسط برنامه واریانس $\\{\\beta_t \\in (0, 1)\\}_{t=1}^T$ کنترل می‌شود:\n",
    "\n",
    "$$q(\\mathbf{x}_t \\vert \\mathbf{x}_{t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}, \\beta_t\\mathbf{I}) \\quad\n",
    "q(\\mathbf{x}_{1:T} \\vert \\mathbf{x}_0) = \\prod^T_{t=1} q(\\mathbf{x}_t \\vert \\mathbf{x}_{t-1})$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "<details><summary><u>جزئیات ریاضی «اضافه شدن» نویز</u></summary>\n",
    "\n",
    "   در فرآیند Forward از اضافه شدن نویز به نمونه‌ها صحبت می‌کنیم اما چنین چیزی در رابطه‌ای که نوشته شده است عملیات جمعی نمی‌بینیم! در ادامه جزئیات ریاضی که منجر به نتیجه مطلوب می‌شود شرح داده‌شده است. در ابتدا توجه داشته باشید که:\n",
    "   \n",
    "   $$\\mathcal{N}(x;\\mu, \\sigma)=\\frac{1}{\\sigma \\sqrt{2 \\pi}}\\exp(-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2)$$\n",
    "    \n",
    "   حال با استفاده از قانون احتمال کل خواهیم داشت:\n",
    "   \n",
    "$$p_{X_t}=\\int p(x_t \\mid x_{t-1})p(x_{t-1})dx_{t-1}$$\n",
    "    \n",
    "   با جایگزین کردن توزیع گاوسی داریم:\n",
    "    \n",
    "   $$p_{X_t}=\\int \\mathcal{N}(x_t;x_{t-1}, 1) p(x_{t-1})dx_{t-1} = \\int \\mathcal{N}(x_t - x_{t-1};0, 1) p(x_{t-1})dx_{t-1}$$ \n",
    "   \n",
    "   که با قدری دقت متوجه خواهید شد که این همان <a href=\"https://en.wikipedia.org/wiki/Convolution\">کانوولوشن</a> است:\n",
    "   \n",
    "   $$p_{X_t}=(N(0,1)*p(x_{t-1}))(x_t)$$\n",
    "    \n",
    "   که طبق <a href=\"https://en.wikipedia.org/wiki/Convolution_of_probability_distributions\">کانوولوشن توزیع‌های احتمالاتی</a> برابر خواهد بود با:\n",
    "    \n",
    "   $$X_t = \\mathcal{N}(0,1) + X_{t-1}$$  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "زمانی که $T$ به اندازه کافی بزرگ باشد (در عمل معمولا ۱۰۰) $x_T$ به صورت یکنواخت نویز گاوسی است. معمولا برنامه واریانس، بر خلاف این نکته که می‌توانند یاگرفته‌شوند، مقادیر ثابت و مستقل از زمانی گرفته می‌شوند. یک راه برای انتخاب مقدار آنها، انتخاب خطی آنها بین $\\beta_0 = 10^{-4}, \\beta_T = 0.2$ است."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۲.۲. پروسه Revese\n",
    "\n",
    "برای بدست آوردن توزیع $q(x_{t-1}\\mid x_t)$ و تخمین زدن آن باید روی کل دیتاست عملیات انجام بدهیم که کار ساده‌ای نخواهد بود به همین دلیل ما مدل $p_\\theta$ را یاد می‌گیریم تا این تابع احتمال را تقریب بزنیم.\n",
    "\n",
    "$$p_\\theta(\\mathbf{x}_{0:T}) = p(\\mathbf{x}_T) \\prod^T_{t=1} p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) \\quad\n",
    "p_\\theta(\\mathbf{x}_{t-1} \\vert \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}_\\theta(\\mathbf{x}_t, t), \\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t))$$\n",
    "\n",
    "که در آن مدل یاد می‌گیرد تا پارامترهای مستقل از زمان آن یادگرفته خواهند شد.\n",
    "\n",
    "\n",
    "<figure id=\"fig5\">\n",
    "  <img src=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/diffusion-example.png\" style=\"display: block;margin-left: auto;margin-right: auto;width: 70%;\">\n",
    "    <figcaption style=\"text-align: center\">شکل ۵: فرآیند Forward و Revers روی دیتای ساده عددی (رول سوئیسی) (<a href=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models\">منبع</a>)</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۳.۲. Objective و تابع Loss\n",
    "\n",
    "مدل ما سعی می‌کند تا انتقال معکوس زنجیره مارکوف را به گونه‌ای یاد بگیرد تا امید‌ریاضی دیتای ورودی بیشینه شود. در عمل، یادگیری برای کمینه کردن <a href=\"https://arxiv.org/pdf/1611.00328.pdf\">حد پایین واریانس</a> منفی امید‌ریاضی خواهد بود:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "L_\\text{VLB} \n",
    "&:= \\mathbb{E}_{q(\\mathbf{x}_{0:T})} \\Big[ \\log \\frac{q(\\mathbf{x}_{1:T}\\vert\\mathbf{x}_0)}{p_\\theta(\\mathbf{x}_{0:T})} \\Big] \\geq - \\mathbb{E}_{q(\\mathbf{x}_0)} \\log p_\\theta(\\mathbf{x}_0)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "به دلیل اینکه توزیع گاوسی در KL Divergence دارای فرم بسته است، می‌خواهیم تا $L_{VLB}$ را به این صورت بنویسیم. تبدیل شده آن به صورت زیر خواهد بود (جزئیات ریاضی را می‌توانید <a href=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#reverse-diffusion-process\">اینجا</a> ببینید):\n",
    "\n",
    "$$\\begin{aligned}\n",
    "L_\\text{VLB} &= L_T + L_{T-1} + \\dots + L_0 \\\\\n",
    "\\text{where } L_T &= D_\\text{KL}(q(\\mathbf{x}_T \\vert \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_T)) \\\\\n",
    "L_t &= D_\\text{KL}(q(\\mathbf{x}_t \\vert \\mathbf{x}_{t+1}, \\mathbf{x}_0) \\parallel p_\\theta(\\mathbf{x}_t \\vert\\mathbf{x}_{t+1})) \\text{ for }1 \\leq t \\leq T-1 \\\\\n",
    "L_0 &= - \\log p_\\theta(\\mathbf{x}_0 \\vert \\mathbf{x}_1)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "همانطور که قبل‌تر اشاره شد برنامه واریانس به صورت ثابت انتخاب می‌شود، به همین دلیل مدل ما تنها میانگین را از هر مرحله به مرحله بعد یاد‌خواهد گرفت. در نظر بگیرید که $\\alpha_t = 1 - \\beta_t$ و $\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i$. در [Ho et al., 2020](https://arxiv.org/abs/2006.11239) به عبارت Loss پارامتری شده و ساده‌شده‌ای رسیده‌اند که \n",
    "\n",
    "$$\\begin{aligned}\n",
    "L_t^\\text{simple}\n",
    "&= \\mathbb{E}_{t \\sim [1, T], \\mathbf{x}_0, \\boldsymbol{\\epsilon}_t} \\Big[\\|\\boldsymbol{\\epsilon}_t - \\boldsymbol{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\|^2 \\Big] \\\\\n",
    "&= \\mathbb{E}_{t \\sim [1, T], \\mathbf{x}_0, \\boldsymbol{\\epsilon}_t} \\Big[\\|\\boldsymbol{\\epsilon}_t - \\boldsymbol{\\epsilon}_\\theta(\\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\boldsymbol{\\epsilon}_t, t)\\|^2 \\Big]\n",
    "\\end{aligned}$$\n",
    "\n",
    "در نهایت الگوریتم یادگیری و نمونه‌گیری خواهند بود:\n",
    "\n",
    "<figure id=\"fig6\">\n",
    "  <img src=\"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/DDPM-algo.png\" style=\"display: block;margin-left: auto;margin-right: auto;width: 70%;\">\n",
    "    <figcaption style=\"text-align: center\">شکل ۶: الگوریتم‌ها (<a href=\"https://arxiv.org/abs/2006.11239\">منبع</a>)</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "# ۳. پیاده‌سازی\n",
    "\n",
    "در این بخش دو پیاده‌سازی برای مدل‌های دیفیوژن را ارائه خواهیم کرد. اولی روی دیتاست Swiss Roll است که برای آشنایی بیشتر شما با مفاهیم دیفیوژن است و دیگری یک پیاده‌سازی به وسیله دیتاست با داده واقعی‌تر (Fashion MNIST) و به وسیله معماری‌های پیچیده‌تر انجام می‌گیرد تا نمونه‌ای از این مدل را در عمل ببینید. قبل از شروع این پیاده‌سازی‌ها ابتدا توابعی پایه که برای پیاده‌سازی مدل‌های انتشاری استفاده می‌شوند را پیاده‌سازی می‌کنیم و سپس به آموزش مدل روی دیتاست‌های نام‌برده خواهیم پرداخت. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U einops tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda, ToPILImage, CenterCrop, Resize\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from unet import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۱.۳. توابع پایه\n",
    "\n",
    "اولین قدم، تخصیص مقادیر بتا و متغیر‌های وابسته به آن مانند آلفاست:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_beta_schedule(T):\n",
    "    \"\"\"Get Linear beta schedule for T time steps\n",
    "    \n",
    "    Args:\n",
    "        T: positive integer time steps\n",
    "        \n",
    "    Returns torch.tensor of T elements\n",
    "    \"\"\"\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 200\n",
    "\n",
    "# get the schedule\n",
    "betas = linear_beta_schedule(T)\n",
    "\n",
    "# alpha and alpha comprods\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "\n",
    "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(a, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = a.gather(-1, t.cpu())\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "همچنین فرآیند‌های نمونه‌برداری را می‌توان به صورت زیر انجام داد: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_sample(x_0, t, noise=None):\n",
    "    \"\"\"Sample X0 for forward deffusion (Algorithm 1, line 2)\"\"\"\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_0)\n",
    "\n",
    "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_0.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n",
    "    )\n",
    "    \n",
    "    return sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def p_sample(model, x, t, t_index):\n",
    "    \"\"\"Sampling (1 iteration in the Algorithm 2 lines 3 and 4)\n",
    "    \n",
    "    Note: This function is vectorized and do one itteration for\n",
    "          sample batch-size (i.e. shape[0] in `p_sample_loop`)\n",
    "    \"\"\"\n",
    "    betas_t = extract(betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
    "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
    "    \n",
    "    # Equation 11 in the paper\n",
    "    # Use our model (noise predictor) to predict the mean\n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "\n",
    "    if t_index == 0:\n",
    "        return model_mean\n",
    "    else:\n",
    "        posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
    "        noise = torch.randn_like(x)\n",
    "        # Algorithm 2 line 4:\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def p_sample_loop(model, shape):\n",
    "    \"\"\"Algorithm 2: Sampling (Vectorized for #shape[0] outputs)\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    b = shape[0]\n",
    "    # start from pure noise (for each example in the batch)\n",
    "    img = torch.randn(shape, device=device)\n",
    "    imgs = []\n",
    "    \n",
    "    for i in tqdm(reversed(range(0, T)), desc='sampling loop time step', total=T):\n",
    "        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
    "        imgs.append(img.cpu().numpy())\n",
    "    return imgs\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, image_size=28, batch_size=16, channels=1):\n",
    "    \"\"\"Wrapper for p_sample_loop\"\"\"\n",
    "    return p_sample_loop(model, shape=(batch_size, channels, image_size, image_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "و در نهایت می‌توانیم تابع هزینه (MSE) را پیاده‌سازی کنیم:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_loss(model, x_0, t, noise=None):\n",
    "    \"\"\"\n",
    "    MSE Loss of the noisy image at step t and the noise\n",
    "    \"\"\"\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_0)\n",
    "    \n",
    "    x_noisy = q_sample(x_0, t, noise)\n",
    "    predicted_noise = model(x_noisy, t)\n",
    "    \n",
    "    return  F.mse_loss(noise, predicted_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۲.۳. پیاده‌سازی PyTorch (داده Swiss Roll)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "پیش از شروع کار داده‌های رولت سوییسی (Swiss Roll) که یک دیتاست کلاسیک است را به تصویر می‌کشیم تا آشنایی بهتری با آن پیدا کنیم. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_size = 10_000\n",
    "roll_data, sr_color = make_swiss_roll(roll_size, noise=0.3)\n",
    "\n",
    "# Plot\n",
    "def plot_3d(data, color, title):\n",
    "    \"\"\"Plots 3d scatter of data\n",
    "    \n",
    "    Args:\n",
    "        data: 3 x N array-like\n",
    "        color: N x 1 array correspoding to each row of data\n",
    "        title: title of the chart\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    fig.add_axes(ax)\n",
    "    ax.scatter(\n",
    "        data[:, 0], data[:, 1], data[:, 2], c=color, s=50, alpha=0.8\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(azim=-66, elev=12)\n",
    "    \n",
    "plot_3d(roll_data, sr_color, \"Swiss Roll\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "حال نویزدار شده این داده را در قدم‌های مختلف زمانی را به نمایش درمی‌آوریم (در دو بعد):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_t = torch.tensor(roll_data).float()\n",
    "\n",
    "def plot_diffusion():\n",
    "    \"\"\"\n",
    "    This function plots diffusion proccess for the input data\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.2))\n",
    "    for i in range(20):\n",
    "        ax = fig.add_subplot(2, 10, i+1)\n",
    "        q_i = q_sample(roll_t, torch.tensor([i * 10]))\n",
    "        ax.scatter(q_i[:, 0], q_i[:,2], s=10);\n",
    "        ax.set_axis_off(); ax.set_title('$q(\\mathbf{x}_{'+str(i*10)+'})$')\n",
    "\n",
    "plot_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "حال یک شبکه عصبی برای یادگرفتن فرآیند بازگشت از نویز به دیتای اصلی می‌سازیم: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, num_in, num_out, T):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.lin = nn.Linear(num_in, num_out)\n",
    "        self.embed = nn.Embedding(T, num_out)\n",
    "        self.embed.weight.data.uniform_()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.lin(x)\n",
    "        gamma = self.embed(y)\n",
    "        out = gamma.view(-1, self.num_out) * out\n",
    "        return out\n",
    "    \n",
    "class ConditionalModel(nn.Module):\n",
    "    def __init__(self, T):\n",
    "        super(ConditionalModel, self).__init__()\n",
    "        self.lin1 = ConditionalLinear(3, 128, T)\n",
    "        self.lin2 = ConditionalLinear(128, 128, T)\n",
    "        self.lin3 = nn.Linear(128, 3)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = F.softplus(self.lin1(x, y))\n",
    "        x = F.softplus(self.lin2(x, y))\n",
    "        return self.lin3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA():\n",
    "    \"\"\"Exponential Moving Average\n",
    "    \n",
    "    This idea is found in most of the implementations, which allows to implement a form \n",
    "    of model momentum. Instead of directly updating the weights of the model, we keep a\n",
    "    copy of the previous values of the weights, and then update a weighted mean between\n",
    "    the previous and new version of the weights.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu=0.999):\n",
    "        self.mu = mu\n",
    "        self.shadow = {}\n",
    "\n",
    "    def register(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name].data = (1. - self.mu) * param.data + self.mu * self.shadow[name].data\n",
    "\n",
    "    def ema(self, module):\n",
    "        for name, param in module.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data.copy_(self.shadow[name].data)\n",
    "\n",
    "    def ema_copy(self, module):\n",
    "        module_copy = type(module)(module.config).to(module.config.device)\n",
    "        module_copy.load_state_dict(module.state_dict())\n",
    "        self.ema(module_copy)\n",
    "        return module_copy\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.shadow\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.shadow = state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalModel(T).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Create EMA model\n",
    "ema = EMA(0.9)\n",
    "ema.register(model)\n",
    "# Batch size\n",
    "batch_size = 100\n",
    "for step in range(2001):\n",
    "    # X is a torch Variable\n",
    "    permutation = torch.randperm(roll_t.size()[0])\n",
    "    for i in range(0, roll_t.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        # Retrieve current batch\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x = roll_t[indices].to(device)\n",
    "        \n",
    "        # Algorithm 1 line 3: sample t uniformally for every example in the batch\n",
    "        t = torch.randint(0, T, (batch_size,), device=device).long()\n",
    "            \n",
    "        # Compute the loss.\n",
    "        loss = f_loss(model, batch_x, t)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Perform gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "        \n",
    "        # Calling the step function to update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the exponential moving average\n",
    "        ema.update(model)\n",
    "    \n",
    "    # Print loss\n",
    "    if (step % 200 == 0):\n",
    "        print(loss)\n",
    "        x_seq = p_sample_loop(model, roll_t.shape)\n",
    "        fig, axs = plt.subplots(1, 19, figsize=(28, 3))\n",
    "        for i in range(1, 20):\n",
    "            cur_x = x_seq[i * 10]\n",
    "            axs[i-1].scatter(cur_x[:, 0], cur_x[:, 2], s=10);\n",
    "            #axs[i-1].set_axis_off(); \n",
    "            axs[i-1].set_title('$q(\\mathbf{x}_{'+str(i*10)+'})$')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۳.۳. پیاده‌سازی PyTorch (داده واقعی)\n",
    "\n",
    "در این بخش یک مدل دیفیوژن با استفاده از شبکه‌های عمیق کانولوشنال خواهیم ساخت.\n",
    "\n",
    "برای یادگرفتن فرآیند بازگشت، به خاطر پیچید بودن این فرآیند، از شبکه‌های عصبی استفاده می‌کنیم. می‌خواهیم از تصویر نویز‌دار ورودی نویز آن را پیش‌بینی کنیم (که ابعاد هر دو یکسان است). معماری که در ابتدا به ذهن می‌رسد معماری Autoencoderهاست. در [[Ho et al., 2020](https://arxiv.org/abs/2006.11239)] نویسندگان از معماری مشابه UNet ([Ronneberger et al., 2015](https://arxiv.org/abs/1505.04597)) بر پایه CNNها استفاده کرده‌اند (<a href=\"#fig7\">شکل ۴</a>)\n",
    "\n",
    "<figure id=\"fig7\">\n",
    "  <img src=\"https://amaarora.github.io/images/unet.png\" style=\"display: block;margin-left: auto;margin-right: auto;width: 70%;\">\n",
    "    <figcaption style=\"text-align: center\">شکل ۷: UNet (<a href=\"https://amaarora.github.io/2020/09/13/unet.html\">منبع</a>)</figcaption>\n",
    "</figure>\n",
    "\n",
    "به خاطر برخی پیچیدگی‌های خارج از مبحث این مدل، مانند لایه‌های Residual و Attention، این مدل شبکه عصبی در فایل `unet.py` آماده شده است، اما شما می‌توانید مراحل پیاده‌سازی آن را در <a href=\"https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/annotated_diffusion.ipynb#scrollTo=5153024b\">این نوت‌بوک فوق‌العاده</a> ببینید (کدهای این نوت‌بوک ساده‌سازی‌شده کد‌های مرجع ذکرشده است). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۱.۳. فرآیند Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "فرآیند اضافه شدن نویز به تصاویر را دنبال می‌کنیم:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ducky = Image.open(\"./graphics/duck.jpg\")\n",
    "ducky"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "دقت کنید که نویز به وسیله PyTorch اضافه می‌شود به همین خاطر قبل از آن باید عکس‌های PIL را به تنسور تبدیل کنیم. در مقاله DDPM پیکسل‌های تصویر به مقادیر بین -۱ تا ۱ اسکیل شده‌اند:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We assume that image data consists of integers in $\\{0, 1, ... , 255\\}$ scaled linearly to $[−1, 1]$. This\n",
    "ensures that the neural network reverse process operates on consistently scaled inputs starting from\n",
    "the standard normal prior $p(\\mathbf{x}_T )$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "\n",
    "trans = Compose([\n",
    "    Resize(image_size),\n",
    "    CenterCrop(image_size),\n",
    "    ToTensor(),\n",
    "    Lambda(lambda t: t * 2 - 1)\n",
    "])\n",
    "\n",
    "rev_trans = Compose([\n",
    "     Lambda(lambda t: (t + 1) / 2),\n",
    "     Lambda(lambda t: t.permute(1, 2, 0)),\n",
    "     Lambda(lambda t: t * 255.),\n",
    "     Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "     ToPILImage(),\n",
    "])\n",
    "\n",
    "rev_trans(trans(ducky))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_image(x_0, t):\n",
    "    # add noise\n",
    "    x_noisy = q_sample(x_0, t=t)\n",
    "\n",
    "    # turn back into PIL image\n",
    "    noisy_image = rev_trans(x_noisy.squeeze())\n",
    "\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = trans(ducky).unsqueeze(0)\n",
    "# take 40 time steps\n",
    "t = torch.tensor([40])\n",
    "get_noisy_image(x_0, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use seed for reproducability\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def plot(imgs, with_orig=False, row_title=None, **imshow_kwargs):\n",
    "    \"\"\"Plot sequence images in rows\n",
    "    \n",
    "    Source: https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
    "    \"\"\"\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(figsize=(200,200), nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [image] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "حال یک دنباله از تصاویر نویزدار شده در چند بخش را نمایش می‌دهیم تا با نویزی شدن تصاویر بیشتر آشنا شوید:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([get_noisy_image(x_0, torch.tensor([t])) for t in [0, 40, 50, 80, 99]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۲.۳. دیتاست\n",
    "\n",
    "دیتاست Fashion MNIST برای یادگیری انتخاب شده است اما می‌توانید از دیتاست‌های دیگری مانند CIFAR10 استفاده کنید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "])\n",
    "\n",
    "mnist = datasets.FashionMNIST('./data', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "loader = DataLoader(mnist, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۳.۳. نمونه‌گیری"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۴.۳. یادگیری (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(dim=28, channels=1, dim_mults=(1, 2, 4, )).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "epochs = 50 # ~ 5 Hours\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(enumerate(loader), total=len(loader)) as pbar:\n",
    "        for step, (images, _) in pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_size = len(images)\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Algorithm 1 line 3: sample t uniformally for every example in the batch\n",
    "            t = torch.randint(0, T, (batch_size,), device=device).long()\n",
    "\n",
    "            loss = f_loss(model, images, t)\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                pbar.set_description(f'Train {epoch} | Loss:{loss.item():.4f}')\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "## ۵.۳. استنتاج (نمونه گیری)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating 32 images and plot 7th image\n",
    "samples = sample(model, image_size=28, batch_size=32, channels=1)\n",
    "plt.imshow(samples[-1][8].reshape(28, 28, 1), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "نتیجه تولید شده که چیزی شبیه به یک پیراهن است :) همانطور که می‌بینید برای اینکه مدل‌های انتشاری روی داده‌های پیچیده‌تر نتایج مطلوبی داشته باشند تعداد epoch کم جوابگو نخواهد بود و برای مدت طولانی باید پروسه یادگیری را طی کنند ($epoch\\sim 1000$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "# ۴. منابع و مراجع\n",
    "\n",
    "منابعی که برای نوشته‌شدن این نوت‌بوک به کار گرفته شده است: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Ho et al., 2020](https://arxiv.org/abs/2006.11239) \n",
    "* [CVPR 2022](https://cvpr2022-tutorial-diffusion-models.github.io/): CVPR 2022 یکی از بهترین منابع برای یادگیری و آشنایی با مدل‌های انتشاری است. [دکتر آرش وحدت](http://latentspace.cc/) (محقق Nvidia) یکی از ارائه دهندگان این آموزش هستند. اسلاید‌های فوق‌العاده این ارائه‌ها را می‌توانید از [این لینک](https://drive.google.com/file/d/1DYHDbt1tSl9oqm3O333biRYzSCOtdtmn/view?usp=sharing) دانلود کنید.\n",
    "* [What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/) \n",
    "* [Introduction to Diffusion Models for Machine Learning](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/) \n",
    "* [An introduction to Diffusion Probabilistic Models](https://ayandas.me/blog-tut/2021/12/04/diffusion-prob-models.html) \n",
    "* [U-Net: A PyTorch Implementation in 60 lines of Code](https://amaarora.github.io/2020/09/13/unet.html) \n",
    "* [The Annotated Diffusion Model](https://huggingface.co/blog/annotated-diffusion) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "# ۵. منابع مفید برای مطالعه بیشتر\n",
    "\n",
    "برای آشنایی عمیق‌تر و با جزئیات بیشتر می‌توانید به مقاله [What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/) و [An introduction to Diffusion Probabilistic Models](https://ayandas.me/blog-tut/2021/12/04/diffusion-prob-models.html) مراجعه کنید. همچنین اگر می‌خواهید یک مدل متن به تصویر (چیزی شبیه به ImageGen) بسازید می‌تواند یک آموزش قدم-به-قدم را در مقاله [MinImageGen](https://www.assemblyai.com/blog/minimagen-build-your-own-imagen-text-to-image-model/) دنبال کنید. همچنین مخزن گیت‌هاب [Awesome Diffusion Model](https://github.com/heejkoo/Awesome-Diffusion-Models) مقالات، پست‌ها، ویدئو‌ها و ... مرتبط با این موضوع را به صورت دسته‌بندی شده جمع‌آوری می‌کند که می‌توانید از مراجع معرفی شده در آن استفاده کنید."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
