{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNx2ze3Cfuh5"
   },
   "source": [
    "<div dir=\"rtl\" align=\"center\">\n",
    "<font face=\"XB Zar\" size=5>\n",
    "    <font face=\"IranNastaliq\" size=5>\n",
    "      به نام خدا\n",
    "    </font>\n",
    "    <br>\n",
    "    <font size=3>\n",
    "      دانشگاه صنعتی شریف - دانشکده مهندسی کامپیوتر\n",
    "    </font>\n",
    "    <br>\n",
    "    <font color=blue size=5>\n",
    "      مقدمه‌ای بر یادگیری ماشین\n",
    "    </font>\n",
    "    <br>\n",
    "    <hr/>\n",
    "    <font color=red size=6>\n",
    "      فصل هفتم: Encoder, Decoder\n",
    "    </font>\n",
    "    <br>\n",
    "       نویسندگان:‌ علیرضا دهقانپور فراشاه، مهدی سلمانی\n",
    "    <hr>\n",
    "<br>\n",
    "  <div align=\"right\">\n",
    "  <font color=\"red\" size=5>فهرست مطالب</font>\n",
    "\t<ul>\n",
    "    <li>\n",
    "        <a href='#intro'>\n",
    "        مقدمه\n",
    "    </a>\n",
    "\t\t</li>\n",
    "\t\t<li>\n",
    "      <a href=\"#model\">\n",
    "       آشنایی با مدل\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#training\">\n",
    "       آموزش مدل\n",
    "      </a>\n",
    "    </li>\n",
    "    <li>\n",
    "      <a href=\"#inference\">\n",
    "       نحوه خروجی گرفتن با داده تست\n",
    "      </a>\n",
    "    </li>\n",
    "    </li>\n",
    "    </div>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIGyifOmnOYc"
   },
   "source": [
    "\n",
    "  <div dir=rtl id=\"intro\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>\n",
    "        مقدمه\n",
    "      </font>\n",
    "<img src=\"https://static.packt-cdn.com/products/9781788624336/graphics/69abba8d-f902-43a9-8701-684941d1baf2.png\" width=\"500\">\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFc72WjwOv1s"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import keras.backend as K\n",
    "from tensorflow.keras import models\n",
    "from numpy import array_equal\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ceat3IVaPblD"
   },
   "outputs": [],
   "source": [
    "\n",
    "n_timesteps_in =   10\n",
    "\n",
    "n_features = 10   \n",
    "\n",
    "train_size= 5000\n",
    "test_size = 100  \n",
    "\n",
    "\n",
    "LSTMoutputDimension = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmZv9X3O0cxg"
   },
   "source": [
    "\n",
    "  <div dir=rtl id=\"model\">\n",
    "  <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>\n",
    "        آشنایی با مدل\n",
    "      </font>\n",
    "      <hr />\n",
    "        در این بخش میخواهیم ستون \n",
    "  </font>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5cbzOzxego6"
   },
   "outputs": [],
   "source": [
    "# TRAINING WITH TEACHER FORCING\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs= Input(shape=(n_timesteps_in, n_features))\n",
    "encoder_lstm=LSTM(LSTMoutputDimension, return_state=True)\n",
    "LSTM_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "\n",
    "# We discard `LSTM_outputs` and only keep the other states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None, n_features), name='decoder_inputs')\n",
    "decoder_lstm = LSTM(LSTMoutputDimension, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "\n",
    "# Set up the decoder, using `context vector` as initial state.\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "#complete the decoder model by adding a Dense layer with Softmax activation function \n",
    "#for prediction of the next output\n",
    "#Dense layer will output one-hot encoded representation as we did for input\n",
    "#Therefore, we will use n_features number of neurons\n",
    "decoder_dense = Dense(n_features, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# put together\n",
    "model_encoder_training = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='model_encoder_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "execution": {
     "iopub.execute_input": "2022-09-08T17:23:58.094178Z",
     "iopub.status.busy": "2022-09-08T17:23:58.093871Z",
     "iopub.status.idle": "2022-09-08T17:23:58.223769Z",
     "shell.execute_reply": "2022-09-08T17:23:58.222728Z",
     "shell.execute_reply.started": "2022-09-08T17:23:58.094152Z"
    },
    "id": "FWaKYE6Zego-",
    "outputId": "7ae64551-af6d-4476-def5-0100d4806651"
   },
   "outputs": [],
   "source": [
    "model_encoder_training.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_encoder_training.summary()\n",
    "plot_model(model_encoder_training, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7u-9szEQ1UST"
   },
   "source": [
    "\n",
    "  <div dir=rtl id=\"preprocessing\">\n",
    "    <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>آماده سازی دیتاست</font>\n",
    "      <hr />  ‍\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0br4xpCOv19"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# generate a sequence of random integers\n",
    "def generate_sequence(length, n_unique):\n",
    "\treturn [randint(1, n_unique-1) for _ in range(length)]\n",
    "\n",
    "# one hot encode sequence\n",
    "def one_hot_encode(sequence, n_unique):\n",
    "\tencoding = list()\n",
    "\tfor value in sequence:\n",
    "\t\tvector = [0 for _ in range(n_unique)]\n",
    "\t\tvector[value] = 1\n",
    "\t\tencoding.append(vector)\n",
    "\treturn array(encoding)\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "  return [argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "  # prepare encoder data for the Encoder-Decoder training\n",
    "def get_encoder_triple(time_steps,vocabulary_size,verbose= False):\n",
    "  # generate random sequence\n",
    "  sequence_in = generate_sequence(time_steps, vocabulary_size)\n",
    "\n",
    "  encoder_in = sequence_in.copy()\n",
    "\n",
    "  decoder_out = sequence_in[::-1]\n",
    "  decoder_in = decoder_out.copy()\n",
    "  decoder_in.insert(0,0)\n",
    "  decoder_in.pop()\n",
    "\n",
    "  # one hot encode\n",
    "  X_encoder_in = one_hot_encode(encoder_in, vocabulary_size)\n",
    "  X_decoder_in = one_hot_encode(decoder_in, vocabulary_size)\n",
    "  y_decoder_out = one_hot_encode(decoder_out, vocabulary_size)\n",
    "  # reshape as 3D\n",
    "  X_encoder_in = X_encoder_in.reshape((1, X_encoder_in.shape[0], X_encoder_in.shape[1]))\n",
    "  X_decoder_in = X_decoder_in.reshape((1, X_decoder_in.shape[0], X_decoder_in.shape[1]))\n",
    "  y_decoder_out = y_decoder_out.reshape((1, y_decoder_out.shape[0], y_decoder_out.shape[1]))\n",
    "\n",
    "  if(verbose):\n",
    "    print('\\nSample X_encoder_in X_decoder_in and y_decoder_out')\n",
    "    print('\\nIn raw format:')\n",
    "    print('X_encoder_in=%s, X_decoder_in=%s, y_decoder_out=%s' % \n",
    "          (one_hot_decode(X_encoder_in[0]), one_hot_decode(X_decoder_in[0]), \n",
    "           one_hot_decode(y_decoder_out[0])))\n",
    "    print('\\nIn one_hot_encoded format:')\n",
    "    print('X_encoder_in=%s' % (X_encoder_in[0]))\n",
    "    print('X_decoder_in=%s' % (X_decoder_in[0]))\n",
    "    print('y_decoder_out=%s' % (y_decoder_out[0]))\n",
    "  return [array(X_encoder_in), array(X_decoder_in), array(y_decoder_out)]\n",
    "\n",
    "\n",
    "def create_encoder_dataset(train_size, test_size, time_steps,vocabulary_size, verbose= False):\n",
    "\n",
    "  X_encoder_in = list()\n",
    "  X_decoder_in = list()\n",
    "  y_decoder_out = list()\n",
    "\n",
    "  for _ in range(train_size):\n",
    "    triple=get_encoder_triple(time_steps,vocabulary_size) \n",
    "    X_encoder_in.append(triple[0])\n",
    "    X_decoder_in.append(triple[1])\n",
    "    y_decoder_out.append(triple[2])\n",
    "\n",
    "  X_encoder_in= array(X_encoder_in).squeeze()\n",
    "  X_decoder_in= array(X_decoder_in).squeeze()\n",
    "  y_decoder_out= array(y_decoder_out).squeeze()\n",
    "  if(verbose):\n",
    "    print('\\nGenerated sequence datasets as follows')\n",
    "    print('X_encoder_in.shape: ', X_encoder_in.shape)\n",
    "    print('X_decoder_in.shape: ', X_decoder_in.shape)\n",
    "    print('y_decoder_out.shape: ', y_decoder_out.shape)\n",
    "    print('Sample sequences in raw format:')\n",
    "    \n",
    "    print('X_encoder_in: \\n', one_hot_decode(X_encoder_in[0]))\n",
    "    print('X_decoder_in: \\n', one_hot_decode(X_decoder_in[0]))\n",
    "    print('y_decoder_out: \\n',one_hot_decode(y_decoder_out[0]))\n",
    "\n",
    "    print('Sample sequences in one-hot encoded format:')\n",
    "    print('X_encoder_in: \\n', X_encoder_in[0])\n",
    "    print('X_decoder_in: \\n', X_decoder_in[0])\n",
    "    print('y_decoder_out: \\n', y_decoder_out[0])\n",
    "\n",
    "  return X_encoder_in,X_decoder_in, y_decoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-09-08T17:23:58.225234Z",
     "iopub.status.busy": "2022-09-08T17:23:58.224941Z",
     "iopub.status.idle": "2022-09-08T17:23:58.274266Z",
     "shell.execute_reply": "2022-09-08T17:23:58.272846Z",
     "shell.execute_reply.started": "2022-09-08T17:23:58.225206Z"
    },
    "id": "Vxei2ek5egpB",
    "outputId": "c54a1188-108d-4f70-a566-442aceda714d"
   },
   "outputs": [],
   "source": [
    "\n",
    "encoder_input_data, decoder_input_data, decoder_predicted_data=\\\n",
    "create_encoder_dataset(train_size, test_size, n_timesteps_in,n_features , verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGFFzm99T43e"
   },
   "source": [
    "\n",
    "  <div dir=rtl id=\"training\">\n",
    "    <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>آموزش مدل</font>\n",
    "      <hr />  ‍\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-09-08T17:23:58.275887Z",
     "iopub.status.busy": "2022-09-08T17:23:58.275573Z",
     "iopub.status.idle": "2022-09-08T17:23:58.309198Z",
     "shell.execute_reply": "2022-09-08T17:23:58.308143Z",
     "shell.execute_reply.started": "2022-09-08T17:23:58.275853Z"
    },
    "id": "-rUt-7j7egpD",
    "outputId": "1b6f3cb1-8494-46e0-fcca-a0bcd4b1c7ba"
   },
   "outputs": [],
   "source": [
    "model_encoder_training.fit([encoder_input_data, decoder_input_data], decoder_predicted_data,\n",
    "          batch_size=32,\n",
    "          epochs=30,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNzvcU7eUFKJ"
   },
   "source": [
    "\n",
    "  <div dir=rtl id=\"inference\">\n",
    "    <font face=\"XB Zar\" size=4>\n",
    "      <font color=\"red\" size=5>نحوه خروجی گرفتن روی داده تست</font>\n",
    "      <hr />  ‍\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "execution": {
     "iopub.execute_input": "2022-09-08T17:23:59.694902Z",
     "iopub.status.busy": "2022-09-08T17:23:59.694562Z",
     "iopub.status.idle": "2022-09-08T17:23:59.770833Z",
     "shell.execute_reply": "2022-09-08T17:23:59.769590Z",
     "shell.execute_reply.started": "2022-09-08T17:23:59.694874Z"
    },
    "id": "m_BKQ1yuegpP",
    "outputId": "48219b44-281c-48eb-a4df-355dc598dee6"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "plot_model(encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "bCS3RIlkQ3va",
    "outputId": "ad3a28fb-72ee-426f-e9a3-5a4d92fea21d"
   },
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(LSTMoutputDimension,))\n",
    "decoder_state_input_c = Input(shape=(LSTMoutputDimension,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "plot_model(decoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8c_8eOb0ZU5"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, n_features))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, 0] = 1\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_seq = list()\n",
    "    while not stop_condition:\n",
    "\n",
    "        # in a loop\n",
    "        # decode the input to a token/output prediction + required states for context vector\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # convert the token/output prediction to a token/output\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_digit = sampled_token_index\n",
    "        # add the predicted token/output to output sequence\n",
    "        decoded_seq.append(sampled_digit)\n",
    "        \n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (len(decoded_seq) == n_timesteps_in):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the input target sequence (of length 1) \n",
    "        # with the predicted token/output \n",
    "        target_seq = np.zeros((1, 1, n_features))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update input states (context vector) \n",
    "        # with the ouputed states\n",
    "        states_value = [h, c]\n",
    "\n",
    "        # loop back.....\n",
    "        \n",
    "    # when loop exists return the output sequence\n",
    "    return decoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "-e4Sy3YBVUU2",
    "outputId": "28512557-32fb-4d36-febd-459698a41198"
   },
   "outputs": [],
   "source": [
    "print('Input \\t\\t\\t  Expected  \\t   Predicted \\t\\tT/F')\n",
    "correct =0 \n",
    "sampleNo =  10\n",
    "for sample in range(0,sampleNo):\n",
    "  predicted= decode_sequence(encoder_input_data[sample].reshape(1,n_timesteps_in,n_features))\n",
    "  if (one_hot_decode(decoder_predicted_data[sample])== predicted):\n",
    "    correct+=1\n",
    "  print( one_hot_decode(encoder_input_data[sample]), '\\t\\t', \n",
    "        one_hot_decode(decoder_predicted_data[sample]),'\\t', predicted,\n",
    "        '\\t\\t',one_hot_decode(decoder_predicted_data[sample])== predicted)\n",
    "print('Accuracy: ', correct/sampleNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbQao9hQjsSb",
    "outputId": "eef36490-7081-48ad-831f-160f1b6ea63f"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "result = []\n",
    "for ts in tqdm(range(4, 50, 5)):\n",
    "    encoder_inputs= Input(shape=(ts, n_features))\n",
    "    encoder_lstm=LSTM(LSTMoutputDimension, return_state=True)\n",
    "    LSTM_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    decoder_inputs = Input(shape=(None, n_features), name='decoder_inputs')\n",
    "    decoder_lstm = LSTM(LSTMoutputDimension, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                initial_state=encoder_states)\n",
    "    decoder_dense = Dense(n_features, activation='softmax', name='decoder_dense')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model_encoder_training = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='model_encoder_training')\n",
    "    model_encoder_training.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    encoder_input_data, decoder_input_data, decoder_predicted_data=\\\n",
    "    create_encoder_dataset(train_size, test_size, ts,n_features)\n",
    "    history = model_encoder_training.fit([encoder_input_data, decoder_input_data], decoder_predicted_data, \n",
    "          verbose=0,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          validation_split=0.2)\n",
    "    result.append(history.history['accuracy'][-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ds4-sV1yovuw"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "1OxIRWUZrj39",
    "outputId": "1845e983-5714-480a-f158-bc5b54c54db3"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(4, 50, 5), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "pskpZ_9rqYEp",
    "outputId": "7021c99d-a8c8-4073-a044-281ccaf012a0"
   },
   "outputs": [],
   "source": [
    "x = range(4, 50, 5)\n",
    "poly = np.polyfit(x, result, deg=3)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(result, label='data')\n",
    "ax.plot(np.polyval(poly, x), label='fit')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "id": "k4ibzibNpYLh",
    "outputId": "14355706-8e16-4ec9-ca15-d2206daa8344"
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "# 300 represents number of points to make between T.min and T.max\n",
    "xnew = np.linspace(4, 49, 300) \n",
    "\n",
    "spl = make_interp_spline(range(4, 50, 5), result, k=9)  # type: BSpline\n",
    "power_smooth = spl(xnew)\n",
    "\n",
    "plt.plot(xnew, power_smooth)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
