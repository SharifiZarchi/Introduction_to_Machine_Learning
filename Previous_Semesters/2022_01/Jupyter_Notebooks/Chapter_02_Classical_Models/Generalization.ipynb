{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWK755-FnxSb"
   },
   "source": [
    "<font face=\"XB Zar\" size=5><div dir=rtl align=center>\n",
    "<font face=\"IranNastaliq\" size=5>\n",
    "به نام خدا\n",
    "</font>\n",
    "<br>\n",
    "<font size=3>\n",
    "دانشگاه صنعتی شریف - دانشکده مهندسی کامپیوتر\n",
    "</font>\n",
    "<br>\n",
    "<font color=blue size=5>\n",
    "مقدمه‌ای بر یادگیری ماشین\n",
    "</font>\n",
    "\n",
    "<hr/>\n",
    "<font color=red size=6>\n",
    "فصل دوم:مرور روش‌های کلاسیک یادگیری ماشین \n",
    "<br>\n",
    "مبحث:خطای عمومی سازی\n",
    "</font>\n",
    "<br>\n",
    "نویسنده:‌ حدیث احمدیان\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffDQcr6isJk4"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "<font color=\"red\" size=5>1.مفاهیم اولیه وعمومی سازی</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O70q6bhSv_lt"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "تعاریف زیر را در نظر بگیرید\n",
    "<br>\n",
    "**داده‌های آموزش(train):**\n",
    " مجموعه داده‌هایی که قرار است مدل روی آن‌ها آموزش ببیند.\n",
    "<br>\n",
    "**تابع هزینه :**  میانگین خطا (loss) روی داده‌های آموزش.\n",
    "<br>\n",
    "**داده های‌تست:** مجموعه داده‌هایی که پس از آموزش مدل برای سنجیدن مدل استفاده میشود. (برای سنجش یک مدل میتوان از معیار‌هایی مانند دقت استفاده کرد)\n",
    "<br>\n",
    "<br>\n",
    "**مفهوم خطای عمومی‌سازی :**\n",
    "<br>\n",
    "اگر بتوانیم مدلی را پیدا کنیم که خطا روی داده‌های آموزش را کمینه کند آیا می‌توانیم ادعا کنیم که به نتیجه‌ی مطلوب رسیده ایم؟\n",
    "<br>\n",
    "هدف اصلی ما از اموزش این مدل چه بوده‌است؟ ما می‌خواهیم الگوی موجود در داده‌های آموزش را پیدا کنیم تا بتوانیم با استفاده از آن، برای داده‌هایی که تابحال ندیده‌ایم پیش بینی‌های لازم را انجام دهیم پس برای ما کافی نیست که خطا روی داده‌های آموزش کمینه باشد بلکه خطا روی داده‌هایی که مدل برای آموزش دیدن از آنها استفاده نکرده‌است (داده های تست) نیز باید کم باشد به عبارت دیگر مدل باید توانایی عمومی‌سازی را داشته باشد و خطای عمومی‌سازی آن کم باشد.\n",
    "<br>\n",
    "<br>\n",
    "پس به طور خلاصه :\n",
    "<br>\n",
    "مدل باید علاوه بر پیش بینی صحیح داده‌های آموزش، بتواند برای نمونه‌های جدید نیز قابل عمومی‌سازی باشد.\n",
    "<br>\n",
    "<br>\n",
    "**داده های validation :** تا این مرحله لزوم و جود داده‌های تست و آموزش واضح شد.  دسته‌ی دیگری از داده را نیز میتوان جدا کرد و به منظور تنظیم هایپرپارامتر‌هایی مانند learning rate از آن ها استفاده کرد، به این مجموعه داده‌ها validation می‌گویند."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qYbpSqewI74"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "<font color=\"red\" size=5>2.بایاس و واریانس</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iw8mBW4swI75"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "تعاریف زیر را در نظر بگیرید :\n",
    "<br>\n",
    "بایاس تفاوت بین Expected Value ی estimator و مقدار پارامتری است که می‌خواهیم آن را تخمین بزنیم.\n",
    "<br>\n",
    "<div dir=ltr>\n",
    "$Bias(\\hat{\\theta})=\\mathbb{E}[\\hat{\\theta}]-\\theta$\n",
    "<div dir=rtl>\n",
    "<br>\n",
    "<br>\n",
    "واریانس نیز به صورت زیر قابل تعریف است. \n",
    "<br>\n",
    "<div dir=ltr>\n",
    "$Variance(\\hat{\\theta})=\\mathbb{E}[(\\mathbb{E}[\\hat{\\theta}]-\\hat{\\theta})^2]$    \n",
    "<div dir=rtl>\n",
    "<br>\n",
    "اگر S را خطای squared loss در نظر بگیریم خواهیم داشت :\n",
    "<br>\n",
    "<div dir=ltr>\n",
    "$S=(y-\\hat{y})^2 = (y-\\mathbb{E}[\\hat{y}]+\\mathbb{E}[\\hat{y}]-\\hat{y})^2$\n",
    "<br>\n",
    "$=(y-\\mathbb{E}[\\hat{y}])^2+(\\mathbb{E}[\\hat{y}]-\\hat{y})^2+2(y-\\mathbb{E}[\\hat{y}])(\\mathbb{E}[\\hat{y}]-\\hat{y})$\n",
    "<div dir=rtl>\n",
    "<br>\n",
    "<br>\n",
    " با اعمال امید ریاضی  (Expected value)  به هر دو سمت معادله خواهیم داشت:\n",
    "<br>\n",
    "<div dir=ltr>\n",
    "$\\mathbb{E}[S]=\\mathbb{E}[(y-\\hat{y})^2]=(y-\\mathbb{E}[\\hat{y}])^2+\\mathbb(E)[(\\mathbb{E}[\\hat{y}]-\\hat{y})^2]=[Bias]^2+Variance$\n",
    "<div dir=rtl>\n",
    "<br>\n",
    "<br>\n",
    "پس میتوان دید Mean squared loss قابل تجزیه به بایاس و ورایانس است.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82WX4TgqwI76"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "<font color=\"red\" size=5>3. overfit و underfit شدن</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUDfS_QqwI76"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "<font color=\"red\" size=4>3-1 Underfitting</font>\n",
    "<br>\n",
    "<br>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "1.هنگامی اتفاق می‌افتد که مدل انتخاب شده برای یادگرفتن ساختار و الگوی داده‌ها بیش از حد ساده است.\n",
    "<br>\n",
    "2.در این حالت واریانس کم و بایاس زیاد است.\n",
    "<br>\n",
    "3.خطا روی مجموعه‌ی آموزش و تست زیاد است.\n",
    "<br>\n",
    "<br>\n",
    "راه حل‌ها :مدل‌های پیچیده تر، مهندسی ویژگی‌ها و ویژگی‌های بهتر و کاهش قیود محدود کننده‌ی مدل\n",
    "<br>\n",
    "<br>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "<font color=\"red\" size=4>3-2 Overfitting</font>\n",
    "<br>\n",
    "<br>\n",
    "1.هنگامی اتفاق می‌افتد که مدل بیش از حد پیچیده است (با توجه به نوع داده‌ها و نویز موجود در ان‌ها ) و در نتیجه صرف نظر از الگوی پنهان در داده‌ها، میتواند داده‌های آموزش را کاملا حفظ کند.\n",
    "<br>\n",
    "2.در این حالت بایاس کم و واریانس زیاد است\n",
    "<br>\n",
    "3.در این حالت خطا روی داده‌های آموزش بسیار کم است اما روی داده‌های تست خطا زیاد است (در واقع خطای عمومی‌سازی زیاد است و مدل قدرت عمومی‌سازی ندارد)\n",
    "<br>\n",
    "راه حل‌ها : مدل های ساده تر، داده های بیشتر، کاهش نویز و منظم‌سازی\n",
    "<br>\n",
    "<br>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "<font color=\"red\" size=4>3-3 نتیجه‌گیری</font>\n",
    "<br>\n",
    "<br>\n",
    "1.در یک مدل مناسب که نه آندرفیت شده و نه اورفیت، بایاس و واریانس هر دو کم هستند.\n",
    "<br>\n",
    "2.در یک مدل مناسب خطا روی داده‌های تست و آموزش هردو میزان کم و قابل قبولی است.\n",
    "<br>\n",
    "<br>\n",
    "<font color=\"blue\" size=4>جمع بندی:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vml-ez3ZwI78"
   },
   "source": [
    "![Alt Text](https://machinelearningknowledge.ai/wp-content/uploads/2019/05/Overfitting-and-Underfitting-Animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgPnZcrywI8E"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "<font color=\"red\" size=5>4. مثال عملی</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mykfsJiwI8F"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "در زیر قطعه کدی آمده که هدف آن به نمایش گذاشتن مفاهیم مطرح شده در بالا است.\n",
    "<br>\n",
    "<br>\n",
    "**ساخت سمپل ها :**\n",
    "<br>  \n",
    "فرض کنید یک سری سمپل داریم که در واقع از یک تابع سینوسی گرفته شدده‌اند (البته ما در ابتدا این را نمی‌دانیم و درواقع فقط سمپل ها را داریم و هدف ما این است که از به سمپل ها مدلی فیت کنیم که به بهترین شکل بتواند تابع اصلی را تقریب بزند.\n",
    "<br>\n",
    "<br>\n",
    "نکته‌ی قابل ذکر این است که مانند دنیای واقعی سمپل ها مقدار کمی نسبت به مقدار اصلی‌شان نویزاندازه گیری دارند. وجود نویز میتواند باعث اورفیت شدن مدل های بیش از حد پیچیده شود پس در ادامه باید مدل خود را با پیچیدگی مناسبی انتخاب کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "ca0QgNvPxkUp",
    "outputId": "f1651ba8-b958-4ff6-9151-56ebcf810e59"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def function(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "X_tr=random.sample(list(np.arange(0, 10, 0.1)), 30)\n",
    "Y_tr=[ function(x)+random.uniform(-0.3, 0.3) for x in X_tr]\n",
    "plt.scatter(X_tr,Y_tr,color=\"red\")\n",
    "X=np.arange(0, 10, 0.1)\n",
    "Y=[ function(x) for x in X]\n",
    "plt.plot(X,Y,color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8s4mPmKwI8G"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "حال سه مدل چند‌جمله‌ای را به سمپل‌های گرفته شده فیت می‌کنیم. تفاوت این چندجمله‌ای‌ها درجه‌ی آن‌هاست. در واقع هرچقدر درجه‌ی مدل ما بیشتر باشد پیچیدگی بیشتری دارد.\n",
    "<br>\n",
    "<br>\n",
    "نکته : برای فیت کردن چندجمله‌ای به نمونه‌ها در قطعه کد‌های زیر از توابع numpy استفاده شده‌است که از روش‌های جبری استفاده می‌کند و صرفا برای نشان دادن چگونگی نتیجه ی فیت شدن از آن استفاده شده‌است. برای مقاصد لرنینگ و فیت کردن مدل‌های چندجمله‌ای یا .... با رویکرد‌های لرنینگ، کتابخوانه های دیگری قابل استفاده هستند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "iEidetmPxmEY",
    "outputId": "8171a1ea-a768-4166-adf5-9f28e01b6b15"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_tr,Y_tr,color=\"yellow\")\n",
    "X=np.arange(0,9, 0.1)\n",
    "C=[\"blue\",\"red\",\"cyan\"]\n",
    "k=-1\n",
    "for deg in [3,6,17]:\n",
    "  k+=1\n",
    "  Y=[]\n",
    "  res=np.polyfit(X_tr, Y_tr, deg, rcond=None, full=False, w=None, cov=False)\n",
    "  for x in X:\n",
    "    y=0\n",
    "    for i in range(deg):\n",
    "      y+=(x**(deg-i)*res[i])\n",
    "    Y.append(y)\n",
    "  plt.plot(X,Y,color=C[k],label=\"deg=\"+str(deg))\n",
    "\n",
    "X=np.arange(0, 10, 0.1)\n",
    "Y=[ function(x) for x in X]\n",
    "plt.plot(X,Y,color=\"green\",label=\"real function\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvV6dp93wI8G"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "میتوان دید تابع درجه 3 پیچیدگی کافی برای بیان رابطه‌ی بین سمپل‌ها و درواقع یافتن الگوی بین داده‌ها را ندارد از همین جهت این مدل آندرفیت شده‌است و خطای آموزش بالاست و هم چنین خطای عمومی‌سازی نیز بالاست زیرا مدل ما از تابع اصلی بسیار دور است.\n",
    "<br>\n",
    "<br>\n",
    "تابع درجه 17 پیچیدگی زیادی دارد و به همین علت توانسته به خوبی از اکثر داده‌های آموزشی دقیقا بگذرد و خطای آموزش بسیار پایین است. اما همانطور که مشخص است این مدل قدرت عمومی‌سازی خوبی ندارد و خطای عمومی‌سازی روی آن بالا خواهد بود و مدل تقریب درستی از تابع اصلی نیست. این به این معناست که مدل اورفیت شده است و در واقع میتوان گفت به جای یافتن الگوی بین داده‌ها تا حد ممکن آن‌ها را به طور دقیق حفظ کرده است.\n",
    "<br>\n",
    "<br>\n",
    "بر خلاف دو مدل بالا، مدل درجه 6 از پیچیدگی مناسبی برخوردار است و ضمن اینکه به خوبی از نزدیکی داده‌های آموزشی گذشته و خطای آموزش در آن مقدار کمی دارد، تابع اصلی را نیز به خوبی تقریب زده و قدرت عمومی‌سازی خوبی دارد."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4G-F6MkWGG7"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "<font  size=5>منابع :</font>\n",
    "\n",
    "https://machinelearningknowledge.ai/overfitting-and-underfitting-in-machine-learning-animated-guide-for-beginners/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
