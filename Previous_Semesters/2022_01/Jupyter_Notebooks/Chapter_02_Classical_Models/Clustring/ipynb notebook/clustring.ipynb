{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWK755-FnxSb"
   },
   "source": [
    "<font face=\"XB Zar\" size=5><div dir=rtl align=center>\n",
    "<font face=\"IranNastaliq\" size=5>\n",
    "به نام خدا\n",
    "</font>\n",
    "<br>\n",
    "<font size=3>\n",
    "دانشگاه صنعتی شریف - دانشکده مهندسی کامپیوتر\n",
    "</font>\n",
    "<br>\n",
    "<font color=blue size=5>\n",
    "مقدمه‌ای بر یادگیری ماشین\n",
    "</font>\n",
    "\n",
    "<hr/>\n",
    "<font color=red size=6>\n",
    "فصل دوم:مرور روش‌های کلاسیک یادگیری ماشین \n",
    "<br>\n",
    "مبحث:خوشه بندی\n",
    "</font>\n",
    "<br>\n",
    "نویسنده:‌ حدیث احمدیان\n",
    "<hr>\n",
    "    <div align=\"right\">\n",
    "  <font color=\"red\" size=5>فهرست مطالب</font>\n",
    "  <br>\n",
    "  <font size=4>\n",
    "\t<ul>\n",
    "        <li>\n",
    "        <a href=\"#1\">\n",
    "        1- مقدمه\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "        <ul>\n",
    "    <li>\n",
    "        <a href=\"#1-1\">\n",
    "        1-1. یادگیری بدون ناظر\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#1-2\">\n",
    "        1-2. خوشه‌بندی\n",
    "        </a>\n",
    "        </li>\n",
    "        <ul>\n",
    "        <li>\n",
    "        <br>\n",
    "        <a href=\"#1-2-1\">\n",
    "        1-2-1. انواع خوشه‌بندی\n",
    "        </a>\n",
    "        </li>\n",
    "        <li>\n",
    "        <a href=\"#1-2-2\">\n",
    "        <br>\n",
    "        1-2-2. تعریف خوشه\n",
    "        </a>\n",
    "         </li>\n",
    "    </ul>\n",
    "     </ul>\n",
    "    <br>\n",
    "        <li>\n",
    "        <a href=\"#2\">\n",
    "        2- k_means\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "        <ul>\n",
    "    <li>\n",
    "        <a href=\"#2-1\">\n",
    "        2-1. معرفی الگوریتم\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#2-2\">\n",
    "       2-2. پیاده سازی k-means\n",
    "        </a>\n",
    "        </li>\n",
    "     <br>\n",
    "    <li>\n",
    "        <a href=\"#2-3\">\n",
    "       2-3. مقداردهی اولیه مراکز خوشه ها\n",
    "        </a>\n",
    "        </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <a href=\"#2-4\">\n",
    "       2-4. بهبودهای k-means\n",
    "        </a>\n",
    "        </li>\n",
    "        <br>\n",
    "        <ul>\n",
    "    <li>\n",
    "        <a href=\"#2-4-1\">\n",
    "        2-4-1.K-means++\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "     <li>\n",
    "        <a href=\"#2-4-2\">\n",
    "        2-4-2.K-means تسریع شده\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "     <li>\n",
    "        <a href=\"#2-4-3\">\n",
    "        2-4-3.mini-batch K-means\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "    </ul>\n",
    "        <li>\n",
    "        <a href=\"#2-5\">\n",
    "        2-5.انتخاب تعداد خوشه‌ها\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "        <ul>\n",
    "     <li>\n",
    "        <a href=\"#2-5-1\">\n",
    "        2-5-1.استفاده از inertia\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "     <li>\n",
    "        <a href=\"#2-5-2\">\n",
    "        2-5-2.silhouette score\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "     <li>\n",
    "        <a href=\"#2-5-3\">\n",
    "        2-5-3.DB index\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "        </ul>\n",
    "        <li>\n",
    "        <a href=\"#2-6\">\n",
    "        2-6.محدودیت‌های k-means\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "     </ul>\n",
    "        <li>\n",
    "        <a href=\"#3\">\n",
    "        3.کاربردهای خوشه بندی\n",
    "        </a>\n",
    "\t</li> \n",
    "          <br>\n",
    "    <ul>\n",
    "     <li>\n",
    "        <a href=\"#3-1\">\n",
    "        3-1. Image Segmentation\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "     <li>\n",
    "        <a href=\"#3*2\">\n",
    "        3-2. پیش پردازش داده‌ها\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "        <li>\n",
    "        <a href=\"#3-3\">\n",
    "        3-3. Semi-Supervised learning\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "        <li>\n",
    "        <a href=\"#3-4\">\n",
    "        3-4. یادگیری فعال (active learning)\n",
    "        </a>\n",
    "\t</li>\n",
    "    <br>\n",
    "       \n",
    "            \n",
    "   <br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffDQcr6isJk4"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"1\">\n",
    "<font color=\"red\" size=5>**1.مقدمه**</font>\n",
    "<br>\n",
    "    <br>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"1-1\">\n",
    "<font color=\"red\" size=4>**1-1. یادگیری بدون ناظر (Unsupervised learning)**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O70q6bhSv_lt"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "در دنیای امروزی اکثر کاربردهای یادگیری ماشین  مبتنی بر یاگیری با ناظر (supervised learning) هستند. این بدین معنی است که برای این کاربردها نیاز به داده های برچسب‌دار داریم یعنی برای آموزش مدل خود علاوه بر ویژگی ها باید برچسب داده های مورد نظر را نیز داشته باشیم حال آنکه داده‌های برچسب دار تنها بخش بسیار کوچکی از تمام داده‌های موجود هستند.\n",
    "<br>\n",
    "<br>\n",
    "اجازه دهید با یک مثال بیشتر به این موضوع بپردازیم. فرض کنید در یک کارخانه که کالایی را تولید می‌کند وظیفه داریم کالای سالم از کالای خراب را تشخیص دهیم و برای انجام این کار می خواهیم یک مدل آموزش دهیم. ساخت داده بدون برچسب برای این کار بسیار راحت است. کافیست یک دوربین در اختیار داشته باشیم که از تمام کالاهای تولید شده در خط تولید عکسبرداری کند اما تنها با داشتن این عکس ها نمیتوانیم به صورت supervised عمل کنیم، زیرا نمی‌دانیم که هرعکس متعلق به کالای سالم است یا یک کالای خراب. به بیان دیگر برچسب متعلق به هر داده را در اختیار نداریم.برای برچسب گذاری داده ها نیاز به یک اپراتور انسانی داریم که تک تک عکس ها را بررسی کند و مشخص کند که آن کالا سالم بوده است یا خیر. می دانیم که این کار بسیار پر هزینه خواهد بود، به همین دلیل اغلب مجبور خواهیم بود تنها بخش کوچکی از داده‌های موجود را به طور تصادفی انتخاب کنیم و تنها آن بخش کوچک را برچسب گذاری کنیم.\n",
    "<br>\n",
    "<br>\n",
    " اولین مشکل این است که به دلیل کوچک بودن مجموعه داده های برچسب دار، نمی توان مدل  توانمندی را آموزش داد. علاوه بر این اگر بخش هایی از کالاهای تولیدی توسط کارخانه تغییر کند، دیگر مدل ما قابل استفاده نخواهد بود و باید از اول عکس های کالاهای جدید برچسب گذاری شود و مدل با داده های جدید آموزش ببیند.\n",
    "<br>\n",
    "<br>\n",
    " یک مثال جالب برای مقایسه ی میزان داده های برچسب دار و بدون برچسب موجود، مثال کیک و گیلاس است. اگر داده های بدون برچسب موجود را به اندازه یک کیک در نظر بگیریم، داده های برچسب دار تنها به اندازه گیلاس کوچکی روی کیک است!\n",
    " پس مشخص است که اگر ما رویکردی در اختیار داشتیم که بدون نیاز به برچسب داده ها بتواند یک مدل را آموزش دهد مزیت بزرگی برای ما خواهد بود  به این دلیل که تعداد داده های بدون برچسب در دسترس در حال حاضر بسیار بیشتر از داده های برچسب دار است و برچسب گذاری یک پروسه‌ی پرهزینه است.\n",
    "<br>\n",
    "<br>\n",
    "به رویکرد هایی که بدون نیاز به برچسب میتوانند از داده ها استفاده کنند روشهای بدون ناظر یا unsupervised گفته می شود.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mmWrqsqgjS9"
   },
   "source": [
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQPSJiCfgeheZmrwGW_f06cRHOI-7LacSUvBzshOguL1KDPdxbZBnuTEGwSBwEHjcunTdI&usqp=CAU)\n",
    "\n",
    "\n",
    "<a href=\"https://www.123rf.com/photo_124142961_womans-hand-puts-a-cherry-on-top-of-a-cake-on-the-white-blue-background-square-vector-illustration.html\">pic source</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kh34Le73gjS-"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"1-2\">\n",
    "<font color=\"red\" size=4>**1-2. خوشه‌بندی (Clustring)**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7EWjlqIgjS-"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "خوشه بندی از رویکردهای Unsupervised  است که هدف اصلی در آن، گروه بندی نمونه هاست به صورتی که نمونه های مشابه در یک گروه قرار بگیرد. خوشه بندی در کاربرد های زیادی استفاده می‌شود از این کاربردها می توان به  سیستم های recomender، موتورهای جستجو، سگمنتیشن تصاویر، یادگیریsemi-supervised،  کاهش بعد و... اشاره کرد.\n",
    "<br>\n",
    "<br>\n",
    "    مثال زیر را در نظر بگیرید، در نمودار سمت راست داده‌ها برچسب دارند و یک رویکرد با ناظر می‌تواند از این داده‌ها استفاده کند (مانند classification) اما همان نمونه‌ها در سمت چپ را بدون برچسب‌هایشان مشاهده می‌کنید و هرچند این داده ها برچسب ندارند، اما باز هم جدا بودن بخشی از داده‌ها نسبت به سایر داده‌ها واضح است. این نشان می‌دهد بدون داشتن برچسب داده‌ها، ویژگی‌ها بدون داشتن برچسب ها می‌توانند اطلاعات کافی برای نسبت دادن هر نمونه به یک گروه را در اختیار ما قرار دهند که این همان رویکرد بدون ناظر است(مانند خوشه‌بندی).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sULNRWQ0gjS_"
   },
   "source": [
    "![](https://freddyox.github.io/images/kmeans/4Means_example_success.png )\n",
    "\n",
    "<a href=\"https://freddyox.github.io/blog/Kmeans/\">pic source</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9rz5f-GgjTA"
   },
   "source": [
    "\n",
    "\n",
    "   \n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "<font color=\"red\" size=4><div id=\"1-2-1\">1-2-1. انواع خوشه بندی :</font>\n",
    "<br>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "**الف ) دسته بندی بر اساس نرم یا سخت بودن**\n",
    "<br>\n",
    "**سخت (hard) :** هر نمونه دقیقا به یک خوشه نسبت داده میشود. در واقع خروجی این است که هر نمونه دقیقا متعلق به کدام خوشه است.\n",
    "<br>\n",
    "**نرم (soft) :** هر نمونه  با احتمالی بین 0و 1 به چندین خوشه نسبت داده میشود. در واقع خورجی این است که احتمال تعلق هر نمونه به هر کدام از خوشه ها چقدر است.\n",
    "<br>\n",
    "<br>\n",
    "**الف ) دسته بندی بر اساس patitional  یا hierachial بودن**\n",
    "<br>\n",
    "**patitional :** تمام خوشه ها در سطح یکسانی قرار دارند.\n",
    "<br>\n",
    "**سلسه مراتبی (hierachial) :** وقتی به شکل سلسه مراتبی با ادغام خوشه های کوچکتر به خوشه های بزرگتر میرسیم. ئرواقع هر خوشه خود میتواند زیر مجموعه ی یک خوشه ی سطح بالاتر باشد و چند خوشه ی کوچکتر را در بر داشته باشد.این یعنی خوشه ها سطح دارد و همه در سطح یکسانی نیستند.\n",
    "<br>\n",
    " اگر در ابتدا هر نمونه را یک خوشه در نظر بگیریم و سپس خوشه های نزئیک را باهم ادغام کنیم تا نهایتا به یک خوشه برسیم این روش خوشه بندی سلسه مراتبی به صورت تجمعی خواهد بود. رویکرد متفاوت میتواند این باشد که تمام داده ها یک خوشه در نظر گرفته شود و سپس خوشه های بزرگتر با تقسیم سلسه مراتبی به خوشه های کوچکتر تبدیل شوند.\n",
    "<br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "<font color=\"red\" size=4><div dir=rtl id=\"1-2-2\">1-2-2. تعریف خوشه :</font>\n",
    "<br>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "حال که با مفهوم و انواع خوشه‌بندی آشنا شدیم شاید جالب باشد درمورد مفهوم خود خوشه هم به طور دقیق‌تر صحبت کنیم. هیچ تعریف جهانی ای برای خوشه وجود ندارد و تعریف خوشه کاملاً به کاربرد ما بستگی دارد. بعضی از الگوریتم‌ها به دنبال داده‌هایی هستند که از یک نقطه‌ی مشخص به نام مرکز خوشه، کمترین فاصله را داشته باشند. برخی به دنبال نواحی از از نمونه‌ها هستند که چگالی بیشتری دارند ودر آن ها خوشه‌ها هر شکلی می‌توانند داشته باشند. برخی دیگر از الگوریتم‌ها نیز به طور سلسه مراتبی خوشه‌بندی می‌کنند ودرواقع به دنبال خوشه ای از خوشه‌ها هستند.\n",
    "<br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    در ادامه یکی از مهم‌ترین الگوریتم‌های خوشه‌بندی به نام k-means را مورد بررسی قرار می‌دهیم و سپس جزییات و کاربردهای بیشتر از خوشه‌بندی را مرور می‌کنیم.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNQ3GDorgjTB"
   },
   "source": [
    "![](https://miro.medium.com/max/1400/1*ghEzFd4sMX37OvH_U1xPZQ.png)\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/\">pic source</a>\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*Ntef_OJUpkrxytutzwDtIA.png)\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/a-brief-introduction-to-unsupervised-learning-20db46445283\">pic source</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9F_0GGI5gjTD"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2\">\n",
    "<font color=\"red\" size=5>**2.K-means**</font>\n",
    "<br>\n",
    "    <br>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-1\">\n",
    "<font color=\"red\" size=4>**2-1.معرفی الگوریتم**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0B5FiecgjTE"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "این الگوریتم با فرض وجود k خوشه، k مرکز خوشه را مشخص می‌کند و هر داده را به خوشه ای که داده به مرکز آن خوشه نزدیک‌تر است نسبت می‌دهد.\n",
    "<br>\n",
    "به عبارت دیگر به ازای k مرکز خوشه‌ی $c_k$ و $x_n$ هایی که عضو هر خوشه هستند هدف k-means کمینه کردن مقدار زیر است.\n",
    "<br>\n",
    "<div dir=ltr>\n",
    "$\\sum_{n=1}^{N} \\sum_{x_n \\in c_k}{||x_n – c_k||}^2$\n",
    "    \n",
    "<div dir=rtl>\n",
    "<br>\n",
    "<br>\n",
    "فرض کنید مرکز خوشه‌ها را در اختیار داریم، بنابراین یافتن اینکه هر داده به کدام خوشه متعلق است بسیار ساده است و کافی است ببینیم هر داده به کدام مرکز خوشه نزدیک‌تر است.\n",
    "<br>\n",
    "حال فرض کنید مرکز خوشه‌ها را نداریم؛ ولی برچسب هر داده در اختیار ماست و میدانیم هر داده متعلق به چه خوشه ای است، به این ترتیب می‌توانیم میانگین داده‌های هر خوشه را به عنوان مرکز آن خوشه معرفی کنیم.\n",
    "<br>\n",
    "<br>\n",
    "اما در ابتدای امر ما نه مرکز خوشه‌ها را داریم و نه برچسب داده هارا پس رویکرد چه باید باشد؟ Kmeans به این گونه عمل می‌کند: \n",
    "<br>\n",
    "ابتدا k مرکز خوشه‌ی تصادفی انتخاب می‌کند (درواقع  به طور تصادفی K تا از داده‌ها را به عنوان مراکز خوشه انتخاب می‌کند)\n",
    "<br>\n",
    " سپس با استفاده از مرکزهای انتخاب شده، خوشه‌ی هر داده را مشخص می‌کنیم\n",
    "<br>\n",
    " سپس با استفاده از برچسب‌های مشخص شده مرکزهای جدید را محاسبه و به روز رسانی می‌کنیم\n",
    "<br>\n",
    " همین دو مرحله را تا زمانی ادامه می‌دهیم که مرکز خوشه‌ها دیگر جابجا نشوند. \n",
    "<br>\n",
    "<br>\n",
    "نکته‌ی قابل این است که الگوریتم بعد از تعدادی مرحله (که اصولاً هم کم است) حتماً همگرا می‌شود و تا ابد نوسان نخواهد داشت. (این موضوع با این حقیقت قابل اثبات است که در هر مرحله mean squared distance بین داده‌ها و نزدیک‌ترین مرکز خوشه به آن‌ها تنها می‌تواند کاهش یابد)\n",
    "<br>\n",
    "<br>\n",
    "عملکرد الگوریتم k-means را میتوانید در مثال زیر ببینید:\n",
    "  <br>  \n",
    "      <br>  \n",
    "(اگر وب پیج در نوت بوک برای شما باز نمیشود، میتوانید مستقیما از طریق لینک به وب پیج دسترسی پیدا کنید)\n",
    "    \n",
    "    http://shabal.in/visuals/kmeans/2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LOoPwHmwgjTF",
    "outputId": "af89f8c7-d7e1-4c33-f3d4-29e32103bbfa"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"http://shabal.in/visuals/kmeans/2.html\" width=\"900\" height=\"900\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJp6GJ3zgjTI"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-2\">\n",
    "<font color=\"red\" size=4>**2-2.پیاده سازی k-means**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPq9MEAbgjTJ"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "ابتدا اجازه دهید داره های مورد استفاده را معرفی کنیم. gene expression cancer RNA-Seq DataSet یک دیتاست است که ویژگی های آن میزان بیان ژن های مختلف در افراد مبتلا سرطان است که هرکدام نوع متفاوتی از تومور (BRCA, KIRC, COAD, LUAD and PRAD) را دارند. \n",
    "<br>\n",
    "لینک دیتابیس برای اطلاعات بیشتر :https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq\n",
    "<br>\n",
    "<br>\n",
    "نکته 1: دیتاست اصلی شامل تعداد 20531  ژن و میزان بیان هر کدام به ازای هر بیمار است (در واقع میزان بیان هر ژن یک ویژگی است پس دیتاست اصلی 20531 ویژگی به ازای هر نمونه دارد) ، چون میخواهیم یک مثال ملموس داشته باشیم و داده ها قابل visulisation باشند، داده ها را با استفاده از TSNE کاهش بعد داده ایم اما این مراحل به دلیل اینکه مبحث مورد بحث ما نیست در این قسمت نیامده است. نتیجه ی نهایی پس از کاهش بعد یک دیتاست است که به ازای هر نمونه دو ویژگی دارد.\n",
    "<br>\n",
    "<br>\n",
    "نکته 2 : این دیتاست یک دیتاست با برچسب است اما ما قرار نیست از برچسب ها در طی خوشه بندی استفاده کنیم چون خوشه بندی یک رویکرد بدون ناظر است. بعد از خوشه بندی بدون استفاده از برچسب ها، ما نتایج خوشه بندی را با برچسب های واقعی مقایسه میکنیم تا این دید را منتقل کنیم که در کاربرد های واقعی نتیجه ی حاصل از خوشه بندی میتواند یک نتیجه ی معنا دار باشد اما طبیعتا در کاربرد های واقعی ما برچسب ها را نخواهیم داشت.\n",
    "<br>\n",
    "<br>\n",
    "پس نهایتا داده های مورد استفاده برای مثال خوشه بندی به شکل زیر هستند، تعداد 640 بیمار که به ازای هر کدام 2 ویژگی مرتبط به ژن ها داریم و میخواهیم ببینیم با توجه به تفاوت این ویژگی ها در افراد، آیا میشود آن ها را در خوشه های مجزا قرار داد ؟\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBi2_WEHgjTK"
   },
   "outputs": [],
   "source": [
    "data=[[15.749946, 25.67278], [18.836815, 25.197464], [-7.8372335, 10.255067], [-26.534391, -23.085606], [-11.669913, 9.651402], [-2.8868644, -0.7663649], [-12.393535, 4.355013], [11.539186, -20.062393], [20.767662, 24.43075], [-22.82413, -21.556166], [-12.494511, 16.865156], [-23.29931, -19.123072], [30.594902, -8.565838], [8.062314, -23.518204], [28.009048, -8.1264105], [-8.852229, 15.578309], [-21.624655, -20.548853], [-24.849821, -24.472263], [20.560423, 21.571238], [-1.1004233, 2.0087533], [-1.873746, 7.9915347], [30.802496, -7.2481036], [19.072481, 19.2552], [21.065872, 20.76488], [-9.375898, 15.893979], [-10.643299, 8.0750065], [-8.878188, 15.637808], [-12.114253, 3.164282], [-1.8818645, -0.058748364], [-8.220354, 12.318555], [-1.5130491, 6.7672877], [19.958986, 17.029428], [-24.160555, -19.009085], [-8.652243, 8.02438], [-11.925594, 16.602318], [10.08873, -17.2292], [-26.068758, -17.625523], [-1.8641611, -1.2421356], [20.334507, 20.234566], [19.643442, 22.422144], [-10.528474, 5.8064904], [-24.901917, -19.479239], [0.5557313, 0.38845488], [-2.490182, 0.37663853], [33.444653, -6.9606776], [33.363544, -7.600764], [-0.14743622, 0.5715712], [-11.346277, 3.3364131], [-13.75685, 8.601343], [-8.598696, 13.576949], [19.987904, 19.942095], [7.3668094, -20.416945], [-2.0887446, 7.412787], [22.61622, 21.406818], [-12.245721, 13.306295], [-23.16132, -23.11047], [28.825615, -8.328112], [-5.689404, 9.635], [-23.893557, -21.534235], [-8.952067, 16.497849], [32.665592, -6.9591084], [4.728124, -19.528355], [-7.3340797, 11.689362], [5.874291, -16.841555], [5.0278525, -20.49007], [31.77242, -6.7844343], [-7.7575927, 14.996685], [31.033504, -9.387033], [-13.493384, 11.359119], [19.021095, 24.559881], [6.117631, -21.315266], [-23.06664, -17.494513], [33.123928, -5.466884], [-26.893663, -18.59526], [18.504772, 17.385168], [-21.36341, -20.575232], [15.983028, 25.560915], [32.62078, -7.5419703], [-13.197562, 12.806383], [-26.023556, -22.497927], [7.7810893, -22.673521], [-13.901995, 11.814548], [23.70875, 17.3704], [-6.9608626, 8.73798], [9.953586, -22.718294], [4.618629, -21.913677], [9.191335, -20.365538], [-5.169105, 2.397376], [-12.784279, 16.292143], [22.268135, 25.45882], [-10.809961, 13.481175], [-22.00729, -19.473463], [-6.788726, 7.666438], [-8.8964815, 6.8367133], [-10.882726, 17.935997], [-13.556144, 14.610165], [21.378126, 18.746866], [-27.218693, -23.560282], [-2.3457656, 7.387856], [-26.440521, -18.626944], [6.3414383, -21.481787], [-2.70661, 1.3246679], [-4.365422, 5.9851727], [-2.9775302, 7.877526], [-11.960014, 9.717776], [15.883193, 22.227861], [13.8058, -19.209534], [-7.9356537, 9.139616], [-7.4210234, 18.604452], [-15.541277, 10.804491], [6.4835353, -19.646725], [-9.58969, 11.23551], [-5.376545, 6.724256], [24.530594, 22.188747], [21.362503, 20.116465], [-3.7793558, 10.385966], [8.272492, -23.800909], [-11.594442, 11.350551], [21.817879, 22.373203], [22.000446, 18.77062], [4.499771, -23.6405], [-9.552845, 10.413451], [3.8106287, -19.75768], [8.119941, -24.515549], [13.34871, -21.495506], [7.172435, -20.091446], [-24.673698, -18.845781], [0.2259135, 0.08480928], [19.27379, 23.865324], [-22.713743, -19.472214], [29.008854, -8.165669], [21.808655, 17.111238], [-7.7448645, 12.672498], [12.223417, -21.012325], [22.446653, 23.50067], [17.265171, 20.126259], [-13.154639, 9.652476], [-11.551202, 3.250993], [13.011624, -21.46731], [-5.333635, 10.277853], [-5.68719, 10.028599], [-25.782557, -22.712795], [-25.437347, -20.03646], [-3.863495, 3.7416878], [30.797544, -8.51625], [6.974225, -21.737309], [6.049369, -21.68588], [21.122274, 17.13188], [21.011917, 25.744953], [-27.241808, -23.26462], [-12.513337, 14.080099], [13.258498, -19.705452], [15.732821, 25.722572], [-7.7534084, 13.538689], [11.157929, -21.144474], [24.645401, 20.768118], [33.805904, -7.937472], [-13.07635, 4.102323], [12.131721, -22.207945], [-9.818184, 8.828529], [13.149512, -22.875092], [-26.356396, -19.183191], [17.146223, 26.133163], [33.802113, -9.354775], [-3.766513, 0.2872465], [-3.6620135, 6.5946093], [32.049026, -7.8431053], [-21.652308, -17.453861], [19.467188, 21.822176], [19.53931, 21.517168], [-0.5502047, -0.27104813], [-8.41759, 14.48058], [19.624487, 22.200245], [-24.579105, -15.127612], [-22.65383, -15.550299], [6.080668, -24.53112], [7.081777, -20.315655], [-24.927261, -19.517702], [30.310556, -5.505753], [-2.1316278, 6.3784513], [-22.720955, -20.99752], [21.665094, 24.692392], [-12.747998, 16.388393], [23.012644, 23.772465], [-12.313512, 12.933869], [-7.830558, 9.428963], [31.94222, -5.7897987], [5.4508414, -18.778093], [-15.259263, 10.852008], [9.285285, -20.88104], [21.429943, 23.407312], [31.691841, -6.490375], [19.504995, 24.405596], [-7.50579, 6.4883704], [-26.22849, -19.516808], [-22.052282, -18.442577], [21.302965, 21.448833], [7.1157446, -20.98469], [33.18514, -9.921984], [22.038916, 16.719606], [7.095394, -19.560774], [31.24311, -6.98421], [6.8154106, -23.495207], [-9.825268, 12.991114], [6.9602976, -19.104046], [32.34765, -9.2230625], [-28.34239, -19.977686], [-13.900457, 13.25054], [0.22298025, -0.17785977], [9.662015, -19.216732], [23.40345, 24.06542], [11.841735, -21.742834], [-8.1015005, 13.309891], [18.575165, 21.408155], [-7.0185976, 8.232393], [30.035961, -8.451019], [13.830763, -19.17294], [-5.8294063, 9.489572], [7.014954, -22.375439], [-5.5569324, 9.121034], [-23.110321, -21.70129], [-26.88022, -19.501986], [21.66117, 25.548695], [-10.124909, 15.37163], [22.917925, 25.557474], [10.007142, -22.174294], [-22.9533, -22.504717], [-22.470602, -20.689491], [-7.2770114, 5.0337615], [9.935935, -22.151089], [29.831753, -9.176116], [-4.6532216, 10.388449], [-5.626613, 4.7179112], [19.350887, 20.85086], [11.634768, -21.909538], [4.7391653, -23.341022], [-12.916995, 11.106371], [21.963486, 25.410484], [-5.719871, 15.984827], [31.655005, -7.280147], [7.0984745, -18.630186], [-23.766874, -19.470087], [-8.430784, 10.920739], [21.176811, 21.528362], [30.13139, -7.3420267], [6.1744742, -21.247454], [5.0232058, -16.989756], [32.321682, -4.9799223], [-23.777279, -17.610977], [-7.217397, 12.912841], [-11.839074, 10.946936], [22.164423, 22.876196], [-22.20905, -16.827663], [-13.406613, 11.13075], [20.731943, 25.258347], [-7.8909864, 5.6368823], [19.630861, 17.908161], [-14.624699, 12.93678], [5.8345275, -17.287518], [5.319486, -16.699549], [-8.403704, 13.508244], [-20.211773, -20.231918], [3.7624197, -21.205303], [32.525913, -7.2107143], [19.361256, 19.701805], [-12.639847, 13.220277], [34.23677, -6.607308], [-14.4184675, 12.034888], [5.5154023, -22.181705], [28.08207, -8.094085], [-12.627698, 9.562921], [32.428608, -6.334043], [-26.404085, -21.910698], [29.606382, -8.445484], [31.035444, -7.3776875], [-9.180939, 8.814103], [-9.679962, 16.661919], [33.44832, -5.6464067], [6.391694, -18.527462], [-14.891498, 12.037067], [6.270977, -19.751465], [-23.943275, -23.114965], [30.732155, -6.6759505], [-25.5429, -21.303652], [-8.824535, 4.4803886], [-2.6884809, 9.187094], [-3.1371644, -0.40088275], [9.560083, -19.090624], [-6.8592134, 9.282417], [23.568419, 23.278687], [-11.83134, 6.1393094], [19.151999, 24.653112], [-24.617579, -21.693352], [-23.679081, -20.645304], [-10.317247, 5.5775385], [-8.003753, 7.2578077], [35.328648, -8.031376], [-5.3311462, 7.995837], [-25.050865, -17.946358], [-9.707505, 6.5879755], [-22.560123, -20.634602], [6.3319077, -19.882467], [16.152323, 25.2384], [-6.224099, 10.639958], [-27.85909, -20.014677], [-23.411943, -17.01247], [-10.908223, 12.187706], [27.4144, -8.445472], [-1.5666143, 6.597062], [6.985483, -18.051249], [32.75801, -8.8444], [11.501614, -21.90836], [-6.7997036, 9.597791], [-22.776024, -20.259266], [-22.490227, -21.743948], [-10.29802, 6.8104258], [-22.589909, -18.658527], [11.7743635, -22.896288], [4.871357, -16.229334], [-20.359259, -20.1522], [9.055662, -20.19132], [32.25735, -7.66897], [-4.494575, 9.296986], [-21.699286, -22.83246], [-8.896653, 10.445289], [-6.797821, 6.4294205], [34.490406, -6.304211], [-0.18221594, -1.0011784], [-13.372654, 4.0171866], [32.15079, -10.166369], [-23.242487, -17.23244], [-6.2523074, 6.964531], [-9.964879, 13.372585], [7.7620044, -21.138304], [-2.6694398, 6.7359548], [21.426271, 17.836628], [-7.4282165, 18.600395], [-6.256361, 8.375626], [-26.104334, -15.200393], [-20.55048, -18.454046], [-27.721245, -21.724974], [33.063854, -7.561181], [7.619193, -23.418343], [20.044384, 26.439116], [22.729692, 18.119698], [-7.883111, 8.7311125], [19.94739, 22.972229], [8.32456, -19.612345], [-15.087975, 14.082391], [32.528034, -5.737695], [-9.514895, 9.368405], [10.431457, -19.412025], [-12.310189, 6.3310237], [-11.901736, 11.0095415], [-2.7865293, -0.06485431], [8.6544695, -18.125423], [0.3529832, 0.6494782], [-13.298017, 4.2924366], [20.272398, 17.014894], [23.56346, 19.102137], [20.776995, 24.851395], [-24.037943, -15.280286], [4.2656126, -19.521446], [-15.279032, 14.631053], [0.71416837, 0.97750473], [16.188965, 22.601965], [-5.846988, 8.971903], [20.38825, 19.370504], [-25.829424, -18.715086], [9.183862, -17.75163], [5.250631, -20.316265], [-6.4004993, 7.8119674], [-10.113469, 11.881924], [-24.719854, -22.753992], [-6.5930552, 7.3588123], [19.262642, 19.183191], [-10.201551, 6.1850505], [10.326273, -22.550026], [-11.566003, 3.5326881], [-25.730558, -22.145895], [-10.323783, 12.398664], [24.491573, 24.112823], [0.39504248, 0.3805396], [31.810894, -7.7148347], [5.569654, -16.782503], [-26.978085, -22.018904], [23.765951, 17.992378], [15.648333, 24.547375], [20.039635, 25.184689], [-1.992553, 0.58352685], [-9.076839, 13.041351], [6.3828163, -19.870182], [-8.247947, 6.025746], [5.5123725, -20.875156], [-10.427021, 6.776877], [-21.83356, -15.926712], [23.646343, 25.639877], [-2.1558301, -1.9972987], [-5.121292, 13.694186], [12.585074, -22.805653], [20.749998, 26.047136], [7.469689, -19.70583], [-11.889177, 7.107875], [9.266435, -18.221512], [-10.295265, 10.525016], [19.978464, 19.952839], [-25.85116, -15.842298], [23.977444, 18.891968], [-20.868837, -21.725391], [20.986378, 18.284801], [9.24515, -25.349556], [7.0816126, -23.564985], [24.543318, 18.735582], [-24.44842, -22.061275], [-25.35719, -22.282244], [7.9650445, -24.273302], [21.101698, 20.367546], [-25.094828, -21.676994], [20.614298, 15.982875], [32.639748, -10.194853], [-11.414761, 3.4047215], [23.781612, 24.277382], [22.522251, 23.953075], [-8.984715, 7.9849067], [15.581436, 22.007126], [21.777708, 19.447418], [5.3635526, -21.225618], [-9.224753, 4.0562525], [-27.524538, -17.866093], [8.917984, -23.359512], [-6.550101, 10.756013], [10.435902, -23.475195], [-10.522691, 11.599672], [20.47274, 25.263655], [-25.211586, -19.901386], [-1.9991556, -0.30551013], [7.8969674, -22.602184], [20.867434, 19.047935], [-13.851619, 13.676666], [-4.323738, 11.94483], [30.009138, -6.6208315], [-5.1409526, 9.527891], [-5.8773975, 12.648014], [21.434032, 17.11918], [-26.593485, -20.481112], [19.404577, 18.521784], [-8.79659, 4.4472127], [-6.336389, 14.867744], [-0.68260884, 0.98633146], [21.10487, 24.574482], [-27.82866, -22.189941], [20.778852, 27.182676], [23.981758, 22.95174], [-12.844236, 9.495018], [0.5187756, -1.9026572], [9.9501095, -21.9533], [-7.623433, 10.216174], [32.420094, -10.174718], [-28.655323, -19.930504], [21.388641, 17.023134], [19.627968, 23.70178], [24.053507, 22.920546], [-8.508982, 9.649208], [20.586966, 19.313593], [-23.112564, -19.752296], [-21.196806, -17.43478], [-8.523292, 6.9039297], [18.903551, 22.240564], [-0.94353086, 2.3861728], [22.679209, 21.249083], [11.152647, -17.36612], [-6.9433694, 7.743698], [19.67152, 25.731873], [-10.223686, 7.6667104], [20.04336, 23.428165], [29.959509, -6.9498606], [8.143237, -23.33081], [-25.385563, -15.251363], [10.712153, -24.591085], [-9.87018, 15.64367], [-8.221048, 3.7196245], [-9.485348, 4.9644423], [10.66504, -17.82208], [-3.2842896, 7.1333055], [32.521862, -6.503626], [30.52262, -7.4824333], [-7.527122, 14.064329], [-12.592742, 13.009217], [-1.0521485, 0.59620684], [-28.704367, -18.668798], [-3.4732742, -0.81531286], [31.530386, -7.8998895], [-25.72608, -23.150887], [-4.937788, 14.3142805], [-7.12577, 13.752764], [18.517284, 20.136023], [21.78704, 23.712894], [-9.141786, 14.337623], [-9.091479, 11.443679], [-1.9414732, 1.3364518], [-1.4742372, -0.19324699], [-7.2346454, 10.387769], [8.6151905, -22.18366], [33.542824, -6.547914], [34.04404, -8.472653], [-28.429008, -22.648228], [33.410683, -7.0185704], [23.625391, 19.459528], [10.433451, -18.579287], [-23.380388, -19.742933], [19.000246, 18.415108], [-5.405585, 11.308013], [18.78532, 18.577204], [-11.995059, 14.075999], [-3.1268902, 7.6783385], [22.626904, 23.079569], [22.032534, 23.894037], [-11.73983, 12.204481], [17.36958, 22.275278], [18.34627, 23.355345], [-24.544828, -19.568947], [-21.329687, -19.009813], [5.2235527, -17.848001], [7.072785, -20.87855], [11.689521, -22.70457], [-9.548237, 16.88883], [-13.804216, 15.8963], [0.22833587, -1.2990744], [-22.877035, -21.929405], [-27.925512, -23.629158], [31.254759, -8.92222], [-11.307327, 16.708158], [5.608953, -22.443604], [20.29846, 24.441053], [-1.5266383, 1.3511852], [7.478948, -20.866623], [35.291378, -8.046991], [22.13168, 26.662287], [-6.6123495, 11.985339], [20.52683, 19.406712], [-24.209972, -19.994905], [29.30938, -6.3226047], [-11.906997, 3.954787], [-27.882225, -21.458557], [-23.126741, -15.190878], [-6.8831134, 6.7826533], [-10.747586, 14.402427], [-26.29709, -21.16495], [-8.699017, 12.094375], [-12.972817, 13.4902935], [-6.7457347, 13.586611], [9.946116, -20.07805], [-8.076798, 12.487374], [-16.528276, 13.039964], [10.95607, -18.155544], [-25.867594, -20.54032], [-24.637861, -17.355148], [21.886105, 18.185665], [33.05168, -7.1149387], [-1.1817938, -1.687144], [-4.9582605, 15.361062], [34.500546, -7.490501], [-8.739214, 13.919178], [19.660051, 17.108023], [-24.17124, -15.698891], [-13.926876, 4.7835946], [-22.713377, -20.77393], [-0.893016, 1.5897458], [-0.77253, 1.9183514], [-26.70165, -17.752253], [-7.229249, 16.04925], [20.301193, 25.219292], [-11.237701, 9.262465], [22.596909, 24.160122], [30.133692, -7.30519], [30.234627, -7.0258904], [-25.766989, -20.96087], [-7.4240522, 9.259262], [-1.6806045, -0.010849822], [-23.438295, -20.431797], [-5.897264, 5.9539204], [18.310667, 25.924322], [-23.262735, -24.485287], [-24.293129, -14.982212], [-4.4462986, 12.047455], [8.554054, -21.78333], [-26.853104, -19.297298], [12.2981, -21.794706], [21.327824, 24.085228], [-1.4533111, -0.8426513], [-22.227057, -17.336014], [-7.3819227, 10.471768], [29.019962, -9.503677], [8.51981, -22.206554], [10.585956, -18.232357], [7.9070845, -23.474586], [-24.386429, -21.067545], [10.366455, -20.889435], [-8.008604, 10.642828], [0.2046103, -0.32008448], [10.554625, -23.52794], [-27.847166, -22.307806], [16.289167, 24.779615], [17.888805, 23.487223], [-10.898158, 9.88265], [6.218405, -20.720823], [12.249046, -20.964548], [-21.533401, -19.669436], [-7.7874985, 7.188829], [-25.028368, -15.338505], [32.090492, -9.075057], [-28.155659, -22.947647], [28.784258, -9.313506], [21.438032, 25.772402], [-10.543739, 5.295614], [-21.465494, -21.173304], [-9.089599, 11.522259], [20.214724, 18.358177], [-7.6426835, 10.252953], [-10.710532, 15.765243], [-14.5252695, 8.687052], [-24.875635, -23.786013], [-4.43827, 9.379211], [5.888641, -16.96861], [20.763144, 27.545776], [-27.21829, -20.67809], [20.709501, 23.760117], [23.064472, 22.765865], [1.7626336, -4.265446], [-23.506048, -18.508024], [-11.783122, 15.141541], [-10.606146, 3.0557768], [-29.27284, -21.64707], [-11.603426, 13.514367], [-26.510849, -16.397713], [7.8984966, -24.88446], [10.763742, -19.058397], [-0.328442, 0.49709567], [21.924952, 22.134737], [-24.070852, -20.899239]]\n",
    "label=['KIRC', 'KIRC', 'BRCA', 'PRAD', 'BRCA', 'BRCA', 'BRCA', 'LUAD', 'KIRC', 'PRAD', 'BRCA', 'PRAD', 'COAD', 'LUAD', 'COAD', 'BRCA', 'PRAD', 'PRAD', 'KIRC', 'BRCA', 'BRCA', 'COAD', 'KIRC', 'KIRC', 'BRCA', 'BRCA', 'BRCA', 'BRCA', 'BRCA', 'BRCA', 'BRCA', 'KIRC', 'PRAD', 'BRCA', 'BRCA', 'LUAD', 'PRAD', 'BRCA', 'KIRC', 'KIRC', 'BRCA', 'PRAD', 'BRCA', 'BRCA', 'COAD', 'COAD', 'BRCA', 'BRCA', 'BRCA', 'BRCA', 'KIRC', 'LUAD', 'BRCA', 'KIRC', 'BRCA', 'PRAD', 'COAD', 'BRCA', 'PRAD', 'BRCA', 'COAD', 'LUAD', 'BRCA', 'LUAD', 'LUAD', 'COAD', 'BRCA', 'COAD', 'BRCA', 'KIRC', 'LUAD', 'PRAD', 'COAD', 'PRAD', 'KIRC', 'PRAD', 'KIRC', 'COAD', 'BRCA', 'PRAD', 'LUAD', 'BRCA', 'KIRC', 'BRCA', 'LUAD', 'LUAD', 'LUAD', 'BRCA', 'BRCA', 'KIRC', 'BRCA', 'PRAD', 'BRCA', 'BRCA', 'BRCA', 'BRCA', 'KIRC', 'PRAD', 'BRCA', 'PRAD', 'LUAD', 'BRCA', 'BRCA', 'BRCA', 'BRCA', 'KIRC', 'LUAD', 'BRCA', 'BRCA', 'BRCA', 'LUAD', 'BRCA', 'BRCA', 'KIRC', 'KIRC', 'BRCA', 'LUAD', 'BRCA', 'KIRC', 'KIRC', 'LUAD', 'BRCA', 'LUAD', 'LUAD', 'LUAD', 'LUAD', 'PRAD', 'BRCA', 'KIRC', 'PRAD', 'COAD', 'KIRC', 'BRCA', 'LUAD', 'KIRC', 'KIRC', 'BRCA', 'BRCA', 'LUAD', 'BRCA', 'BRCA', 'PRAD', 'PRAD', 'BRCA', 'COAD', 'LUAD', 'LUAD', 'KIRC', 'KIRC', 'PRAD', 'BRCA', 'LUAD', 'KIRC', 'BRCA', 'LUAD', 'KIRC', 'COAD', 'BRCA', 'LUAD', 'BRCA', 'LUAD', 'PRAD', 'KIRC', 'COAD', 'BRCA', 'BRCA', 'COAD', 'PRAD', 'KIRC', 'KIRC', 'BRCA', 'BRCA', 'KIRC', 'PRAD', 'PRAD', 'LUAD', 'LUAD', 'PRAD', 'COAD', 'BRCA', 'PRAD', 'KIRC', 'BRCA', 'KIRC', 'BRCA', 'BRCA', 'COAD', 'LUAD', 'BRCA', 'LUAD', 'KIRC', 'COAD', 'KIRC', 'BRCA', 'PRAD', 'PRAD', 'KIRC', 'LUAD', 'COAD', 'KIRC', 'LUAD', 'COAD', 'LUAD', 'BRCA', 'LUAD', 'COAD', 'PRAD', 'BRCA', 'BRCA', 'LUAD', 'KIRC', 'LUAD', 'BRCA', 'KIRC', 'BRCA', 'COAD', 'LUAD', 'BRCA', 'LUAD', 'BRCA', 'PRAD', 'PRAD', 'KIRC', 'BRCA', 'KIRC', 'LUAD', 'PRAD', 'PRAD', 'BRCA', 'LUAD', 'COAD', 'BRCA', 'BRCA', 'KIRC', 'LUAD', 'LUAD', 'BRCA', 'KIRC', 'BRCA', 'COAD', 'LUAD', 'PRAD', 'BRCA', 'KIRC', 'COAD', 'LUAD', 'LUAD', 'COAD', 'PRAD', 'BRCA', 'BRCA', 'KIRC', 'PRAD', 'BRCA', 'KIRC', 'BRCA', 'KIRC', 'BRCA', 'LUAD', 'LUAD', 'BRCA', 'PRAD', 'LUAD', 'COAD', 'KIRC', 'BRCA', 'COAD', 'BRCA', 'LUAD', 'COAD', 'BRCA', 'COAD', 'PRAD', 'COAD', 'COAD', 'BRCA', 'BRCA', 'COAD', 'LUAD', 'BRCA', 'LUAD', 'PRAD', 'COAD', 'PRAD', 'BRCA', 'BRCA', 'BRCA', 'LUAD', 'BRCA', 'KIRC', 'BRCA', 'KIRC', 'PRAD', 'PRAD', 'BRCA', 'BRCA', 'COAD', 'BRCA', 'PRAD', 'BRCA', 'PRAD', 'LUAD', 'KIRC', 'BRCA', 'PRAD', 'PRAD', 'BRCA', 'COAD', 'BRCA', 'LUAD', 'COAD', 'LUAD', 'BRCA', 'PRAD', 'PRAD', 'BRCA', 'PRAD', 'LUAD', 'LUAD', 'PRAD', 'LUAD', 'COAD', 'BRCA', 'PRAD', 'BRCA', 'BRCA', 'COAD', 'BRCA', 'BRCA', 'COAD', 'PRAD', 'BRCA', 'BRCA', 'LUAD', 'BRCA', 'KIRC', 'BRCA', 'BRCA', 'PRAD', 'PRAD', 'PRAD', 'COAD', 'LUAD', 'KIRC', 'KIRC', 'BRCA', 'KIRC', 'LUAD', 'BRCA', 'COAD', 'BRCA', 'LUAD', 'BRCA', 'BRCA', 'BRCA', 'LUAD', 'BRCA', 'BRCA', 'KIRC', 'KIRC', 'KIRC', 'PRAD', 'LUAD', 'BRCA', 'BRCA', 'KIRC', 'BRCA', 'KIRC', 'PRAD', 'LUAD', 'LUAD', 'BRCA', 'BRCA', 'PRAD', 'BRCA', 'KIRC', 'BRCA', 'LUAD', 'BRCA', 'PRAD', 'BRCA', 'KIRC', 'BRCA', 'COAD', 'LUAD', 'PRAD', 'KIRC', 'KIRC', 'KIRC', 'BRCA', 'BRCA', 'LUAD', 'BRCA', 'LUAD', 'BRCA', 'PRAD', 'KIRC', 'BRCA', 'BRCA', 'LUAD', 'KIRC', 'LUAD', 'BRCA', 'LUAD', 'BRCA', 'KIRC', 'PRAD', 'KIRC', 'PRAD', 'KIRC', 'LUAD', 'LUAD', 'KIRC', 'PRAD', 'PRAD', 'LUAD', 'KIRC', 'PRAD', 'KIRC', 'COAD', 'BRCA', 'KIRC', 'KIRC', 'BRCA', 'KIRC', 'KIRC', 'LUAD', 'BRCA', 'PRAD', 'LUAD', 'BRCA', 'LUAD', 'BRCA', 'KIRC', 'PRAD', 'BRCA', 'LUAD', 'KIRC', 'BRCA', 'BRCA', 'COAD', 'BRCA', 'BRCA', 'KIRC', 'PRAD', 'KIRC', 'BRCA', 'BRCA', 'BRCA', 'KIRC', 'PRAD', 'KIRC', 'KIRC', 'BRCA', 'LUAD', 'LUAD', 'BRCA', 'COAD', 'PRAD', 'KIRC', 'KIRC', 'KIRC', 'BRCA', 'KIRC', 'PRAD', 'PRAD', 'BRCA', 'KIRC', 'BRCA', 'KIRC', 'LUAD', 'BRCA', 'KIRC', 'BRCA', 'KIRC', 'COAD', 'LUAD', 'PRAD', 'LUAD', 'BRCA', 'BRCA', 'BRCA', 'LUAD', 'BRCA', 'COAD', 'COAD', 'BRCA', 'BRCA', 'BRCA', 'PRAD', 'BRCA', 'COAD', 'PRAD', 'BRCA', 'BRCA', 'KIRC', 'KIRC', 'BRCA', 'BRCA', 'BRCA', 'BRCA', 'BRCA', 'LUAD', 'COAD', 'COAD', 'PRAD', 'COAD', 'KIRC', 'LUAD', 'PRAD', 'KIRC', 'BRCA', 'KIRC', 'BRCA', 'BRCA', 'KIRC', 'KIRC', 'BRCA', 'KIRC', 'KIRC', 'PRAD', 'PRAD', 'LUAD', 'LUAD', 'LUAD', 'BRCA', 'BRCA', 'BRCA', 'PRAD', 'PRAD', 'COAD', 'BRCA', 'LUAD', 'KIRC', 'BRCA', 'LUAD', 'COAD', 'KIRC', 'BRCA', 'KIRC', 'PRAD', 'COAD', 'BRCA', 'PRAD', 'PRAD', 'BRCA', 'BRCA', 'PRAD', 'BRCA', 'BRCA', 'BRCA', 'LUAD', 'BRCA', 'BRCA', 'LUAD', 'PRAD', 'PRAD', 'KIRC', 'COAD', 'BRCA', 'BRCA', 'COAD', 'BRCA', 'KIRC', 'PRAD', 'BRCA', 'PRAD', 'BRCA', 'BRCA', 'PRAD', 'BRCA', 'KIRC', 'BRCA', 'KIRC', 'COAD', 'COAD', 'PRAD', 'BRCA', 'BRCA', 'PRAD', 'BRCA', 'KIRC', 'PRAD', 'PRAD', 'BRCA', 'LUAD', 'PRAD', 'LUAD', 'KIRC', 'BRCA', 'PRAD', 'BRCA', 'COAD', 'LUAD', 'LUAD', 'LUAD', 'PRAD', 'LUAD', 'BRCA', 'BRCA', 'LUAD', 'PRAD', 'KIRC', 'KIRC', 'BRCA', 'LUAD', 'LUAD', 'PRAD', 'BRCA', 'PRAD', 'COAD', 'PRAD', 'COAD', 'KIRC', 'BRCA', 'PRAD', 'BRCA', 'KIRC', 'BRCA', 'BRCA', 'BRCA', 'PRAD', 'BRCA', 'LUAD', 'KIRC', 'PRAD', 'KIRC', 'KIRC', 'LUAD', 'PRAD', 'BRCA', 'BRCA', 'PRAD', 'BRCA', 'PRAD', 'LUAD', 'LUAD', 'BRCA', 'KIRC', 'PRAD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvVRoAy0gjTL"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    در زیر نمونه ها را بدون برچسب هایشان رسم میکنیم و به طور شهودی میتوان دید داده ها به 5 خوشه ی مجزا قابل تفکیک اند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1XLOkHjgjTM",
    "outputId": "dad11ec2-ed00-44d3-bc86-d20c1963da54"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plotting data wrt. its features\n",
    "X=np.array(data)\n",
    "A=X.T[0]\n",
    "B=X.T[1]\n",
    "plt.scatter(A,B)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MciG2h4egjTM"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    سپس یک مدل kmeans با تعداد 5 خوشه را روی این داده ها آموزش میدهیم و اندیس خوشه ای که هر نمونه به آن منتسب شده را نمایش میدهیم.\n",
    "    <br>\n",
    "  توجه کنید که اندیس خوشه را با برچسب داده اشتباه نگیرید. ما روی داده ها برچسب نزده ایم که هرکدام به چه نوع سرطانی تعلق دارند. صرفا نمونه ها را خوشه بندی کردیم و گفتیم هر کدام متعلق به کدام خوشه هستند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1J6uxPuVgjTN",
    "outputId": "cf5249ea-3fce-43d9-9cdd-63c9d98ebf7b"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5).fit(data)\n",
    "y_pred=kmeans.predict(data)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnm-GzsVgjTN"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    نمونه ها را با توجه به خوشه هایشان رنگ آمیزی میکنیم، مراکز خوشه نیز در نمودار نشان داده شده اند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhni0KiZgjTN",
    "outputId": "85a03186-d610-415d-f7de-5f0c80527458"
   },
   "outputs": [],
   "source": [
    "A=np.array(data).T[0]\n",
    "B= np.array(data).T[1]\n",
    "plt.scatter(A,B, c =y_pred)\n",
    "plt.scatter( kmeans.cluster_centers_.T[0], kmeans.cluster_centers_.T[1],color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKZ4PqIegjTO"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    مراکز خوشه ها از طریق ` kmeans.cluster_centers_` قابل دسترسی هستند. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BNgFXENgjTO",
    "outputId": "535c08c3-ef4a-41ac-8527-273c3e1b32ab"
   },
   "outputs": [],
   "source": [
    " kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNvak-1vgjTO"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "   هم چنین میتوانیم برای داده های جدید مشخص کنیم به کدام خوشه متعلق اند. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IQ2OyNbgjTO",
    "outputId": "2ca55d0d-82d4-4b38-e78c-044e72c58e17"
   },
   "outputs": [],
   "source": [
    "X_new = np.array([[0, 2], [15, 25], [-30, -15], [10,-10]])\n",
    "kmeans.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXceyMyegjTP"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "  **نکته** : به جای اینکه به طور سخت تعیین کنیم هر نمونه متعلق به کدام خوشه است، میتوان فاصله ی آن ها با مراکز خوشه ها را نمایش داد به نوعی هرچقدر فاصله ی نمونه با مرکز خوشه ای کمتر از فاصله اش با سایر مرکز خوشه ها باشد، احتمال قرار گرفتنش در آن خوشه نسبت به دیگر خوشه ها بیشتر است و این یک رویکرد برای خوشه بندی نرم خواهد بود.\n",
    "    <br>\n",
    "    در ماتریس فاصله های زیر، میتوان هر سطر را به مجموع آن سطر تقسیم کرد و احتمالاتی بین 0 و 1 نیز داشت."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQp8BUpWgjTP",
    "outputId": "de21f9f1-417b-4cef-c7fd-e5c6cabc235f"
   },
   "outputs": [],
   "source": [
    "kmeans.transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdmMBfNHgjTP"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    چون در مثال ما برچسب ها را داشتیم دست به یک آزمایش میزنیم، در نهایت برچسب واقعی داده ها را نمایش میدهیم تا به یک شهود برسیم که واقعا هر خوشه ی یافت شده یک گونه ی سرطان متفاوت بوده است و میتوان نتیجه گرفت در کاربرد های واقعی هر خوشه میتواند تفاوت معناداری با سایر خوشه ها داشته باشد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wk7yugSjgjTP",
    "outputId": "c343ea32-2eca-4118-aff3-0606677c852a"
   },
   "outputs": [],
   "source": [
    "col={\"BRCA\":\"blue\", \"KIRC\":\"red\", \"COAD\":\"green\", \"LUAD\":\"yellow\" , \"PRAD\":\"black\"}\n",
    "YC=[]\n",
    "for i in range(len(label)):\n",
    "    YC.append(col[label[i]])\n",
    "plt.scatter(A,B, c =YC)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGox2PdmgjTQ"
   },
   "source": [
    "\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-3\">\n",
    "<font color=\"red\" size=4>**2-3.مقداردهی اولیه ی مراکز خوشه ها**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuGmAyykgjTQ"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "یک چالش پیش رو در استفاده از این الگوریتم این است که هرچند الگوریتم تضمین می‌کند همگرا شود، نمبتواند تضمین کند که به بهترین پاسخ (بهینه‌ی سراسری) همگرا می‌شود و پاسخ الگوریتم می‌تواند بسته به مقدار دهی اولیه‌ی مرکز خوشه‌ها می‌تواند متفاوت باشد و به بهینه‌های محلی همگرا شود.\n",
    "<br>\n",
    "<br>\n",
    "برای روبرویی با این چالش چند روش برای مقداردهی اولیه‌ی مرکز خوشه‌ها پیشنهاد شده است که در ادامه مورد بررسی قرار می‌دهیم.\n",
    "<br>\n",
    "    <br>\n",
    "**الف)** اگر به طریقی یک تقریب از مرکز خوشه‌ها داشته باشیم که از حالت رندوم بهتر باشد (مثلاً قبلاً یک الگوریتم خوشه‌بندی دیگر را اجرا کرده باشیم) می‌توانیم به طور دستی آن را به جای مقادیر رندوم، به عنوان مقادیر اولیه‌ی مراکز خوشه‌ها ست کنیم. به این منظور میتوان مراکز خوشه پیشنهادی را در یک np.array ذخیره کرد و با استفاده از هایپرپارامتر `init` مقدار اولیه ی مراکز خوشه را ست کرد. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nCVG6vzgjTQ"
   },
   "outputs": [],
   "source": [
    "good_init = np.array([[8, -20], [-8, 7], [19, 25], [-25, -20], [30, -10]])\n",
    "kmeans = KMeans(n_clusters=5, init=good_init, n_init=1).fit(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1N1_yeVgjTQ"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "**ب)** راه حل دیگر این است که الگوریتم‌ها به تعداد دفعات معین اجرا کنیم و از میان آن‌ها بهترین پاسخ را انتخاب کنیم. واضح است برای انجام این کار نیاز داریم معیاری برای مقایسه‌ی عملکرد داشته باشیم (performance metric)تا بتوانیم بهترین آن‌ها را انختاب کنیم. به این معیار model interia گفته می‌شود که عبارت است از میانگین مجذورات فاصله بین داده‌ها و مرکز خوشه‌هایشان است که طبیعتا هرچقدر این مقدار کمتر باشد یعنی مدل بهتر بوده. \n",
    "به این منظور میتوان هایپرپارامتر `n_init` را به تعداد دفعاتی که میخواهیم الگوریتم اجرا شود ست کنیم.\n",
    "<br>\n",
    "<br>\n",
    "    توجه : اگر این هایپرپارامتر را ست نکنیم مقدار پیش فرض آن 10 خواهد بود.\n",
    "    <br>\n",
    "    **نکته**: با استفاده از `kmeans.inertia_` میتوان به inertiaی مدل نهایی دست پیدا کرد. هم چنین `score` برای داده ای که خوشه بندی روی آن انجام شده همواره برابر با -inertia خواهد بود. زیرا score طبق تعریف باید اینگونه باشد که بیشتر بودنش به معنای بهتر بودنش باشد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7glCQZzgjTR",
    "outputId": "570e511e-1e9e-438d-d677-fd393fc11c03"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, n_init=20).fit(data)\n",
    "print(\"Interia:\",kmeans.inertia_,\"     Score:\",kmeans.score(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRLiHQ4YgjTR"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-4\">\n",
    "<font color=\"red\" size=4>**2-4.بهبودهای K-means**</font>\n",
    "   <br>\n",
    "    <br>\n",
    "    <font face=\"XB Zar\" size=4><div dir=rtl id=\"2-4-1\">\n",
    "<font color=\"red\" size=4>2-4-1.K-means++</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IB9XYzcxgjTR"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "یکی از بهترین بهبودهای پیشنهاد شده برای kmeans الگوریتم  kmeans++است که با داشتن یک روش هوشمندانه‌تر برای مقدار دهی اولیه‌ی مراکز خوشه می‌تواند احتمال رسیدن به پاسخ‌های sub-optimal را افزایش دهد. ایده‌ی کلی این است که مراکز خوشه به گونه ای انتخاب شوند که از یکدیگر دور باشند. نشان داده شده اجرای این بخش به طرز شایان توجهی تعداد دفعات اجرای الگوریتم برای رسیدن به جواب بهنیه را کم می‌کند و از همین جهت محاسبات اضافه‌ی لازم برای این مقداردهی اولیه، ارزشمند است.\n",
    "<br>\n",
    "<br>\n",
    "الگوریتم به شکل زیر عمل می‌کند:\n",
    "<br>\n",
    "یک نمونه‌ی رندوم را به عنوان مرکز خوشه‌ی اول $c^{(1)}$ انتخاب کن\n",
    "<br>\n",
    "تا  زمانی که تمام k مرکز خوشه انتخاب شوند :\n",
    "<br>\n",
    "نمونه‌ی $x^{(i)}$ را با احتمال $D(x^{(i)})^2/sum_{j=1}^{m} D(x^{(j)})^2 $ به عنوان مرکز خوشه‌ی بعدی $c^{(i)}$ انتخاب کن. که $D(x^{(i)})$ فاصله‌ی نمونه‌ی $x^{(i)}$ با نزدیک‌ترین مرکز خوشه‌ی تا به حال انتخاب شده است.\n",
    "<br>\n",
    "    <br>\n",
    "مشخص است که سیاست در انتخاب مرکز خوشه‌ها به گونه ای است که نمونه‌هایی که از مراکز خوشه‌های فعلی انتخاب شده فاصله‌ی بیشتری را دارند، به مراتب احتمال بیشتری برای انتخاب شدن دارند.\n",
    "<br>\n",
    "    <br>\n",
    "K-means استفاده شده در کدهای بالا به طور پیش فرض از همین روش برای مقدار دهی اولیه استفاده می‌کند، درصورت نیاز به مقدار دهی اولیه‌ی رندم باید هایپرپارامتر `init` را برابر با `random` ست کنیم.\n",
    "<br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOMhZgRqgjTS"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-4-2\">\n",
    "<font color=\"red\" size=4>2-4-2.K-means تسریع شده</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o83knTX3gjTS"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "این الگوریتم با تلاش برای عدم انجام محاسبات غیر ضروری تا حد قابل توجهی الگوریتم اصلی را تسریع می‌کند. \n",
    "<br>\n",
    "رویکرد کلی استفاده از نامساوی مثلثی و در نظر گرفتن کران‌های بالا و پایین برای فاصله‌ی نمونه‌ها و مراکز خوشه است.\n",
    "<br>\n",
    "kmeans استفاده شده در کدهای بالا به طور پیش فرض از همین روش استفاده می‌کند، درصورت نیاز به اجرای الگوریتم به روش اصلی، باید هایپرپارامتر `algorithm` را برابر با `full` ست کنیم.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HJdcPkagjTS"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-4-3\">\n",
    "<font color=\"red\" size=4>2-4-3.mini-batch K-means</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aje2qCUxgjTS"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "این الگوریتم k means را قادر می‌سازد به جای استفاده از تمام نمونه‌ها در هر iteration، فقط از یک دسته یا mini batch از داده‌ها برای آپدیت کردن و جابجا کردن مراکز خوشه استفاده کند که در حدود 3 تا 4 بار الگوریتم را تسریع می‌کند. هم چنین استفاده از Mini batch این مزیت را دارد که الگوریتم برای داده‌های عظیم که برای جا شدن تمام نمونه هایشان در مموری مشکل دارند نیز قابل اجرا خواهد بود.\n",
    "به این منظور به شکل زیر عمل میکنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slB4VDorgjTS",
    "outputId": "b3187f83-519b-4bf8-d27f-3c513d7c4175"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=5)\n",
    "minibatch_kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HIEJPLDgjTT"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "هرچند، استفاده از mini batch باعث افزایش سرعت بسیار زیادی می‌شود؛ اما در اکثر مواقع inertia به مقدار کمی نسبت به حالت عادی بیشتر خواهد بود. این تفاوت خصوصاً با افزایش تعداد خوشه‌ها نمایان‌تر می‌شود.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNJVuHtXgjTT"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-5\">\n",
    "<font color=\"red\" size=4>**2-5.انتخاب تعداد خوشه‌ها**</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwNFautRgjTT"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "تا اینجا ما فرض کردیم تعداد خوشه‌ها را میدانیم و در مثال‌های فوق تعداد خوشه‌ها از نگاه کردن به نمونه‌ها قابل تشخیص بود؛ اما برای کاربردهای واقعی این موضوع صادق نخواهد بود. اگر k بیش از حد زیاد یا کم انتخاب شود خوشه‌بندی مناسبی را نخواهیم داشت پس مهم است روشی برای یافتن مقدار مناسب k داشته باشیم.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-GkalGPgjTT"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-5-1\">\n",
    "<font color=\"red\" size=4>2-5-1.استفاده از inertia</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsUOgwyhgjTT"
   },
   "source": [
    "![](https://media.geeksforgeeks.org/wp-content/uploads/20190606105550/distortion1.png)\n",
    "\n",
    "<a href=\"https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/\">pic source</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmc3DLCMgjTT"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "ممکن است در ابتدا اینگونه به نظر برسد که k ای که منجر به مدلی با inertia کمتر شود، k مناسب تری خواهد بود؛ اما متاسفانه این موضوع درست نیست. هرچقدر k یا همان تعداد خوشه‌ها افزایش یابد، Inertia کاهش میابد؛ زیرا تعدا مراکز خوشه بیشتر خواهد بود و فاصله‌ی هر نمونه با نزدیک‌ترین مرکز خوشه اش کمتر خواهد شد تا حدی که اگر به اندازه‌ی تعداد نمونه‌ها خوشه داشته باشیم هر نمونه مرکز خوشه‌ی خود خواهد بود و Inertia=0 را خواهیم داشت. پس کم‌تر بودن Inertia به معنای k مناسب‌تر نیست.\n",
    "<br>\n",
    "<br>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "به نمودار بالا دقت کنید علاوه بر اینکه با افزایش تعداد خوشه‌ها Inertia کاهش میابد یک موضوع دیگر را نیز می‌توان از نمودار برداشت کرد. از مقدار k=1 to 4 مقدار inertia با شدت چشمگیری در حال کاهش است در حالی که بعد از 4 کاهش بسیار آهسته‌تر می‌شود. این بدان معناست که کاهش inertia از 4 به بعد تنها به دلیل افزایش تعداد خوشه هاست اما از قبل از آن این تفاوت معنی دار بوده است و در واقع افزایش تعداد خوشه‌ها در آن مراحل gain زیادی برای ما دارد. در واقع نمودار به شکل یک دست خواهد بود که قسمت شکستگی نمودار که شبیه آرنج است (یعنی جایی که شدت کاهش کم می‌شود) می‌تواند انتخاب خوبی برای تعداد خوشه‌ها باشد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2Az0RaygjTT"
   },
   "source": [
    "\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-5-2\">\n",
    "<font color=\"red\" size=4>2-5-2.silhouette score </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1Dsu4AzgjTU"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "یک روش دقیق‌تر و البته با محاسبات بیشتربرای تعیین بهترین تعداد خوشه، استفاده از silhouette score است.\n",
    "<br>\n",
    "Silhouette score برابر است با میانگین silhouette coefficient روی تمام نمونه‌ها.\n",
    "<br>\n",
    "$Silhouette-coefficient = {(b-a)}/{max(a,b)}$\n",
    "<br>\n",
    "که در آن a میانگین فاصله‌ی نمونه با تمام نمونه‌های هم خوشه اش است (میانگین فاصله‌ی درون خوشه ای) و b میانگین فاصله‌ی نمونه با نمونه‌های نزدیک‌ترین خوشه است (درواقع b کمترین میانگین فاصله با نمونه‌های خوشه‌های دیگراست).\n",
    "<br>\n",
    "    <br>\n",
    "مقدار silhouette coefficient می‌تواند بین+1 و -1 باشد که مقدار نزدیک به +1 نشان می‌دهد نمونه به نمونه‌های درون خوشه‌ی نسبت یافته اش نزدیک و از نمونه‌های سایر خوشه‌ها دور است که در واقع یعنی به درستی خوشه اش انتخاب شده و مقدار نزدیک به -1 می‌تواند بیانگر این باشد که نمونه به خوشه‌ی اشتباهی نسبت داده شده است.\n",
    "<br>\n",
    "  به شکل زیر میتوان silhouette score برای داده ها را محاسبه کرد. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmqCE-L1gjTU",
    "outputId": "f08e6dbe-74c3-4f31-eaad-cfcd37a7e62a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_score(data, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VW1RJSasgjTU"
   },
   "source": [
    "![](https://aiaspirant.com/wp-content/uploads/2019/07/Silhouette.png)\n",
    "\n",
    "\n",
    "<a href=\"https://aiaspirant.com/optimal-k-in-k-menas/\">pic source</a>\n",
    "\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "به این ترتیب می‌توانیم Silhouette score را برای k های متفاوت محاسبه و مقایسه کنیم و Silhouette score بیشتر به معنای k مناسب‌تر خواهد بود. هم چنین استقاده از Silhouette score بر خلاف inertia به ما این امکان را می‌دهد که دو k ی دلخواه را نسبت به هم مقایسه کنیم (در روش قبل فقط k بهینه را با استفاده از محل شکستگی پیدا می‌کردیم).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN163iOPgjTU"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "علاوه بر نمایش silhouette score به ازای k های مختلف می‌توان از silhouette diagram نیز استفاده کرده که در آن silhouette coefficient برای تمام نمونه‌ها به ترتیب شماره‌ی خوشه شان و سپس ترتیب بزرگی silhouette coefficient نمایش داده می‌شود. خط عمودی در این نمودار نیز silhouette score به ازای k ای است که خوشه‌بندی با ان انجام شده."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soNHs9zogjTU"
   },
   "source": [
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_kmeans_silhouette_analysis_003.png)\n",
    "\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\">pic source</a>\n",
    "\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    " اگر silhouette coefficient خوشه‌هایی با خط عمودی فاصله داشته باشند نشان دهنده‌ی این است که خوشه‌بندی بد انجام شده و خوشه از دیگر خوشه‌ها فاصله‌ی کافی ندارند.\n",
    "<br>\n",
    "<br>\n",
    "نکته : از این نمودار میشود اندازه ی نسبی خوشه ها نسبت به یکدیگر را نیز دید. در شرایطی که برای دو k شرایط تقریبا یکسان بود یک انتخاب خوب میتواند انتخاب k ای باشد که با استفاده از آن اندازه ی خوشه ها در آن هم اندازه تر هستند."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKtienFIgjTU"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-5-3\">\n",
    "<font color=\"red\" size=4>2-5-3.DB index </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pzh10tDugjTV"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "یک روش دیگه برای سنجیدن کیفیت خوشه بندی انجام شده Davies-Bouldin index است.\n",
    "<br>\n",
    "تعاریف زیر را در نظر بگیرید:\n",
    "<br>\n",
    "<br>\n",
    "پراکندگی خوشه :  میتواند به صورت یک انحراف معیار تعمیم یافته تعبیر شود.\n",
    "<br>\n",
    "<div dir=ltr>\n",
    "$\\delta_k:= \\sqrt{\\frac{1}{N_k}\\sum_{x_n\\in c_k}||x_n-c_k||^2}$\n",
    "<br>\n",
    "<br>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "شباهت خوشه ها : دو خوشه شبیه در نظر گرفته میشوند اگر نسبت به فاصله شان پراکندگی زیادی داشته باشند.\n",
    "<br>\n",
    "<div dir=ltr>\n",
    "$S_{kl}:=\\frac{\\delta_k+\\delta_l}{||c_k-c_l||}$\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "<br>\n",
    "<br>\n",
    "با توجه به تعاریف بالا میتوان دید  DB-index  که به صورت زیر تعریف میشود میتواند معیار خوبی برای سنجش کیفیت خوشه بندی باشد.\n",
    "<br>\n",
    "<div dir=ltr>\n",
    "$V_{DB}:=\\frac{1}{k}\\sum_{k=1}^K \\underset{l\\neq k}{max}S_{kl}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJZz02kCgjTV"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2-6\">\n",
    "<font color=\"red\" size=4>**2-6.محدودیت‌های k-means** </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCfaM43cgjTV"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "علی رغم ویژگی‌های مثبت kmeans مانند سریع و مقیاس پذیر بودنش، این الگوریتم محدودیت‌های قابل توجهی دارد از جمله:\n",
    "<br>\n",
    "-\tوابستگی به مقدار اولیه و نیاز به چندین بار اجرا با مقادیر اولیه متفاوت\n",
    "-\tنیاز به مشخص کردن تعداد خوشه‌ها\n",
    "-\tمشکل در خوشه‌بندی نمونه‌هایی که خوشه‌هایشان هم اندازه نیستند\n",
    "-\tمشکل در خوشه‌بندی نمونه‌هایی که چگالی خوشه‌ها در آن متفاوت است\n",
    "-\tمشکل در خوشه‌بندی نمونه‌هایی که خوشه‌ها فرم غیر کروی (غیر دایره ای) دارند\n",
    "<br>\n",
    "<br>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "نکته: برای مشکل آخر، می‌توان با استفاده از اسکیل کردن ویژگی‌ها، فرم خوشه‌ها را به فرم کروی نزدیک‌تر کرد. هرچند تضمین صد در صدی وجود نداره که اسکیل کردن ویژگی‌ها تمام خوشه‌ها را ایده آل کند؛ اما معمولاً باعث بهبود عملکرد می‌شود.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1-PcyVdgjTV"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"3\">\n",
    "<font color=\"red\" size=5>**3.کاربردهای خوشه بندی** </font>\n",
    "    <br>\n",
    "    <br>\n",
    "    <font face=\"XB Zar\" size=4><div dir=rtl id=\"3-1\">\n",
    "<font color=\"red\" size=4>**3-1. Image Segmentation** </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhttenIngjTW"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "هدف کلی Image segmentation این است که یک تصویر به بخش‌هایی تقسیم شود که هرکدام از این بخش‌ها یک موجودیت مجزای مورد نظر باشد. مثال: تشخیص موانع در اتوموبیل های خودران\n",
    "<br>\n",
    "<br>\n",
    "هرچند مدل‌های Image segmentation برای مثال‌هایی مانند اتوموبیل خودران می‌توانند بسیار پیچیده باشد و به عنوان مثال نیاز به شبکه‌های عصبی و ... باشد، در موارد ساده‌تر می‌توان رویکرد ساده تری به نام Color segmentation را استفاده کرد. در این رویکرد ما بخش‌هایی از تصویر را که رنگ تقریباً مشابهی دارند به عنوان یک گروه مجزا (یک خوشه) جدا می‌کنیم و پیش فرض ما این است که قسمت‌های همرنگ تصویر احتمالاً متعلق به یک موجودیت هستند. \n",
    "<br>\n",
    "<br>\n",
    "این رویکرد ساده در برخی مثال‌ها می‌تواند راهگشا باشد برای مثال تشخیص اینکه چند درصد از یک تصویر ماهواره ای از زمین، جنگل و چند درصد اقیانوس است. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsFKA5U6gjTW"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    بیایید مثال تشحیص درصد اقیانوس و جنگل را اجرا کنیم. در مثال زیر ما یک تصویر ماهواره ای داریم و با استفاده از خوشه بندی در واقع هر پیکسل از تصویر را به یک خوشه اختصاص میدهیم که از نظر رنگ کمترین فاصله را با مرکز خوشه اش دارد و سپس تمام اعضای هر خوشه را با میانگین مقدار خوشه جایگزین میکنیم. \n",
    " <br>\n",
    "    لود کردن تصویر و نمایش  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "ul3jym3UgjTW",
    "outputId": "38996b25-c140-4fd2-e6d0-4b277ffe3c50"
   },
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image = imread(\"./map.jpg\")\n",
    "\n",
    "plt.imshow((image).astype(np.uint8))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drtLAwQcgjTW"
   },
   "source": [
    "<a href=\"http://www.deviantart.com/giresun/art/turkey-satellite-view-18839885\">pic source</a>\n",
    "\n",
    "\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    خوشه بندی تصویر با k=3 (با دانش قبلی که تصویر ماهواره ای اصولا از سه بخش خشکی آب و جنگل تشکیل شده) و سپس جاگذاری هر پیکسل با میانگین مقدار خوشه اش:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ea-eAkhBgjTX"
   },
   "outputs": [],
   "source": [
    "X = image.reshape(-1, 3)\n",
    "kmeans = KMeans(n_clusters=3).fit(X)\n",
    "segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
    "segmented_img = segmented_img.reshape(image.shape)\n",
    "colors=kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7VYd9xDgjTX"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    نمایش تصویر پس از خوشه بندی\n",
    "    میتوان دید به خوبی جنگل ها در یک خوشه، آب ها در یک خوشه و خشکی ها در یک خوشه قرار گرفتند."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLUPAzQKgjTX",
    "outputId": "113c2008-eee0-46e8-b70d-abce72d4a41a"
   },
   "outputs": [],
   "source": [
    "out = segmented_img\n",
    "plt.imshow((out).astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6re_emGgjTY"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    نمایش درصد هر خوشه :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnGliKJ_gjTY",
    "outputId": "c57a8380-a00a-481e-c6a4-68477ae364a5"
   },
   "outputs": [],
   "source": [
    "l=list(colors)\n",
    "print(\"Cluster0:\",l.count(0)/len(l),\"%\\nCluster1:\",l.count(1)/len(l),\"%\\nCluster2:\",l.count(2)/len(l),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WxbBRdGgjTY"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    **نکته**: همانطور که گفته شد ما تعداد خوشه هارا با استفاده از کاربرد خود و دانش قبلی انتخاب کردیم. در مثال های دیگر نیز باید با بررسی های قبلی تعداد خوشه ها را انتخاب کنیم. اگر تعداد خوشه ها کم باشد دو موجودیت مجزا در تصویر که میخواستیم تفکیکشان کنیم در یک دسته قرار خواهند گرفت مثلا اگر تعداد خوشه ها در بالا 2 باشد جنگل و آب ها در یک خوشه ادغام شده و نمیتوانیم درصد آن ها را مشخص کنیم. مشخص است که اگر خوشه ها بیش از حد زیاد انتخاب شوند نیز مطلوب نیست."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHfjqfMPgjTZ"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"3-2\">\n",
    "<font color=\"red\" size=4>**3-2. پیش پردازش داده‌ها** </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O5LAjPkgjTZ"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "یکی از پیش پردازش‌های مهم **کاهش ابعاد** است. ما با کاهش ابعاد سعی می‌کنیم ابعاد داده‌های خود را کمتر کنیم به گونه ای که داده در ابعاد کمتر همچنان اطلاعات کافی برای بیان داده‌ها را دارا باشد به همین علت اصولاً داده‌ها در ابعاد پایین‌تر، اطلاعات نامفید و اضافی که ممکن است داده‌ی اولیه داشته باشد را نخواهند داشت و البته طبیعتا بخشی از اطلاعات اصلی داده را از دست میدهند که اگر متد ما خوب نباشد آن بخش ها میتواند بخش های مفیدی بوده باشند.\n",
    "<br>\n",
    "<br>\n",
    "یک روش کاهش ابعاد استفاده از خوشه‌بندی است به این شکل که ما داده‌ها را خوشه‌بندی کنیم و هر داده را با وکتور فاصله اش از تمام مرکز داده‌ها جایگزین کنیم(در مثال های بالا دیدیم که میتوان فاصله ی هر نمونه با مرکز خوشه را پس از خوشه بندی داشت). به این شکل ابعاد داده‌ی خود را از بعد اولیه‌ی n به k که تعداد خوشه هاست کاهش دادیم (n>k) و میدانیم این بیان جدید داده معنا دار است؛ چون هر خوشه داده‌های شبیه به هم را در خود دارد و فاصله از هر خوشه بیانگر شباهت یا تفاوت نمونه نسبت به نمونه‌ی سایر خوشه هاست و درواقع این بیان جدید از داده‌ها، دور یا نزدیک بودن آن‌ها نسبت به هم و ارتباطشان نسبت به یکدیگر را در خود حفظ کرده است.\n",
    "<br>\n",
    "<br>\n",
    "مزیت کاهش ابعاد داده‌ها این است که اولاً حجم داده‌ها کم می‌شود و منابع لازم برای محاسبات و ذخیره سازی داده‌ها کمتر خواهد بود و دوما اینکه اگر از روش خوبی برای کاهش ابعاد استفاده شده باشد همانطور که گفته شد اطلاعات غیرضروری در داده‌های کاهش بعد داده شده نخواهند بود و وقتی مدل برا آموزش داده‌های با کیفیت تری در اختیار داشته باشد طبیعتاً عملکرد بهتری خواهد داشت.\n",
    "<br>\n",
    "<br>\n",
    "بعد از کاهش ابعاد داده‌ها با استفاده از خوشه‌بندی می‌توان از آن‌ها برای آموزش یک مدل به طور با ناظر (با فرض موجود بودن برچسب داده‌ها) استفاده کرد.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMrjAR5DgjTZ"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    در مثال های زیر از دیتابیس ارقام دست نویس از دیتاست های موجود در sklearn.datasets استفاده شده است که در آن هر نمونه یک تصویر 8*8 از یک رقم دست نویس است.\n",
    "    <br>\n",
    "    لود کردن دیتابیس و نمایش یکی از نمونه های آن :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uX0JvBmMgjTZ",
    "outputId": "d143e0b5-ebd4-4518-df8a-84b882273d95"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "\n",
    "X_digits.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zP7PCKjgjTa",
    "outputId": "6dc971dc-a779-41e4-8049-46bd908b0d26"
   },
   "outputs": [],
   "source": [
    "i=402\n",
    "X=X_digits[i].reshape(8,8)\n",
    "plt.imshow(X,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e1z9WwKgjTa"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    همانطور که در بالا دیده شد هر نمونه یک تصویر 8*8 است یعنی هر نمونه 64 پیکسل یا ویژگی دارد. (در shape داده نیز این موضوع مشخص است)\n",
    "    <br>\n",
    "    <br>\n",
    "    حال با kmeans داده ها را با k=20 خوشه بندی میکنیم و به ازای هر نمونه به جای خود نمونه، فاصله اش از مراکز خوشه ها را جایگزین میکنیم.\n",
    "    <br>\n",
    "    در واقع هر نمونه ی 64 پیکسلی با یک آرایه 20 عنصری جایگزین میشود یعنی ابعاد ویژگی ها را از 64 به 20 کاهش داده ایم.\n",
    "    <br>\n",
    "    <br>\n",
    "    توجه: هرچند شاید به نظر برسد تعداد خوشه ها باید 10 باشد و 10 خوشه برای بیان داده ها کافی است، این موضوع را مد نظر داشته باشید که هر رقم به شکل های متفاوتی نوشته میشود پس ممکن است با 10 خوشه به نتیجه خوبی نرسیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1k7jH2IrgjTa",
    "outputId": "dfb970c1-0991-4aa9-d006-35531c71c8cf"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=20).fit(X_digits)\n",
    "kmeans.transform(X_digits).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGu8fzZlgjTa"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    بخشی از داده های کاهش بعد داده شده را به عنوان تست و بخش دیگر را به عنوان داده های آموزش جدا میکنیم و یک مدل logistic regression روی آن آموزش میدهیم.\n",
    "    <br>\n",
    "    میتوان دید علی رغم اینکه داده ها را کاهش بعد داده بودیم به دقت خوبی رسیدیم. کاهش بعد طبیعتا سرعت آموزش را بالا میبرد زیرا مدل پارامتر های کمتری خواهد داشت. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJ2Yf3srgjTa",
    "outputId": "5710969c-ef39-4719-cda3-cef170c6dc37"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(kmeans.transform(X_digits), y_digits)\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh3SR4CkgjTb"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"3-3\">\n",
    "<font color=\"red\" size=4>**3-3. Semi-Supervised learning** </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nbgJQjrgjTb"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "وقتی تعداد زیادی داده‌ی بدون برچسب داریم می‌توانیم از روش‌های یادگیری بدون ناظر استفاده کنیم. اما برای تسک‌هایی مانند  کلاس بندی نیاز داریم داده‌ها برچسب داشته باشند و از آنجا که نمی‌توانیم تمام داده‌ها را برچسب بزنیم (به دلیل هزینه بر بودن) مجبوریم تعداد کمی از آن‌ها را به نحوی انتخاب کنیم و فقط آن ها را برچسب زده و برای آموزش استفاده کنیم. می‌توان حدس زد اگر به طور کاملاً رندوم بخش نسبتا \n",
    "  کمی از داده‌ها را برچسب بزنیم و از آنها برای آموزش مدل استفاده کنیم نتیجه‌ی مطلوبی نخواهیم داشت.(در مثال زیر 50 نمونه از کل داده های ارقام دست نویس)\n",
    "    <br>\n",
    "    <br>\n",
    "    توجه : منظور از برچسب گذاری باید این باشد که ما پس از انتخاب نمونه ها به طور دستی تک به تک آن ها را ببینیم و برچسب آن ها را به طور دستی مشخص کنیم اما چون در  مثال ها در ادامه برچسب همه داده ها از قبل موجود است ما صرفا برچسب نظیر داده های انتخابی را به عنوان برچسبشان برای آموزش استفاده میکنیم. توجه کنید در یک مثال semi-supervised دنیای واقعی برچسب ها را در ابتدا نداریم و باید خودمان برچسب داده های انتخاب شده را مشخص کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yd4yky3gjTb",
    "outputId": "436298a3-f3b6-40a8-c291-5bad158ed419"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits)\n",
    "n_labeled = 50\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train[:n_labeled], y_train[:n_labeled])\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rV_CjPcjgjTb"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "اینجا این ایده مطرح می‌شود که با استفاده از یک روش بدون ناظر (در اینجا خوشه‌بندی) از تمام داده‌ها استفاده کنیم و سپس از نتایج آن استفاده کنیم تا داده‌هایی را برای برچسب زدن انتخاب کنیم که شامل اطلاعات مفید تری باشند.\n",
    "<br>\n",
    "<br>\n",
    "یک روش این است که داده‌ها را خوشه‌بندی کنیم و سپس نزدیک‌ترین نمونه به مرکز هر خوشه را به عنوان نمیانده ی آن خوشه انتخاب کنیم. سپس نماینده‌های هر خوشه را به طور دستی برچسب گذاری کنیم و از آن‌ها به عنوان داده برای یادگیری با ناظر خود استفاده کنیم.\n",
    "<br>\n",
    "<br>\n",
    "    در مثال زیر با k=50 خوشه بندی را انجام داده و سپس نماینده ی هر خوشه را نمایش داده ایم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLUXJcJAgjTc"
   },
   "outputs": [],
   "source": [
    "k = 50\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "X_digits_dist = kmeans.fit_transform(X_train)\n",
    "representative_digit_idx = np.argmin(X_digits_dist, axis=0)\n",
    "X_representative_digits = X_train[representative_digit_idx]\n",
    "Y_representative_digits = y_train[representative_digit_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixOrpOfYgjTc",
    "outputId": "e9464c25-98c6-418c-d617-d713274bbbcf"
   },
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    X=X_representative_digits[i].reshape(8,8)\n",
    "    plt.imshow(X,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_jyjnRD7gjTc",
    "outputId": "8eededa2-5d39-47ba-d8e3-8a9d1db0af30"
   },
   "outputs": [],
   "source": [
    "Y_representative_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFnVarLhgjTc",
    "outputId": "5949aa97-040b-4b19-a7e7-52eda8929b72"
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_representative_digits, Y_representative_digits)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2dtYugngjTd"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "    میتوان دید استفاده از خوشه بندی برای انتخاب داده هایی که برچسب میزنیم، باعث افزایش دقت شد.\n",
    "    <br>\n",
    "    <br>\n",
    "اگر کمی این ایده را بسط دهیم به روش label propagation   یا انتشار برچسب می‌رسیم. در این ایده بعد از برچسب زدن نماینده‌ی هر خوشه، به کل اعضای آن خوشه نیز برچسب نماینده اش را نسبت می‌دهیم و درواقع برچسبش را به کل خوشه منتشر می‌کنیم و از کل داده‌ها برای آموزش به روش با ناظر خود استفاده خواهیم کرد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fk2biiJQgjTd",
    "outputId": "eec16e3e-4bf6-42e2-efbd-fff2c00bac0e"
   },
   "outputs": [],
   "source": [
    "y_train_propagated = np.empty(len(X_train), dtype=np.int32)\n",
    "for i in range(k):\n",
    "    y_train_propagated[kmeans.labels_==i] = Y_representative_digits[i]\n",
    "    \n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train_propagated)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMWMqB69gjTd"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "        میتوان دید استفاده از label propagation، باعث افزایش دقت شد.\n",
    "    <br>\n",
    "    <br>\n",
    "اشکال روش قبل در این است که توجهی به فاصله‌ی نمونه‌ها با مرکز خوشه ندارد. نمونه‌هایی که به مرکز خوشه و در نتیجه نماینده‌ی خوشه نزدیک هستند به احتمال بالایی همان برچسب نماینده خود را خواهند داشت؛ اما در مورد نمونه‌های نزدیک به مرز خوشه‌ها نمی‌توان با همین اطمینان اظهار نظر کرد. به همین منظور در یک بهبود برای روش قبل، برچسب نماینده را تنها به درصد نزدیکی از نمونه‌ها به مرکز انتشار می‌دهیم. مثلاً فقط به 50 درصد نزدیک‌ترین نمونه‌ها به مرکز هر خوشه برچسب نمیانده ی آن خوشه را نسبت می‌دهیم و سپس از تمام داده‌های برچسب گذاری شده برای آموزش استفاده میکینم. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIwNC1m9gjTd",
    "outputId": "1c7fdc81-0e79-40b0-fdae-651f4b071b0c"
   },
   "outputs": [],
   "source": [
    "percentile_closest = 50\n",
    "X_cluster_dist = X_digits_dist[np.arange(len(X_train)), kmeans.labels_]\n",
    "for i in range(k):\n",
    "    in_cluster = (kmeans.labels_ == i)\n",
    "    cluster_dist = X_cluster_dist[in_cluster]\n",
    "    cutoff_distance = np.percentile(cluster_dist, percentile_closest)\n",
    "    above_cutoff = (X_cluster_dist > cutoff_distance)\n",
    "    X_cluster_dist[in_cluster & above_cutoff] = -1\n",
    "partially_propagated = (X_cluster_dist != -1)\n",
    "X_train_partially_propagated = X_train[partially_propagated]\n",
    "y_train_partially_propagated = y_train_propagated[partially_propagated]\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_partially_propagated, y_train_partially_propagated)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cnf3dTkNgjTd"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "        میتوان دید انتشار برچسب تنها به نمونه های نزدیک تر به مرکز خوشه که اطمینان بالایی دارند، اندکی دقت را بهبود داد."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcAiu9xjgjTd"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"3-4\">\n",
    "<font color=\"red\" size=4>**3-4.یادگیری فعال (Active learning):** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_koGCErkgjTe"
   },
   "source": [
    "<font face=\"XB Zar\" size=4><div dir=rtl>\n",
    "در این رویکرد ناظر با الگوریتم یادگیری ارتباط متفابل دارد به این شکل که هر زمان الگوریتم برای داده‌هایی که اعلام می‌کند نیاز به برچسب داشت، ناظر آن داده‌ها را برایش برچسب گذاری کند.\n",
    "<br>\n",
    "<br>\n",
    "یه روش یادگیری فعال uncertainty sampling  نام دارد به این صورت که هر بارا لگوریتم با داده‌های برچسب داری که دراختیار دارد آموزش را انجام می‌دهد و روی داده‌های بدون برچسب پیش بینی انجام می‌دهد. با ازای هر پیش بینی یه ضریب اطمینان نیز محاسبه می‌کند و داده‌هایی را که به پیش بینی شان کمترین اطمینان را دارد به ناظر می‌دهد تا برایش برچسب بزند و این مراحل را تکرار میکتد تا زمانی که بهبود قابل توجهی حاصل نشود.\n",
    "<br>\n",
    "<br>\n",
    "روش‌های دیگر یادیگری فعال می‌تواند شامل موارد زیر باشد:\n",
    "<br>\n",
    "-\tالگوریتم داده‌هایی که موجب بیشترین کاهش در خطا باشد را برای برچسب زدن به ناظر بدهد\n",
    "-\tچند الگوریتم روی داده‌ها اجرا شود و نمونه‌هایی که الگوریتم‌های مختلف پیش بینی‌های مختلفی برایشان داشته است برای برچسب زدن به ناظر داده شوند.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORT9S7tJgjTe"
   },
   "source": [
    "<hr>\n",
    "<font face=\"XB Zar\" size=4><div dir=rtl id=\"2\">\n",
    "<font color=\"black\" size=5> منابع</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuu-RLn5gjTe"
   },
   "source": [
    "\n",
    "- GeÌron, A. (2019). Hands-on machine learning with Scikit-Learn, Keras and TensorFlow: concepts, tools, and techniques to build intelligent systems (2nd ed.). O’Reilly.\n",
    "\n",
    "- https://github.com/asharifiz/Introduction_to_Machine_Learning/blob/main/Slides/Chapter_02_Classical_Models/Clustering/section%202-3.pdf"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
