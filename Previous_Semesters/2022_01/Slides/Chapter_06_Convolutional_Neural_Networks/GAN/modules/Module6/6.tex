\begin{frame}
    \frametitle{StyleGAN}
    \begin{figure}[h!]
        \hyperlink{StyleGAN}{
            \includegraphics[width=5cm]{images/stylegan_example1.png}
            \caption{Example of One Set of Generated Faces (Left) Adopting the Coarse Style of Another Set of Generated Faces (Top)}
        }
    \end{figure}
    \begin{itemize}
        \item GAN: Lacking Control Over Synthesized Images
        \item Style Generative Adversarial Network(StyleGAN) Controls Style Using New Generator Model
        \item StyleGan is proficient in producing impressively photorealistic high-quality photos of faces and grants control over the characteristic of the created image at different specification levels by changing the style vectors and noise.
    \end{itemize}

\end{frame}

\frame{\frametitle{StyleGAN Model Architecture}
    \hyperlink{StyleGAN}{
        \begin{figure}[h!]
            \includegraphics[width=6cm]{images/StyleGan_Architecture.png}
            \caption{StyleGAN Architecture \href{https://arxiv.org/abs/1812.04948}{(Source)}}
        \end{figure}
    }

}
\frame{\frametitle{StyleGAN Model Architecture}
    \vspace*{-2cm}
    \begin{itemize}
        \item The StyleGAN is described as a progressive growing GAN architecture with five modifications:
              \begin{itemize}
                  \item Baseline Progressive GAN.
                  \item Addition of tuning and bilinear upsampling.
                  \item Addition of mapping network and AdaIN (styles).
                  \item Removal of latent vector input to generator.
                  \item Addition of noise to each block.
                  \item Addition Mixing regularization.
              \end{itemize}
    \end{itemize}
}
\begin{frame}
    \frametitle{CycleGAN: Unpaired Image-to-Image Translation}
    \begin{itemize}
        \item Style transfer problem: change the style of an image while preserving the content.
    \end{itemize}
    \hyperlink{CycleGAN}{
        \begin{figure}[h!]
            \includegraphics[width=10cm]{images/cyclegan1.png}
        \end{figure}
    }
    \begin{itemize}
        \item Data: Two unrelated collections of images, one for each style
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{CycleGAN: Unpaired Image-to-Image Translation}
    \vspace*{-2cm}
    \begin{itemize}
        \item If we had paired data (same content in both styles), this would be a supervised learning problem. But this is hard to find.
        \item The CycleGAN architecture learns to do it from unpaired data.
              \begin{itemize}
                  \item Train two different generator nets to go from style 1 to style 2, and vice versa.
                  \item Make sure the generated samples of style 2 are indistinguishable from real images by a discriminator net.
                  \item Make sure the generators are cycle-consistent: mapping from style 1 to style 2 and back again should give you almost the original image.
              \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{CycleGAN}
    \hyperlink{CycleGAN}{
        \begin{figure}[h!]
            \includegraphics[width=10cm]{images/cyclegan2.png}
        \end{figure}
    }
\end{frame}

\begin{frame}
    \frametitle{CycleGAN}
    \vspace*{-2cm}
    \begin{itemize}
        \item Style transfer between aerial photos and maps:
    \end{itemize}
    \hyperlink{CycleGAN}{
        \begin{figure}[h!]
            \includegraphics[width=10cm]{images/cyclegan3.png}
        \end{figure}
    }
\end{frame}

\begin{frame}
    \frametitle{CycleGAN: Example}
    \vspace*{-1cm}
    \begin{itemize}
        \item Style transfer between road scenes and semantic segmentations (labels of every pixel in an image by object category):
    \end{itemize}
    \hyperlink{CycleGAN}{
        \begin{figure}[h!]
            \includegraphics[width=10cm]{images/cyclegan4.png}
        \end{figure}
    }
\end{frame}
