{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce6397ab",
   "metadata": {},
   "source": [
    "<img src=\"./pic/sharif-main-logo.png\" alt=\"SUT logo\" width=345 height=345 align=left class=\"saturate\">\n",
    "\n",
    "\n",
    "<br>\n",
    "<font>\n",
    "<div dir=ltr align=center>\n",
    "<font color=0F5298 size=7>\n",
    "    Machine Learning <br>\n",
    "<font color=2565AE size=5>\n",
    "    Computer Engineering Department <br>\n",
    "    Fall 2024<br>\n",
    "<font color=3C99D size=5>\n",
    "    Practical Assignment 2 - Unsupervised Learning<br>\n",
    "<font color=696880 size=4>\n",
    "    Assignment Supervisor: Niki Sepasian <br>\n",
    "<font color=696880 size=5>\n",
    "    Asemaneh Nafe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbbf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_number = None\n",
    "full_name = None\n",
    "assert student_number and full_name is not None, 'please input your information'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3551f3e4",
   "metadata": {},
   "source": [
    "<font color=red size=3>\n",
    "notice that you can not use sklearn.decomposition and sklearn.cluster libary in this home work! you should implement pca and kmeans from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f15b487",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this assignment, you will perform PCA and K-Means clustering on credit card customer data. dataset contains information about customer’s use of credit cards. The goal is to reduce the dataset’s dimensionality using PCA and then apply clustering to segment customers. You will compare the clustering performance both before and after PCA. Additionally, you'll be asked to explain the theory and decisions behind each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d27dee",
   "metadata": {},
   "source": [
    "## Data Preprocessing (15 points)\n",
    "Read the dataset.CSV file and display a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f92d77",
   "metadata": {},
   "source": [
    "Display dataset information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b68cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f0af2",
   "metadata": {},
   "source": [
    "Which column do you think might be the most irrelevant for PCA and clustering?\n",
    "<br>\n",
    "Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b471c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude irrelevant feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a71f9",
   "metadata": {},
   "source": [
    "how do you handle missing data, and why did you choose this method?\n",
    "<br>\n",
    "Answer: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0105ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371304a8",
   "metadata": {},
   "source": [
    "plot the correlation matrix and identify redundant features.remove them from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307fa5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae98d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and remove redundant features. use 0.8 threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c152dc",
   "metadata": {},
   "source": [
    "## Standardize the Data (5 points)\n",
    "Standardize the dataset using z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c9de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da254869",
   "metadata": {},
   "source": [
    "Why is it important to standardize the data before applying PCA?\n",
    "<br>\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f617fe",
   "metadata": {},
   "source": [
    "What is differnce between Normalizer and StandardScaler classes. which is better for PCA?\n",
    "<br>\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db37a4",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA) (35 points)\n",
    "Implement PCA from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7410b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomPCA:\n",
    "    def __init__(self, n_components=None):\n",
    "        \"\"\"\n",
    "        Initialize the PCA class with the number of components to keep.\n",
    "        n_components: Number of principal components to keep. If None, all components are kept.\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.components = None  # To store the principal components (eigenvectors)\n",
    "        self.mean = None        # To store the mean of the data (used for centering the data)\n",
    "        self.explained_variance_ratio = None  # To store the explained variance ratio of the components\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit the PCA model on the dataset X by calculating the eigenvalues and eigenvectors of the covariance matrix.\n",
    "        X: Input data (n_samples, n_features)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform the input data X into the new space using the principal components.\n",
    "        X: Input data (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        # Return the transformed data\n",
    "\n",
    "    def get_explained_variance_ratio(self):\n",
    "        \"\"\"\n",
    "        Return the explained variance ratio of each principal component.\n",
    "        \"\"\"\n",
    "        return self.explained_variance_ratio\n",
    "\n",
    "    def get_components(self):\n",
    "        \"\"\"\n",
    "        Return the principal components (eigenvectors).\n",
    "        \"\"\"\n",
    "        return self.components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2507b3",
   "metadata": {},
   "source": [
    "### Visualizing the Cumulative Variance\n",
    "\n",
    "Plot the cumulative explained variance to visualize the selection of components.  How many components are needed to explain 75% of the variance?\n",
    "<br>\n",
    "answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238fb526",
   "metadata": {},
   "source": [
    "Build a new DataFrame with the first slected components. save it to a new CSV file named 'pca_output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a new DataFrame with the first slected components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed43b921",
   "metadata": {},
   "source": [
    "We expect these new features to be orthogonal to each other. Check this and show the correlation between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674be777",
   "metadata": {},
   "source": [
    "## KMeans (45 points)\n",
    "Implement kmeans from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomKMeans:\n",
    "    def __init__(self, n_clusters=3, max_iter=100, random_state=42):\n",
    "        \"\"\"\n",
    "        Initialize the KMeans class with the number of clusters and maximum iterations.\n",
    "        n_clusters: Number of clusters to form.\n",
    "        max_iter: Maximum number of iterations for convergence.\n",
    "        random_state: Seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.centroids = None  # To store the centroids of clusters\n",
    "        self.inertia_ = None   # To store the inertia (within-cluster sum of squares)\n",
    "        self.labels_ = None    # To store the label assigned to each data point (cluster assignment)\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit the KMeans model on the dataset X.\n",
    "        X: Input data (n_samples, n_features)\n",
    "        \"\"\"\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _calculate_inertia(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the within-cluster sum of squared distances (inertia).\n",
    "        X: Input data (n_samples, n_features)\n",
    "        Returns: inertia (float)\n",
    "        \"\"\"\n",
    "        # Step 1: For each cluster, compute the squared distances of points from their corresponding centroid\n",
    "        # Step 2: Sum all squared distances to compute inertia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f5b851",
   "metadata": {},
   "source": [
    "### Elbow Method\n",
    "Apply the elbow method to determine the optimal number of clusters for K-Means. what is the best number of clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07562698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the WCSS values for each number of clusters\n",
    "WCSS = []\n",
    "\n",
    "# Apply KMeans for a range of cluster values (from 1 to 30)\n",
    "for i in range(1, 30):\n",
    "    # Initialize the CustomKMeans with `i` clusters and a random state of 42\n",
    "    kmeans_pca = CustomKMeans(n_clusters=i, random_state=42)\n",
    "    \n",
    "    # Fit the model to the PCA-transformed data\n",
    "    \n",
    "\n",
    "    # Append the calculated inertia (WCSS) to the WCSS list\n",
    "    WCSS.append(kmeans_pca.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b090a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Elbow curve using Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3b3664",
   "metadata": {},
   "source": [
    "Apply the optimal KMeans clustering on the PCA-transformed data, and assign cluster labels to each observation. Add a new column named segment to the df_pca DataFrame to store these labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KMeans on PCA-reduced data with the optimal number of clusters based on the elbow method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b957e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'segment' to pca data frame and assign the cluster labels to each observation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c2ba55",
   "metadata": {},
   "source": [
    " visualize the clustering by plotting the pairwise relationships of the PCA-reduced features, color-coded by the cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d166a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bec536",
   "metadata": {},
   "source": [
    "So, when we employ PCA prior to using K-means we can visually separate almost the entire data set. That was one of the biggest goals of PCA - to reduce the number of variables by combining them into bigger, more meaningful features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8bb61a",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering\n",
    "Perform hierarchical clustering on the reduced dataset after PCA. Use complete linkage method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777cd9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Hierarchical Clustering on the pca dataset\n",
    "\n",
    "# Visualize the dendrogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0f296",
   "metadata": {},
   "source": [
    "\"Use scipy.cluster.hierarchy.fcluster to assign clusters from the dendrogram with a specified number of 5 clusters. Then visualize the results using pairplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334fd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose threshold and assign clusters\n",
    "\n",
    "# Assign cluster labels to PCA DataFrame\n",
    "\n",
    "# Visualize using PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5b8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
