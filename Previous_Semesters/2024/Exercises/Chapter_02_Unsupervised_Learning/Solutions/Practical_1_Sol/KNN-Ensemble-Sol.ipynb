{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pulMkHkQa6K6"
   },
   "source": [
    "<img src=\"./pic/sharif-main-logo.png\" alt=\"SUT logo\" width=345 height=345 align=left class=\"saturate\">\n",
    "\n",
    "\n",
    "<br>\n",
    "<font>\n",
    "<div dir=ltr align=center>\n",
    "<font color=0F5298 size=7>\n",
    "    Machine Learning <br>\n",
    "<font color=2565AE size=5>\n",
    "    Computer Engineering Department <br>\n",
    "    Fall 2024<br>\n",
    "<font color=3C99D size=5>\n",
    "    Practical Assignment 2 - Unsupervised Learning<br>\n",
    "<font color=696880 size=4>\n",
    "    Assignment Supervisor: Niki Sepasian <br>\n",
    "<font color=696880 size=5>\n",
    "    Sarina Heshmati\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thbdn8kkMErt"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tR4Ma36gMEKo"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualizations\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "ZlKHHSCRGUrH",
    "outputId": "28df4798-814a-4105-92de-d6a0259d1b18"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxij84ZZMICb"
   },
   "source": [
    "# Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKjjjNIXbPKh"
   },
   "source": [
    "Explore the dataset and get familiar with its features and statistics. (don't worry about the 'masked values' in our target column. They are simply used to automatically test your model later on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Wf2XDTG92VjY",
    "outputId": "5daa6fe8-04fd-49f0-a135-2839e3a86a9d"
   },
   "outputs": [],
   "source": [
    "# Load the Breast Cancer dataset from sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Check the basic structure of the dataset\n",
    "print(\"Dataset Info:\")\n",
    "df.info()  # Check data types and for missing values\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())  # Summary statistics of numeric features\n",
    "\n",
    "# Check for any missing values in the dataset\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())  # Find if any column has missing values\n",
    "\n",
    "# Explore the target variable (binary classification)\n",
    "print(\"\\nTarget Variable Distribution:\")\n",
    "print(df['Attrition'].value_counts())  # Distribution of the target classes\n",
    "\n",
    "# Visualize the target distribution\n",
    "sns.countplot(x='Attrition', data=df)\n",
    "plt.title(\"Distribution of Target Variable\")\n",
    "plt.show()\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5CdOmE6drWQ"
   },
   "source": [
    "It is generally better to remove columns with only one unique value from a DataFrame when preparing data for a decision tree. <br>\n",
    "Such columns do not provide any useful information for splitting the data and can lead to unnecessary complexity in the model. Remove the said columns from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfYCZxOnKT4z",
    "outputId": "3356d5c9-c07c-4d00-afb1-4aa634e1f232"
   },
   "outputs": [],
   "source": [
    "# Measure and print the number of unique values for each column.\n",
    "# Check if there are any columns with less than 2 unique values. If so, remove them.\n",
    "\n",
    "unique_counts= {}\n",
    "for col in df:\n",
    "    unique_counts[col]= df[col].nunique()\n",
    "print(unique_counts)\n",
    "\n",
    "print(\"colmuns with less than 2 unique values: \")\n",
    "for key, value in unique_counts.items():\n",
    "    if value<2:\n",
    "        print(key)\n",
    "        df.drop(key, axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTBf219zdnX-"
   },
   "source": [
    "Look at the DataFrame and try to gather insight into people's monthly income and things that generally affect this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "AzmrpRpQLyCH",
    "outputId": "3095def0-5d75-48d6-d40c-bf944d37cec3"
   },
   "outputs": [],
   "source": [
    "# TODO: Plot the average MonthlyIncome against the YearsAtCompany.\n",
    "# Then find which departments have the highest and lowest incomes on average.\n",
    "\n",
    "sns.lineplot(data= df, x= 'YearsAtCompany', y= 'MonthlyIncome')\n",
    "print('Highest Average Income: ', df.groupby('Department')['MonthlyIncome'].mean().idxmax())\n",
    "print('Lowest Average Income: ',df.groupby('Department')['MonthlyIncome'].mean().idxmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nViqoo1oMNPN"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tq8nGk_PyS2L"
   },
   "source": [
    "Label Encode categorical columns and create a new DataFrame. Then split this data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "cG8NLcPBNMqQ",
    "outputId": "13ec4cba-21ec-45a0-c15a-1fc7065970c3"
   },
   "outputs": [],
   "source": [
    "# Label encode all categorical columns\n",
    "\n",
    "encoded_df= df.copy()\n",
    "for col in encoded_df.columns:\n",
    "    if encoded_df[col].dtype=='object':\n",
    "        encoded_df[col]=LabelEncoder().fit_transform(encoded_df[col])\n",
    "encoded_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jkyNBYHMP7Z"
   },
   "outputs": [],
   "source": [
    "# Split into features and target variable\n",
    "X = encoded_df.drop(columns=['Attrition'])\n",
    "y = encoded_df['Attrition']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoDFp4Y8MR2H"
   },
   "source": [
    "# K-Nearest Neighbors (KNN) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EDXQWeyobF1"
   },
   "source": [
    "Implement KNN model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xICc83R0k-u_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class CustomKNN:\n",
    "    def __init__(self, k=3):\n",
    "        \"\"\"\n",
    "        Initialize the KNN classifier.\n",
    "\n",
    "        Parameters:\n",
    "        - k (int): Number of neighbors to consider.\n",
    "        \"\"\"\n",
    "        # Store the number of neighbors (k)\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the KNN classifier to the training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train (numpy array): Training feature vectors.\n",
    "        - y_train (numpy array): Training labels.\n",
    "        \"\"\"\n",
    "        # Store training data\n",
    "        self.X_train = np.array(X_train)\n",
    "        self.y_train = np.array(y_train)\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Calculate the Euclidean distance between two data points.\n",
    "\n",
    "        Parameters:\n",
    "        - x1 (numpy array): First data point.\n",
    "        - x2 (numpy array): Second data point.\n",
    "\n",
    "        Returns:\n",
    "        - float: Euclidean distance between x1 and x2.\n",
    "        \"\"\"\n",
    "        # Calculate and return the Euclidean distance\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict labels for test data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_test (numpy array): Test feature vectors.\n",
    "\n",
    "        Returns:\n",
    "        - numpy array: Predicted labels.\n",
    "        \"\"\"\n",
    "        # Predict label for each test instance and return the array of predictions\n",
    "        predictions = [self._predict(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict label for a single data point.\n",
    "\n",
    "        Parameters:\n",
    "        - x (numpy array): Test data point.\n",
    "\n",
    "        Returns:\n",
    "        - int: Predicted label.\n",
    "        \"\"\"\n",
    "        # Compute distances from x to all training points\n",
    "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "\n",
    "        # Find the indices of the k nearest neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        # Get the labels of the k nearest neighbors\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "\n",
    "        # Return the most common label among the k nearest neighbors (majority vote)\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMZmgCCAk-mn",
    "outputId": "1fef4eec-69ab-46b3-97c8-ff61887ad9e5"
   },
   "outputs": [],
   "source": [
    "# Optional. You can choose any range of k values that you want.\n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15]\n",
    "accuracies = []\n",
    "models= []\n",
    "\n",
    "# Fit the model using the scaled training data\n",
    "# Make predictions on the scaled test data\n",
    "# Evaluate the model's accuracy for each value of k and choose the best one\n",
    "for k in k_values:\n",
    "  my_model= CustomKNN(k)\n",
    "  my_model.fit(X_train_scaled, y_train)\n",
    "  y_pred_custom= my_model.predict(X_test_scaled)\n",
    "  accuracy= accuracy_score(y_test, y_pred_custom)\n",
    "  print(f'k: {k} - Accuracy: {accuracy}')\n",
    "  models.append(my_model)\n",
    "  accuracies.append(accuracy)\n",
    "\n",
    "best_custom_model= models[np.argmax(accuracies)]\n",
    "# Keep the best k value (needed later on with bagging)\n",
    "bestk= k_values[np.argmax(accuracies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o42cvk6lMU_I",
    "outputId": "63fd042a-3b59-4011-ca4c-80a2e703bc4b"
   },
   "outputs": [],
   "source": [
    "# Print the accuracy and classification report using sklearn's metrics for your best model\n",
    "y_pred= best_custom_model.predict(X_test_scaled)\n",
    "print(\"Model's Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ucAEb4vMWzy"
   },
   "source": [
    "Visualize the confusion matrix for KNN predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "beurxpdoMaIr",
    "outputId": "70c63f16-eb59-4301-c1e6-2e3c7dec0b69"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for KNN\n",
    "cm_knn = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XySx_HrNmhu"
   },
   "source": [
    "## Evaluation\n",
    "In this part, we are going to evaluate your model's performance on another set of unseen data. Load test.csv (this data is already encoded), use your best_custom_model to predict and save the results in a DataFrame called 'result.csv'. The DataFrame should contain one column called 'target' that contains your model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZSBB3dBMBbi"
   },
   "outputs": [],
   "source": [
    "# Load test.csv\n",
    "eval_df= pd.read_csv('encodedtest.csv')\n",
    "# Use your old scaler to scale the data\n",
    "eval_df= scaler.transform(eval_df)\n",
    "# Predict using your model\n",
    "y_pred_eval= best_custom_model.predict(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4gXdORtPMAy"
   },
   "source": [
    "Save the results in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dBnBretPKlj"
   },
   "outputs": [],
   "source": [
    "# Save the results as a csv file\n",
    "result_df= pd.DataFrame()\n",
    "result_df['target']=pd.Series(y_pred_eval)\n",
    "result_df.to_csv('result.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH3_BUvKMbBG"
   },
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYHBUJr-MdGi",
    "outputId": "714ab9bb-1686-488a-f470-34bf0431ed0c"
   },
   "outputs": [],
   "source": [
    "# Random Forest Model Implementation\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid_rf = {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5, 10]}\n",
    "rf_cv = GridSearchCV(rf, param_grid_rf, cv=5)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf = rf_cv.best_estimator_\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Print Random Forest model accuracy and classification report\n",
    "print(\"Random Forest Model Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZxEb6pgMfCC"
   },
   "source": [
    "Visualize the confusion matrix for Random Forest predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "GvJrLdwEMhH7",
    "outputId": "6adbe9a2-655c-43aa-a485-8267eb09651f"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EatS9AnH4iaV"
   },
   "source": [
    "A feature importance plot is a visual representation that illustrates the significance of each feature (or variable) in a machine learning model, particularly in the context of supervised learning tasks like classification and regression. Plot the feature importances using a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "id": "QJzZXn8p32FE",
    "outputId": "5e68713a-67a8-4b98-ec5e-a489c1f37371"
   },
   "outputs": [],
   "source": [
    "imps= best_rf.feature_importances_\n",
    "indices= np.argsort(imps)[::-1]\n",
    "importance_df= pd.DataFrame({'Feature': df.columns[indices], 'Importance': imps[indices]})\n",
    "\n",
    "sns.barplot(data= importance_df, x='Feature', y='Importance').tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2tDZYAuMk5l"
   },
   "source": [
    "# Bagging with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6cAaGHxMnH0",
    "outputId": "7579dfb7-6a70-4720-a63b-5f42edabb2a2"
   },
   "outputs": [],
   "source": [
    "# Bagging with KNN Model Implementation\n",
    "bagging_knn = BaggingClassifier(KNeighborsClassifier(n_neighbors=bestk), n_estimators=50, random_state=42)\n",
    "bagging_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred_bagging_knn = bagging_knn.predict(X_test_scaled)\n",
    "\n",
    "# Print Bagging with KNN model accuracy and classification report\n",
    "print(\"Bagging with KNN Model Accuracy:\", accuracy_score(y_test, y_pred_bagging_knn))\n",
    "print(classification_report(y_test, y_pred_bagging_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDXp4LBDMpVL"
   },
   "source": [
    "Visualize the confusion matrix for Bagging with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "T1IDrlwCMo7p",
    "outputId": "3a6815cb-8f5b-4533-de10-e469da32aaa4"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for Bagging with KNN\n",
    "cm_bagging_knn = confusion_matrix(y_test, y_pred_bagging_knn)\n",
    "sns.heatmap(cm_bagging_knn, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Bagging with KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTXD8Ke6MsXI"
   },
   "source": [
    "# AdaBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtojzxETMyJu",
    "outputId": "ac129ba4-5977-458c-a883-33689d511c04"
   },
   "outputs": [],
   "source": [
    "# AdaBoost Model Implementation\n",
    "adaboost = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning for AdaBoost\n",
    "param_grid_ada = {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 1.0]}\n",
    "adaboost_cv = GridSearchCV(adaboost, param_grid_ada, cv=5)\n",
    "adaboost_cv.fit(X_train, y_train)\n",
    "\n",
    "# Best AdaBoost model\n",
    "best_adaboost = adaboost_cv.best_estimator_\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred_adaboost = best_adaboost.predict(X_test)\n",
    "\n",
    "# Print AdaBoost model accuracy and classification report\n",
    "print(\"AdaBoost Model Accuracy:\", accuracy_score(y_test, y_pred_adaboost))\n",
    "print(classification_report(y_test, y_pred_adaboost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZkdWW-oMzis"
   },
   "source": [
    "Visualize the confusion matrix for AdaBoost predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "NNTZuC0qMy72",
    "outputId": "fa43ed30-d1a3-4eba-f728-71295e3ab922"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for AdaBoost\n",
    "cm_adaboost = confusion_matrix(y_test, y_pred_adaboost)\n",
    "sns.heatmap(cm_adaboost, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - AdaBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORGr2kDzM3FS"
   },
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "aXUodw21M3Yz",
    "outputId": "58428149-f9fb-4bee-887b-dd9d8b44ddcd"
   },
   "outputs": [],
   "source": [
    "# Create a table comparing all the models' accuracy\n",
    "models = ['KNN', 'Random Forest', 'Bagging KNN', 'AdaBoost']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred),\n",
    "    accuracy_score(y_test, y_pred_rf),\n",
    "    accuracy_score(y_test, y_pred_bagging_knn),\n",
    "    accuracy_score(y_test, y_pred_adaboost)\n",
    "]\n",
    "\n",
    "accuracy_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Accuracy': accuracies\n",
    "})\n",
    "\n",
    "# Display the comparison table\n",
    "print(\"\\nModel Comparison Table:\")\n",
    "print(accuracy_df)\n",
    "\n",
    "# Plotting model accuracies for comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='Model', y='Accuracy', data=accuracy_df)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
