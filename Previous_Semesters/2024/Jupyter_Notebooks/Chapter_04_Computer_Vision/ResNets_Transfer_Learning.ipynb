{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axViOHHuSBe5"
   },
   "source": [
    "# Residuals Networks and Transfer Learning\n",
    "\n",
    "[CE477: Machine Learning](https://www.sharifml.ir/)\n",
    "\n",
    "__Course Instructor__: Dr. Sharifi-Zarchi\n",
    "\n",
    "__Notebook Authors__: Ramtin Moslemi\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_04_Computer_Vision/ResNets_Transfer_Learning.ipynb)\n",
    "[![Open In kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/SharifiZarchi/Introduction_to_Machine_Learning/main/Jupyter_Notebooks/Chapter_04_Computer_Vision/ResNets_Transfer_Learning.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Objectives\n",
    "\n",
    "In this notebook we are going to implement a simple convolutional neural network as well as CNN with residual connections. Additionally we will also take a look at Transfer Learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T00:22:37.852532Z",
     "iopub.status.busy": "2024-12-01T00:22:37.851835Z",
     "iopub.status.idle": "2024-12-01T00:22:46.995098Z",
     "shell.execute_reply": "2024-12-01T00:22:46.994035Z",
     "shell.execute_reply.started": "2024-12-01T00:22:37.852502Z"
    },
    "id": "7ASubvlvxY9f",
    "outputId": "5195e6e3-0d37-4d15-cdda-9acba4dba505"
   },
   "outputs": [],
   "source": [
    "! pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-12-01T00:22:46.997868Z",
     "iopub.status.busy": "2024-12-01T00:22:46.997585Z",
     "iopub.status.idle": "2024-12-01T00:22:51.635653Z",
     "shell.execute_reply": "2024-12-01T00:22:51.634674Z",
     "shell.execute_reply.started": "2024-12-01T00:22:46.997841Z"
    },
    "id": "CYQYyHliSpeZ"
   },
   "outputs": [],
   "source": [
    "# @title setup and imports\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-01T00:22:51.637319Z",
     "iopub.status.busy": "2024-12-01T00:22:51.636907Z",
     "iopub.status.idle": "2024-12-01T00:23:01.310528Z",
     "shell.execute_reply": "2024-12-01T00:23:01.309708Z",
     "shell.execute_reply.started": "2024-12-01T00:22:51.637285Z"
    },
    "id": "4-ORDaFPSpXz",
    "outputId": "5f0589f1-8b89-4ec1-ee5b-e78ac257ef40"
   },
   "outputs": [],
   "source": [
    "# @title CIFAR10 dataset\n",
    "\n",
    "norm_mean = (0.4914, 0.4822, 0.4465)\n",
    "norm_std = (0.2023, 0.1994, 0.2010)\n",
    "batch_size = 128\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm_mean, norm_std),\n",
    "])\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-12-01T00:23:01.312426Z",
     "iopub.status.busy": "2024-12-01T00:23:01.312051Z",
     "iopub.status.idle": "2024-12-01T00:23:01.328500Z",
     "shell.execute_reply": "2024-12-01T00:23:01.327641Z",
     "shell.execute_reply.started": "2024-12-01T00:23:01.312379Z"
    },
    "id": "PmVvvoucSpbo"
   },
   "outputs": [],
   "source": [
    "# @title helper functions\n",
    "\n",
    "def train_epoch(model, loss_fn, optimizer, dataloader=trainloader):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (logits.argmax(dim=1) == labels).sum().item()\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader.dataset)\n",
    "    return train_loss, 100 * train_acc\n",
    "\n",
    "\n",
    "def validate_epoch(model, loss_fn, dataloader=testloader):\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    val_acc = 0.\n",
    "    with torch.inference_mode():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = model(images)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (logits.argmax(dim=1) == labels).sum().item()\n",
    "        val_loss /= len(dataloader)\n",
    "        val_acc /= len(dataloader.dataset)\n",
    "    return val_loss, 100 * val_acc\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, n_epochs):\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    for _ in (pbar := trange(n_epochs)):\n",
    "        train_loss, train_acc = train_epoch(model, loss_fn, optimizer)\n",
    "        history['train_loss'].append(train_loss), history['train_acc'].append(train_acc)\n",
    "        val_loss, val_acc = validate_epoch(model, loss_fn)\n",
    "        history['val_loss'].append(val_loss), history['val_acc'].append(val_acc)\n",
    "        pbar.set_description(f'Training Accuracy {train_acc:.2f}% | Validation Accuracy {val_acc:.2f}% ')\n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_training_curves(results):\n",
    "    epochs_range = range(1, len(results['train_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, results['train_loss'], label='Train Loss')\n",
    "    plt.plot(epochs_range, results['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xticks(epochs_range)  # Adding ticks for epochs\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, results['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(epochs_range, results['val_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xticks(epochs_range)  # Adding ticks for epochs\n",
    "    plt.yticks(range(0, 101, 10))  # Accuracy range from 0 to 100\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_results(m1_name, m1_results, m2_name, m2_results):\n",
    "    epochs_range = range(1, len(m1_results['val_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, m1_results['val_loss'], label=f'{m1_name}')\n",
    "    plt.plot(epochs_range, m2_results['val_loss'], label=f'{m2_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xticks(epochs_range)  # Adding ticks for epochs\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, m1_results['val_acc'], label=f'{m1_name}')\n",
    "    plt.plot(epochs_range, m2_results['val_acc'], label=f'{m2_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xticks(epochs_range)  # Adding ticks for epochs\n",
    "    plt.yticks(range(0, 101, 10))  # Accuracy range from 0 to 100\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEFVbOtbSofo"
   },
   "source": [
    "# Plain Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUv2AhkeT8uc"
   },
   "source": [
    "Let's start by creating `BasicBlock`s for the CNN. We will create our blocks as follows:\n",
    "\n",
    "\n",
    "*   Each block will have 2 convolutional layers with `kernel_size=3` and `padding=1`\n",
    "*   Each convolutional layer will be followed by a batch normalization layer and a `ReLU` activation function\n",
    "*   The `expansion` factor is a class attribute that indicates the channel expansion factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T00:23:01.331631Z",
     "iopub.status.busy": "2024-12-01T00:23:01.331299Z",
     "iopub.status.idle": "2024-12-01T00:23:01.345731Z",
     "shell.execute_reply": "2024-12-01T00:23:01.344854Z",
     "shell.execute_reply.started": "2024-12-01T00:23:01.331605Z"
    },
    "id": "U5FNgUJyztkp"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1  # BasicBlock does not expand channels\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esNaCFsG26Wn"
   },
   "source": [
    "Next we will proceed to the network itself. Using the `BasicBlock` module, we first create four blocks and double the number of channels at each one. At last we use an average pooling layer in addition to a fully connected layer to make the predictions.\n",
    "\n",
    "The `_make_layer` method is a utility function used to create a sequence of blocks (such as `BasicBlock`s or `ResidualBlock`s) in the ResNet architecture. It handles the construction of layers, including any required downsampling to ensure dimensions match correctly for the skip connections. For residual connectionsthe input and output dimensions of a block must match, so if there is a mismatch, a sequential layer with a 1x1 convolution and batch normalization will be added to match the input to the output dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T00:23:01.347094Z",
     "iopub.status.busy": "2024-12-01T00:23:01.346754Z",
     "iopub.status.idle": "2024-12-01T00:23:01.363108Z",
     "shell.execute_reply": "2024-12-01T00:23:01.362302Z",
     "shell.execute_reply.started": "2024-12-01T00:23:01.347058Z"
    },
    "id": "Nhs46GiESDnk"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16  # CIFAR-10 starts with 16 filters\n",
    "\n",
    "        # Initial convolution layer\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Residual layers\n",
    "        self.layer1 = self._make_layer(block, 16, layers[0], stride=1)  # 32x32\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)  # 16x16\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)  # 8x8\n",
    "\n",
    "        # Global average pooling and fully connected layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slw1ziojxY9i"
   },
   "source": [
    "In our experiments we use the resnet architecture from [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385). Specifically we use the architectures introduced for the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T00:42:52.613751Z",
     "iopub.status.busy": "2024-12-01T00:42:52.613376Z",
     "iopub.status.idle": "2024-12-01T00:42:52.618591Z",
     "shell.execute_reply": "2024-12-01T00:42:52.617625Z",
     "shell.execute_reply.started": "2024-12-01T00:42:52.613716Z"
    },
    "id": "jOQu4lkkxY9i"
   },
   "outputs": [],
   "source": [
    "def resnet_cifar10(block, n):\n",
    "    \"\"\"\n",
    "    Constructs a ResNet for CIFAR-10 with 6n+2 layers.\n",
    "    Example:\n",
    "    n=3 -> ResNet-20\n",
    "    n=5 -> ResNet-32\n",
    "    n=7 -> ResNet-44\n",
    "    n=9 -> ResNet-56\n",
    "    \"\"\"\n",
    "    return ResNet(block, [n, n, n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6uuFzB1fD0K"
   },
   "source": [
    "Now lets create an instance of this architecture and see its parameter count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-01T00:23:01.379017Z",
     "iopub.status.busy": "2024-12-01T00:23:01.378748Z",
     "iopub.status.idle": "2024-12-01T00:23:02.251448Z",
     "shell.execute_reply": "2024-12-01T00:23:02.250639Z",
     "shell.execute_reply.started": "2024-12-01T00:23:01.378984Z"
    },
    "id": "sq0OGQA2SBGW",
    "outputId": "809ad3f0-f401-425e-ec77-98360f6783b5"
   },
   "outputs": [],
   "source": [
    "plain20 = resnet_cifar10(BasicBlock, 3).to(device)\n",
    "summary(plain20, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNnO05Mbfvj-"
   },
   "source": [
    "Finally we can train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "execution": {
     "iopub.execute_input": "2024-12-01T00:23:02.253052Z",
     "iopub.status.busy": "2024-12-01T00:23:02.252668Z",
     "iopub.status.idle": "2024-12-01T00:30:01.504351Z",
     "shell.execute_reply": "2024-12-01T00:30:01.503340Z",
     "shell.execute_reply.started": "2024-12-01T00:23:02.253011Z"
    },
    "id": "Ly5revaMRkxd",
    "outputId": "c9c300d8-8833-429e-e023-33ef6dc5db04"
   },
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    plain20 = torch.compile(plain20)\n",
    "optim = Adam(plain20.parameters(), lr=1e-4)\n",
    "\n",
    "p20results = train_model(plain20, optim, n_epochs=30)\n",
    "plot_training_curves(p20results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMHWDRxaxY9j"
   },
   "source": [
    "Let's move on to a larger network to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T00:30:01.506612Z",
     "iopub.status.busy": "2024-12-01T00:30:01.505844Z",
     "iopub.status.idle": "2024-12-01T00:38:18.784841Z",
     "shell.execute_reply": "2024-12-01T00:38:18.783904Z",
     "shell.execute_reply.started": "2024-12-01T00:30:01.506559Z"
    },
    "id": "5HnDEj4UxY9j",
    "outputId": "e976323b-ed42-422e-cd86-52b615c9d418"
   },
   "outputs": [],
   "source": [
    "plain32 = resnet_cifar10(BasicBlock, 5).to(device)\n",
    "if device == 'cuda':\n",
    "    plain32 = torch.compile(plain32)\n",
    "optim = Adam(plain32.parameters(), lr=1e-4)\n",
    "\n",
    "p32results = train_model(plain32, optim, n_epochs=30)\n",
    "plot_training_curves(p32results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7sb4DcDxY9j"
   },
   "source": [
    "It seems that increasing the depth of the network not only didn't help but actually made things worse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T00:38:18.786256Z",
     "iopub.status.busy": "2024-12-01T00:38:18.785992Z",
     "iopub.status.idle": "2024-12-01T00:38:19.450367Z",
     "shell.execute_reply": "2024-12-01T00:38:19.449532Z",
     "shell.execute_reply.started": "2024-12-01T00:38:18.786230Z"
    },
    "id": "lFTtfOMmxY9j",
    "outputId": "f92e4d9d-37a1-4938-c440-d431f1c38846"
   },
   "outputs": [],
   "source": [
    "compare_results('plain20', p20results, 'plain32', p32results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D28V07oJgBBM"
   },
   "source": [
    "# Residual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evhe65ySsTee"
   },
   "source": [
    "In this section we are going to implement CNNs with residual connections. To do so we will first implement a `ResidualBlock` module. If the input size and output size differ, we'll add a `downsample` to overcome this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T00:38:19.452274Z",
     "iopub.status.busy": "2024-12-01T00:38:19.451638Z",
     "iopub.status.idle": "2024-12-01T00:38:19.460025Z",
     "shell.execute_reply": "2024-12-01T00:38:19.459005Z",
     "shell.execute_reply.started": "2024-12-01T00:38:19.452231Z"
    },
    "id": "W_dlvd8ZgCuS"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    expansion = 1  # BasicBlock does not expand channels\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEYcOzfiuqmr"
   },
   "source": [
    "Using the `ResidualBlock` module we just defined and the `ResNet` module from the previous section, we can now build a residual network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-01T00:43:03.308325Z",
     "iopub.status.busy": "2024-12-01T00:43:03.307466Z",
     "iopub.status.idle": "2024-12-01T00:43:03.350712Z",
     "shell.execute_reply": "2024-12-01T00:43:03.349889Z",
     "shell.execute_reply.started": "2024-12-01T00:43:03.308288Z"
    },
    "id": "nNDTqdt_gCcs",
    "outputId": "5720f7a1-b844-41b2-c560-d63ba3a9ddaa"
   },
   "outputs": [],
   "source": [
    "resnet = resnet_cifar10(ResidualBlock, 3).to(device)\n",
    "summary(resnet, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8Os2nIvxY9k"
   },
   "source": [
    "To have a fair comparison we'll train a resnet with 32 layers to compare with the plain32 network from the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "execution": {
     "iopub.execute_input": "2024-12-01T00:43:08.283017Z",
     "iopub.status.busy": "2024-12-01T00:43:08.282647Z",
     "iopub.status.idle": "2024-12-01T00:51:50.063312Z",
     "shell.execute_reply": "2024-12-01T00:51:50.062391Z",
     "shell.execute_reply.started": "2024-12-01T00:43:08.282978Z"
    },
    "id": "6Nf5QUmowGZV",
    "outputId": "911e9fd8-0ef6-4695-802a-c7c31164f7f0"
   },
   "outputs": [],
   "source": [
    "resnet32 = resnet_cifar10(ResidualBlock, 5).to(device)\n",
    "if device == 'cuda':\n",
    "    resnet32 = torch.compile(resnet32)\n",
    "optim = Adam(resnet32.parameters(), lr=1e-4)\n",
    "\n",
    "r32results = train_model(resnet32, optim, n_epochs=30)\n",
    "plot_training_curves(r32results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18ejGc9ZIBv_"
   },
   "source": [
    "As you can see both networks are identical except for the residual connections. Even for small networks such as these two you can see the improvement due to the residual connections. For larger networks with 50, 100, etc layers, this gap in performance will become wider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T00:51:50.065941Z",
     "iopub.status.busy": "2024-12-01T00:51:50.065545Z",
     "iopub.status.idle": "2024-12-01T00:51:50.594216Z",
     "shell.execute_reply": "2024-12-01T00:51:50.593401Z",
     "shell.execute_reply.started": "2024-12-01T00:51:50.065896Z"
    },
    "id": "qy605Jk0xY9k",
    "outputId": "a776d0f4-d1a0-49fd-fa8e-ebfa3d2b2fd9"
   },
   "outputs": [],
   "source": [
    "compare_results('plain32', p32results, 'resnet32', r32results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATVheApKgEbJ"
   },
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyWC67CaIjHg"
   },
   "source": [
    "In this section we are going to learn about transfer learning.\n",
    "\n",
    "We use models available from torchvision. You can find a list of all [available models and pre-trained weights](https://pytorch.org/vision/stable/models.html) on torchvision.\n",
    "\n",
    "To observe the improvement caused by transfer learning, we train the `ResNet18` model twice, once with pre-trained weights (from the ImageNet dataset) and once without pre-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T00:53:46.218803Z",
     "iopub.status.busy": "2024-12-01T00:53:46.217928Z",
     "iopub.status.idle": "2024-12-01T00:53:46.467215Z",
     "shell.execute_reply": "2024-12-01T00:53:46.466324Z",
     "shell.execute_reply.started": "2024-12-01T00:53:46.218764Z"
    },
    "id": "ph6xn58bwOvs",
    "outputId": "2ff28cc7-795b-4849-9d2b-86c2a08e702d"
   },
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(weights='IMAGENET1K_V1')\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "resnet18 = resnet18.to(device)\n",
    "summary(resnet18, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ElgJ76UJ5jq"
   },
   "source": [
    "## Pre-Trained ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T00:53:49.567728Z",
     "iopub.status.busy": "2024-12-01T00:53:49.566849Z",
     "iopub.status.idle": "2024-12-01T01:00:19.112625Z",
     "shell.execute_reply": "2024-12-01T01:00:19.111624Z",
     "shell.execute_reply.started": "2024-12-01T00:53:49.567677Z"
    },
    "id": "norUrdhkyzyO",
    "outputId": "df686236-68fc-47f0-cb1e-63e10b377b75"
   },
   "outputs": [],
   "source": [
    "if device == 'cuda':\n",
    "    resnet18 = torch.compile(resnet18)\n",
    "optim = Adam(resnet18.parameters(), lr=1e-3)\n",
    "\n",
    "pt_results = train_model(resnet18, optim, n_epochs=15)\n",
    "plot_training_curves(pt_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vwoikzNKCe_"
   },
   "source": [
    "## Normal ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T01:00:19.114556Z",
     "iopub.status.busy": "2024-12-01T01:00:19.114262Z",
     "iopub.status.idle": "2024-12-01T01:06:49.746543Z",
     "shell.execute_reply": "2024-12-01T01:06:49.745581Z",
     "shell.execute_reply.started": "2024-12-01T01:00:19.114526Z"
    },
    "id": "eyLwP0maywKC",
    "outputId": "afd124f4-cfde-4353-f8ca-c78fa0c1638e"
   },
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(weights=None)\n",
    "num_ftrs = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "resnet18 = resnet18.to(device)\n",
    "if device == 'cuda':\n",
    "    resnet18 = torch.compile(resnet18)\n",
    "optim = Adam(resnet18.parameters(), lr=1e-3)\n",
    "\n",
    "results = train_model(resnet18, optim, n_epochs=15)\n",
    "plot_training_curves(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7KG-XRDKGaJ"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUMJfOsKKHzT"
   },
   "source": [
    "As you can see the pre-trained weights improve the accuracy significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T01:06:49.748475Z",
     "iopub.status.busy": "2024-12-01T01:06:49.747861Z",
     "iopub.status.idle": "2024-12-01T01:06:50.284316Z",
     "shell.execute_reply": "2024-12-01T01:06:50.283536Z",
     "shell.execute_reply.started": "2024-12-01T01:06:49.748443Z"
    },
    "id": "4587OXIuxY9l",
    "outputId": "dcf90bdb-7b98-4c94-84eb-e8a4a5672af4"
   },
   "outputs": [],
   "source": [
    "compare_results('Pre-trained', pt_results, 'Not Pre-trained', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YQcszUnTpFf"
   },
   "source": [
    "# Refrences\n",
    "\n",
    "*   [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "*   [Transfer Learning for Computer Vision Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "axViOHHuSBe5"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
