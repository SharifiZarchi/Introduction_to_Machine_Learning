{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_Oob41KYdz8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxdCCAERYdz-"
   },
   "outputs": [],
   "source": [
    "# Simulating Data\n",
    "n = 1000\n",
    "x = np.random.normal(3, 5, size=n)\n",
    "y = -15 * x + 20 + np.random.normal(0, 3, size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBKhqJXvYdz_",
    "outputId": "8e800884-6d78-40ba-f9f7-a641c6b6bf44"
   },
   "outputs": [],
   "source": [
    "# Analytcal approach for solving linear regression\n",
    "X = np.sum(x)\n",
    "Y = np.sum(y)\n",
    "b1 = (n * np.dot(x,y) - Y*X)/(n*np.dot(x,x)-X**2)\n",
    "b0 = (Y-b1*X)/n\n",
    "b1, b0 = round(b1, 2), round(b0, 2)\n",
    "print(f\"y = {b1} x + {b0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "id": "bbvNjKCtYd0A",
    "outputId": "50f2a075-1295-44ac-9e25-e0a11b109d36"
   },
   "outputs": [],
   "source": [
    "def MSE_loss(b0, b1, x, y):\n",
    "    pred = b0 + b1 * x\n",
    "    loss = np.sum((pred - y) ** 2) / len(y)\n",
    "    return loss\n",
    "\n",
    "# Generate a grid of b0 and b1 values around the real b0=20 and b1=-15\n",
    "b0_vals = np.linspace(0, 40, 100)\n",
    "b1_vals = np.linspace(-30,0, 100)\n",
    "\n",
    "# Calculate MSE loss for each point of this grid\n",
    "# Log-scale is used only for better visualization\n",
    "Z = np.zeros((len(b0_vals),len(b1_vals)))\n",
    "for i in range(len(b0_vals)):\n",
    "    for j in range(len(b1_vals)):\n",
    "        Z[i, j] = np.log(MSE_loss(b0_vals[i], b1_vals[j], x, y))\n",
    "\n",
    "# 3D Plot of MSE loss in log-scale\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "B0, B1 = np.meshgrid(b0_vals, b1_vals)\n",
    "ax.plot_surface(B0, B1, Z, cmap='viridis')\n",
    "\n",
    "# Adding labels\n",
    "ax.set_xlabel('b0')\n",
    "ax.set_ylabel('b1')\n",
    "ax.set_zlabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "lQ_VT6XbYd0B",
    "outputId": "edb75b7b-cb44-4a89-945a-4a65b37aaffd"
   },
   "outputs": [],
   "source": [
    "# Gradient descent\n",
    "def gradient(b0, b1, x, y):\n",
    "    yhat = b0 + b1 * x\n",
    "    error = (y-yhat)**2\n",
    "    db0 = - 2 * (y - yhat)\n",
    "    db1 = - 2 * x * (y - yhat)\n",
    "    return db0, db1, error\n",
    "\n",
    "b1 , b0 = 0, 0\n",
    "alpha = 0.03\n",
    "b0l, b1l, errl = [],[],[]\n",
    "for epoch in range(1000):\n",
    "    Gb0, Gb1, Error = 0, 0, 0\n",
    "    for i in range(n):\n",
    "        gb0, gb1,err = gradient(b0, b1, x[i], y[i])\n",
    "        Gb0, Gb1, Error = Gb0 + gb0, Gb1 + gb1, Error + err\n",
    "    Gb0, Gb1, Error = Gb0/n, Gb1/n, Error/n\n",
    "    b0, b1 = b0 - alpha * Gb0, b1 - alpha * Gb1\n",
    "    alpha = .995 * alpha\n",
    "    b0l.append(b0)\n",
    "    b1l.append(b1)\n",
    "    errl.append(err)\n",
    "    #print(round(Error,3))\n",
    "print(round(b0, 2), round(b1, 2), round(Error, 3))\n",
    "print(alpha)\n",
    "plt.plot(b0l, b1l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksJdt2r1Yd0B"
   },
   "outputs": [],
   "source": [
    "#Simulate D-dimendional data\n",
    "D=10\n",
    "n=1000\n",
    "sd = 5\n",
    "B = np.random.uniform(-20, 20, size=D)\n",
    "B0 = np.random.uniform(-20,20)\n",
    "x = np.random.uniform(-10,10, size=(n,D))\n",
    "y = []\n",
    "for i in range(n):\n",
    "    y.append(np.dot(x[i,],B)+B0+np.random.normal(0,sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlAda5a4Yd0B",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2c8596df-a7eb-4b2b-ffe3-a3f240217c3f"
   },
   "outputs": [],
   "source": [
    "def gradient(b,b0,x,y):\n",
    "    yh = np.dot(b,x)+b0\n",
    "    err = (y-yh)**2\n",
    "    db0 = -2 * (y-yh)\n",
    "    db = -2 * x * (y-yh)\n",
    "    #print(db0)\n",
    "    return db, db0, err\n",
    "\n",
    "b0 = np.random.uniform(-10,10)\n",
    "b = np.random.uniform(-10,10,size=D)\n",
    "alpha = 0.02\n",
    "for epoch in range(100):\n",
    "    Db, Db0, Err = np.zeros(D), 0, 0\n",
    "    for i in range(n):\n",
    "        db, db0, err = gradient(b, b0, x[i,], y[i])\n",
    "        Db, Db0, Err = Db + db, Db0 + db0, Err + err\n",
    "    Db, Db0, Err = Db/n, Db0/n, Err/n\n",
    "    b = b - alpha * Db\n",
    "    b0 = b0 - alpha * Db0\n",
    "print(\"Correct coefficients:\",B, B0)\n",
    "print(\"Predicted coefficients:\",b, b0, Err)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
