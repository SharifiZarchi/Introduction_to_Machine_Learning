{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ecaqr9YkWpbL"
   },
   "source": [
    "# Neural Networks with PyTorch\n",
    "\n",
    "**[CE477: Machine Learning](https://www.sharifml.ir/)**\n",
    "\n",
    "__Course Instructor__: Dr. Sharifi-Zarchi\n",
    "\n",
    "__Notebook Author__: Ramtin Moslemi\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_03_Neural_Networks/NNs_with_torch.ipynb)\n",
    "[![Open In kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/SharifiZarchi/Introduction_to_Machine_Learning/main/Jupyter_Notebooks/Chapter_03_Neural_Networks/NNs_with_torch.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Objectives\n",
    "\n",
    "In this notebook we are going to implement and train a neural network with PyTorch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XApd8re1Vt7"
   },
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDJTtiVD1dfh"
   },
   "source": [
    "We start by importing necessary modules. Don't worry if it seems a little overwhelming at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gbTJDvZ1X0X"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "djIbr1Vn-CH3"
   },
   "outputs": [],
   "source": [
    "# @title plotting functions\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "def visualize(images, labels):\n",
    "    \"\"\"\n",
    "    Visualize a batch of images.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i].squeeze(), cmap='gray')\n",
    "        ax.set_title(f'Label: {labels[i].item()}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_predictions(images, labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Visualize a batch of images with their true and predicted labels.\n",
    "    Titles are green if the prediction is correct, red if incorrect.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(8, 8, figsize=(11, 12))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i].squeeze(), cmap='gray')\n",
    "        color = 'green' if labels[i].item() == predicted_labels[i].item() else 'red'\n",
    "        ax.set_title(f'True: {labels[i].item()}\\nPred: {predicted_labels[i].item()}', color=color)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_conf_mat(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Plot the confusion matrix for a given model and dataloader.\n",
    "    \"\"\"\n",
    "    # Initialize the confusion matrix\n",
    "    total, correct = 0, 0\n",
    "    conf_mat = torch.zeros((10, 10))\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            total += pred.shape[0]\n",
    "            pred = torch.argmax(pred, axis=1)\n",
    "            correct += sum(pred == y).item()\n",
    "            for j in range(pred.shape[0]):\n",
    "                conf_mat[y[j], pred[j].item()] += 1\n",
    "    # calculate the normalized confusion matrix\n",
    "    norm_conf_mat = conf_mat / torch.sum(conf_mat, axis=1)\n",
    "    # plot the matrix\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(norm_conf_mat)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Labels')\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks(range(10))\n",
    "    plt.colorbar()\n",
    "    # put number of each cell in plot\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            c = conf_mat[j, i]\n",
    "            color = 'black' if c > 500 else 'white'\n",
    "            ax.text(i, j, str(int(c)), va='center', ha='center', color=color)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9_crXc91ull"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYDA-qWO4EYc"
   },
   "source": [
    "We will use `datasets` from `torchvision` to load the [MNIST](https://yann.lecun.com/exdb/mnist/) handwritten digits dataset. You can find the list of datasets available on torchvision [here](https://pytorch.org/vision/0.8/datasets.html). Now let's take a loot at the parameters we set:\n",
    "\n",
    "\n",
    "\n",
    "*   `root` sets the directory we store and load our data from.\n",
    "*   `train` indicates wether we want the training dataset or the test dataset.\n",
    "*   `transform` allows us to apply transformations to our data, here we are only going to convert the data to tensor so that they work with PyToch, however in the future notebooks you will see more complicated transformations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxFSah-P1v6o",
    "outputId": "81ad7d0c-db95-4845-a82b-1a1ed52b915a"
   },
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Training data: {training_data}\\n\")\n",
    "print(f\"Test data: {test_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IefrZMW7NQR"
   },
   "source": [
    "As you can see there are 60000 training samples in the training dataset and there are 10000 samples in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YCOmNEF7hPy"
   },
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRqzyZ2j7j2l"
   },
   "source": [
    "To make loading and working with the data easier, we are going to use `DataLoader` from `torch.utils.data`. The `DataLoader` takes in a dataset and a `batch_size` parameter, and allows us to iterate over the dataset. Here we do one iteration just to see the data shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnLKuT5b3RNe",
    "outputId": "910a2d47-b258-47f2-ce6b-f207fdfde2d2"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# Iterate over the data\n",
    "for x, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {x.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5kFlIJa8fMz"
   },
   "source": [
    "As you can see the `x`s are of shape `[64, 1, 28, 28]` which means we have a batch of `64` images, each with `1` channel which means the images are grayscale (for example colorful images have 3 channels of red, blue and green or RGB), and of size `28x28` pixels.\n",
    "\n",
    "Similarly the `y`s are of shape `[64]` which means we have a batch of 64 labels. In the next section we will learn more about these labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe4pHWs691py"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3eIyvqY93JC"
   },
   "source": [
    "Here we will take a look at single batch of data and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cfN57uEp9-Jv",
    "outputId": "b0bf505c-8929-485e-b7fe-8367eb319eb2"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_dataloader))\n",
    "\n",
    "visualize(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtFDQWM4ASCS"
   },
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4E-odHSoAlIj"
   },
   "source": [
    "To accelerate operations in the neural network, we move it to the GPU or MPS (for Apple silicon) if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBYNiZZFAT9m",
    "outputId": "7d351753-325b-4221-b957-61f000d99c42"
   },
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQyyFmmBAvcH"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioQyu5ChA4zA"
   },
   "source": [
    "Here we define our model. Recall that each batch of image has a shape of `[64, 1, 28, 28]`. For now we only want to use `Linear` layers so we must **flatten** the inputs so that we can pass it to the linear layers. The `nn.Flatten()` module allows us to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEDxIof6Awyn"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LK_HFak6ChOT"
   },
   "source": [
    "Next we initialize our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqMh9dC-CkqO",
    "outputId": "46bf1afd-3150-434b-e172-0ec581a43dee"
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZL-dYlMCtKh"
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoUk5yhZCvQI"
   },
   "source": [
    "Since we are trying to classify the handwritten digits, we are going to use the cross entropy loss. You can see the list of loss functions in PyTorch [here](https://pytorch.org/docs/stable/nn.html#loss-functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJltpy3MCu4w"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfKNbTfcDL72"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8HTPwT8DRQc"
   },
   "source": [
    "Next we need to setup an optimizer for training our model. We use stochastic gradient descent so we have must use the `SGD` module from `torch.optim`. We must pass the `model.parameters()` to the `SGD` optimizer and set its learning rate `lr=1e-3`. In the following sessions you will learn more about different optimizers but can also learn about the optimizers available on PyTorch [here](https://pytorch.org/docs/stable/optim.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmjqBHF8DOfK"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uryY-hUQDNw2"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrvYbCNcJKzw"
   },
   "source": [
    "To train the model we first set the number of epochs. For each epoch we then iterate over the entire training data and update the model parameters. For each batch of data, we must first move the data to same device as the network, then we predict the output of the model, calculate the loss, perform backward pass, update parameters, and reset the gradients.\n",
    "\n",
    "To monitor training, we use `trange` from `tqdm` which performs similar to `range` but allows us to have a progress bar `pbar` which lets us display useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhAslicTEFwi",
    "outputId": "78fe1044-26f7-4f25-bf05-ab24ce9d60f5"
   },
   "outputs": [],
   "source": [
    "# Number of epochs we wish to train the model\n",
    "n_epochs = 30\n",
    "\n",
    "for _ in (pbar := trange(n_epochs)):\n",
    "    # Iterate over the data\n",
    "    for x, y in train_dataloader:\n",
    "        # Move the datapoints to same device as the model\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Predict the output and perform the forward pass\n",
    "        pred = model(x)\n",
    "        # Compute prediction error\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update the model weights\n",
    "        optimizer.step()\n",
    "        # Update the progress bar\n",
    "        pbar.set_description(f'Loss = {loss.item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjCxEVVFLVj0"
   },
   "source": [
    "In the following notebooks we explore more advanced methods for monitoring the training but what you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkaReM2DL-DN"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K81CBFV6RPwH"
   },
   "source": [
    "Finally we can evaluate the trained model. We will start by evaluating the model on the test dataset. Here we use `torch.no_grad()` since we don't need the gradients. We iterate over the entire test dataset and print the accuracy of our model on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dH2Ljj-IG-JJ",
    "outputId": "46ab4ca3-f3cc-4a7b-f017-e8d8caa94658"
   },
   "outputs": [],
   "source": [
    "# Store the number of correctly classified and total labels\n",
    "correct, total = 0, 0\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    # Iterate over the test data\n",
    "    for x, y in test_dataloader:\n",
    "        # Move the datapoints to same device as the model\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # Predict the output\n",
    "        logits = model(x)\n",
    "        # Get the predicted label\n",
    "        pred = torch.argmax(logits, axis=1)\n",
    "        # Update the number of correclty classified labels\n",
    "        correct += sum(pred == y).item()\n",
    "        # Update the number of total labels\n",
    "        total += pred.shape[0]\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDwSUz1lR4In"
   },
   "source": [
    "Let's visuzlie a batch to compare the predictions and the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "M11iJLo0OBfQ",
    "outputId": "05923ef6-db3d-4833-d697-a1c371c0225b"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_dataloader))\n",
    "preds = torch.argmax(model(images.to(device)), axis=1).cpu()\n",
    "\n",
    "visualize_predictions(images, labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTqq3z4RSDHp"
   },
   "source": [
    "To get a better sense of our model, we can plot it's confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "cpffebCFNXh3",
    "outputId": "da3ea4db-2833-4586-e4c1-683662706d80"
   },
   "outputs": [],
   "source": [
    "plot_conf_mat(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9oZHsfcZyds"
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkSi-XC8jver"
   },
   "source": [
    "Here we will take a look at different optimizers and how they effect training and convergence. Run the widget bellow to train the model for different optimizers! You can increase the number of epochs or set the hyperparameters of each optimizers manually if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "735d23da5277453da30f909cdb00d58e",
      "36e7fbfbc67549f9a8aeb29adee0aa63",
      "d6292cc9bcc3463da6b2fcf4d427f98a"
     ]
    },
    "id": "ynpWvE5yaRVI",
    "outputId": "774e2a83-0c51-4020-dc14-96f90685f801"
   },
   "outputs": [],
   "source": [
    "# @markdown Optimizer Experimentation Widget\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=128)\n",
    "\n",
    "def train_model(model, optimizer, n_epochs=10):\n",
    "    losses, accuracies = [], []\n",
    "    for _ in (pbar := trange(n_epochs)):\n",
    "        running_loss, acc = 0, 0\n",
    "        for x, y in train_dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            pred = torch.argmax(pred, axis=1)\n",
    "            acc += sum(pred == y).item()\n",
    "        acc /= len(train_dataloader.dataset)\n",
    "        acc *= 100\n",
    "        running_loss /= len(train_dataloader)\n",
    "        losses.append(running_loss)\n",
    "        accuracies.append(acc)\n",
    "        pbar.set_description(f'Loss = {running_loss:.3f} | Accuracy = {acc:.2f}% ')\n",
    "    return losses, accuracies\n",
    "\n",
    "\n",
    "def plot_losses_accuracies(results):\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    for optimizer, res in results.items():\n",
    "        if 'losses' not in res or 'accuracies' not in res:\n",
    "            continue\n",
    "        losses = res['losses']\n",
    "        accuracies = res['accuracies']\n",
    "        axes[0].plot(losses, label=optimizer)\n",
    "        axes[1].plot(accuracies, label=optimizer)\n",
    "    axes[0].set_title('Losses')\n",
    "    axes[1].set_title('Accuracies')\n",
    "    axes[0].legend()\n",
    "    axes[1].legend()\n",
    "    fig.set_size_inches(12, 6)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a list of values\n",
    "options = ['SGD', 'AdaGrad', 'RMSProp', 'Adam']\n",
    "\n",
    "# Create a dropdown widget with custom layout\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=options,\n",
    "    description='Optimizer:',\n",
    "    layout={'width': '200px'},\n",
    "    style={'description_width': 'initial'}\n",
    "\n",
    ")\n",
    "\n",
    "# Define a function to run based on selected value\n",
    "def on_value_change(change):\n",
    "    optimizer = change['new']\n",
    "    global first_run, resuts\n",
    "    model = NeuralNetwork().to(device)\n",
    "    if results[optimizer] != {}:\n",
    "        losses = results[optimizer]['losses']\n",
    "        accuracies = results[optimizer]['accuracies']\n",
    "        plot_losses_accuracies(results)\n",
    "        return\n",
    "    if optimizer == 'SGD':\n",
    "        opt = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    elif optimizer == 'AdaGrad':\n",
    "        opt = torch.optim.Adagrad(model.parameters(), lr=1e-3)\n",
    "    elif optimizer == 'RMSProp':\n",
    "        opt = torch.optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    print(f'\\n{optimizer}')\n",
    "    losses, accuracies = train_model(model, opt)\n",
    "    results[optimizer]['losses'] = losses\n",
    "    results[optimizer]['accuracies'] = accuracies\n",
    "    plot_losses_accuracies(results)\n",
    "\n",
    "\n",
    "\n",
    "# Observe changes in the dropdown value\n",
    "dropdown.observe(on_value_change, names='value')\n",
    "\n",
    "results = {optimizer: dict() for optimizer in options}\n",
    "\n",
    "# on_value_change({\"new\": 'SGD'})\n",
    "\n",
    "# Display the widget\n",
    "display(dropdown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ww709YMt17Mg"
   },
   "source": [
    "# Refrences\n",
    "\n",
    "\n",
    "*   [Learn the Basics of PyTorch](https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
    "*   [Neural networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) from [3Blue1Brown](https://www.3blue1brown.com/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "36e7fbfbc67549f9a8aeb29adee0aa63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "200px"
     }
    },
    "735d23da5277453da30f909cdb00d58e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DropdownModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DropdownModel",
      "_options_labels": [
       "SGD",
       "AdaGrad",
       "RMSProp",
       "Adam"
      ],
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "DropdownView",
      "description": "Optimizer:",
      "description_tooltip": null,
      "disabled": false,
      "index": 3,
      "layout": "IPY_MODEL_36e7fbfbc67549f9a8aeb29adee0aa63",
      "style": "IPY_MODEL_d6292cc9bcc3463da6b2fcf4d427f98a"
     }
    },
    "d6292cc9bcc3463da6b2fcf4d427f98a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
