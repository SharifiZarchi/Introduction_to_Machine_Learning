\textbf{خوشه خوشه}

در این مسئله می‌خواهیم به بررسی الگوریتم خوشه بندی
k-means بپردازیم. فرض کنید \(X = {x_1, x_2, ..., x_n}\) داده‌های ما باشد و $\gamma$ یک ماتریس Indicator باشد به این صورت که $\gamma_{ij} = 1$ اگر \(x_i\) متعلق به خوشه j ام باشد و در غیر این صورت برابر ۰ است. فرض کنید $\mu_1, ..., \mu_k$ میانگین خوشه ها باشند. اعوجاج J برای داده‌ها به صورت زیر محاسبه می‌شود :
\[J(\gamma, \mu_1, ..., \mu_k) = n\sum_{j=1}^{k}\sum_{i=1}^{n}\gamma_{ij}\lVert x_i - \mu_j \rVert^2\]
همچنین \(C = 1, ..., k\) را به عنوان مجموعه خوشه ها در نظر بگیرید.
\begin{enumerate}
\item
آیا k-means نسبت به انتخاب نقاط اولیه حساس است، یعنی پاسخ آن بر اساس مجموعه‌ی نقاط اولیه تغییر می‌کند؟ اگر بله یک مثال ارائه کنید و اگر خیر، اثبات کنید.
\vspace{4cm}
\item
نشان دهید که الگوریتم k-means در زمان متناهی قدم به پایان می‌رسد. (راهنمایی: نشان دهید $J$ تعداد محدودی حالت دارد.)
\vspace{7cm}
\item
اگر ابعاد داده نسبت به تعداد نمونه‌ها خیلی زیاد باشد و عملا نمونه‌ها در یک فضای بزرگ پراکنده باشند، برای بهبود خوشه‌بندی از چه روشی استفاده می‌کنید؟
\pagebreak
\item
نشان دهید که کمینه J یک تابع غیرافزایشی بر حسب k یا همان تعداد خوشه هاست. در این صورت آیا انتخاب مقدار هایپرپارامتر $k$ بر اساس کمینه‌کردن مقداز $J$ ایده‌ی خوبی است؟ اگرنه، چه ایده‌ی بهتری دارید؟
\vspace{7cm}
\item
فرض کنید $\hat{x}$ میانگین داده‌های نمونه باشد. مقادیر زیر را در نظر بگیرید.
\[T(X) = \frac{\sum_{i=1}^{n}\lVert x_i - \hat{x}\rVert^2}{n}\]
\[W_j(X) = \frac{\sum_{i=1}^{n}\gamma_{ij}\lVert x_i - \mu_j\rVert^2}{\sum_{i=1}^{n}\gamma_{ij}}\]
\[B(X) = \sum_{j=1}^{k}\frac{\sum_{i=1}^{n}\gamma_{ij}}{n}\r\lVert \mu_j - \hat{x} \rVert^2\]
در اینجا \(T(X)\) نشان دهنده انحراف کلی، \(W_j(X)\) انحراف 
درون خوشه‌ای و \(B(X)\) انحراف بین خوشه‌ای است.
رابطه‌ی بین این ۳ مقدار به چه صورت است؟
نشان دهید که k-means میتواند به عنوان کمینه کننده میانگین وزن دار مقادیر درون خوشه‌ای و به طور تقریبی بیشینه کردن انحراف بین خوشه‌ای دیده شود.
\vspace{7cm}
\end{enumerate}