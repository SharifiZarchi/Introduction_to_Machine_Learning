\textbf{Tikhonov}

تابع هزینه مسئله رگرسیون خطی به صورت زیر تعریف می‌شود:
\[\mathbb{L}_1(w) = \lVert y - Xw \rVert_2^2\]
همانطور که در درس دیدید، می‌توانیم چند عنصر دیگر به عنوان Term Regularization به این تابع هزینه اضاقه کنیم. در این صورت خواهیم داشت:
\[\mathbb{L}_2(w) = \lVert y - Xw \rVert_2^2 + \lVert \Gamma w \rVert_2^2\]
که به \(\Gamma\)، matrix Tikhonov می‌گویند. این حالت کلی مسئله regression ridge است که در اینجا به جای \(\lambda\), از یک ماتریس استفاده می‌کنیم. 
برای آموزش مدل رگرسیون خطی خود، می‌خواهیم از تکنیکی به نام \(drop out\) استفاده کنیم. این تکنیک برای ورودی \(d\) بعدی، هر ویژگی را با احتمال \(p\) نگه داشته و در غیر این صورت برابر صفر خواهد شد. با استفاده از این تکنیک، تابع هزینه به شکل زیر تغییر خواهد کرد :
\[\mathbb{L}_3(w) = \mathbb{E}_{D\textasciitilde Bernouli(p)}[\lVert y - (D \odot X)\hat{w} \rVert_2^2]]\]
توجه کنید در اینجا \(\hat{w}\) پارامتر های پیدا شده توسط مدلی است که با \(dropout\) آموزش داده شده است. همچنین ضرب \(\odot\)، ضرب wise element می‌باشد.
\begin{enumerate}
    \item ابتدا معادله نرمال برای حل مساله‌ی minimization بدون توجه به \(dropout\) به دست آورید. در اینجا شما مانند دیگر مسئله های رگرسیون، باید وزن های بهینه را با استفاده از مشتق و ... با استفاده از تابع هزینه به دست آورید.
    \vspace{6cm}
    \item یک شرط ساده، کافی و لازم برای ماتریس \(\Gamma\) بیان کنید که تضمین کند تابع هزینه یک جواب منحصر به فرد و بهینه برای \(\hat{w}\) دارد.
    \vspace{9cm}

    \item حال اثبات کنید هنگام استفاده از تکنیک \(dropout\),  می‌توان تابع هزینه را به شکل زیر بازنویسی کرد :
    \[\mathbb{L}(w) = \lVert y - pX\hat{w} \rVert_2^2 + p(1 - p)\lVert \hat{\Gamma}\hat{w} \rVert_2^2\]
    به طوری که \(\hat{\Gamma}\) یک ماتریس قطری بوده که عنصر \(j\) ام قطری این ماتریس، برابر نرم ستون \(j\) ام ماتریس دادگان \(X\) می باشد.
        \vspace{9cm}

    \item فرض کنید \(\Gamma\) معکوس پذیر باشد. با یک تغییر متغیر سعی کنید تا تابع هزینه گفته شده در حالت بدون \(dropout\)را به صورت تابع هزینه مسئله regression ridge بازنویسی کنید :
    \[\mathbb{L}(\hat{w}) = \lVert y - \hat{X}\hat{w} \rVert_2^2 + \lambda \lVert \hat{w} \rVert_2^2\]
\end{enumerate}