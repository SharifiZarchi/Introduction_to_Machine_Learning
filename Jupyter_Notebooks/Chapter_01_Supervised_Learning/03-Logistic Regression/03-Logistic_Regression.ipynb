{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOMPiX5vQFoT"
   },
   "source": [
    "<br>\n",
    "<font>\n",
    "<!-- <img src=\"https://sina.sharif.edu/~m_salehi/images/logo_sharif.png\" alt=\"SUT logo\" width=300 height=300 align=left class=\"saturate\"> -->\n",
    "<div dir=ltr align=center>\n",
    "<img src=\"https://sina.sharif.edu/~m_salehi/images/logo_sharif.png\" width=160 height=180>\n",
    "<br>\n",
    "<font color=0F5298 size=6>\n",
    "Introduction to Machine Learning <br>\n",
    "<font color= 6C3BAA size=6>\n",
    "Logistic Regression <br>\n",
    "<font color=696880 size=5>\n",
    "<!-- <br> -->\n",
    "Computer Engineering Department\n",
    "<br>\n",
    "Sharif University of Technology\n",
    "\n",
    "<font color=696880 size=5>\n",
    "<br>\n",
    "CE 40477 - Fall 2025\n",
    "\n",
    "<font color=GREEN size=5>\n",
    "<br>\n",
    "Mahdi Aghaei & Farzan Rahmani\n",
    "<!-- <br> -->\n",
    "\n",
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7p7ugD6xQAP"
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "\n",
    "*   ## [Binary Classification](#scrollTo=rwBQ-Xn1xc-6)\n",
    "*   ## [Multi-class logistic regression](#scrollTo=ebx9kaEpwpOd&line=1&uniqifier=1)\n",
    "*  ## [Real-World Example: Pima Indians Diabetes](#scrollTo=rK2ukkrQtTGh&line=1&uniqifier=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwBQ-Xn1xc-6"
   },
   "source": [
    "# Binary Classification\n",
    "In this section, we will use [breast cancer dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) of scikit-learn which is a classic binary classification dataset used for machine learning. This dataset contains multiple features for tumors as well as it's label (either benign or malignant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUJasFdY3f12"
   },
   "source": [
    "At first the dataset is loaded from Scikit-learn’s built-in load_breast_cancer function, which provides features and labels for tumor samples. After extracting the features (X) and labels (y), the feature names are printed to understand what variables are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4GUthYnyi-SI",
    "outputId": "cc85ba45-c66f-4566-ce89-9f9a5c7dd9e6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "\n",
    "# Load breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Extract features and labels\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WmXn6bgLCdK"
   },
   "source": [
    "Next, we focus our analysis on two specific features — **mean perimeter** and **mean smoothnes** — to make the classification problem visually interpretable. We standardize these features to ensure consistent scaling, add a bias term manually, and then divide the dataset into training and validation sets with an 80/20 ratio. A scatter plot of the training data helps us see how the two tumor classes are distributed across the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "-6AA32TtjDl3",
    "outputId": "058effc8-acb8-4545-d57c-a70677c9e31a"
   },
   "outputs": [],
   "source": [
    "# Select two features (mean perimeter and mean smoothness)\n",
    "X = data.data[:, [2, 4]]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Add bias term (column of ones)\n",
    "X_bias = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "\n",
    "# Split data into training and validation sets (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_bias, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Plot training data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1],\n",
    "            color='red', label='Malignant')\n",
    "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1],\n",
    "            color='blue', label='Benign')\n",
    "plt.xlabel('Mean Perimeter (Standardized)')\n",
    "plt.ylabel('Mean Smoothness (Standardized)')\n",
    "plt.title('Breast Cancer Dataset (Training Set)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CWdEOpRLZMk"
   },
   "source": [
    "Know we define core functions required for logistic regression.\n",
    "\n",
    "We implement the **sigmoid activation function**, the **binary cross-entropy loss function**, the **gradient of the loss,** and a **function to compute validation accuracy** :\n",
    "\n",
    "Sigmoid : $\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$\n",
    "\n",
    "\n",
    "Loss: $\n",
    "L(w) = -\\frac{1}{m} \\sum_{i=1}^{m} \\Big[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\Big]\n",
    "$\n",
    "&nbsp; &nbsp; s.t &nbsp; &nbsp;\n",
    "$\n",
    "\\hat{y}^{(i)} = \\sigma(X^{(i)} w)\n",
    "$\n",
    "\n",
    "Gradient:\n",
    "$\n",
    "\\nabla_w L(w) = \\frac{1}{m} X^{T} (\\hat{y} - y)\n",
    "$\n",
    "\n",
    "Accuracy:\n",
    "$\n",
    "\\text{Accuracy} = \\frac{1}{m} \\sum_{i=1}^{m} \\mathbb{I}\\big[ \\hat{y}^{(i)} = y^{(i)} \\big]\n",
    "$\n",
    "&nbsp; &nbsp; s.t &nbsp; &nbsp;\n",
    "$\n",
    "\\hat{y}^{(i)} =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } \\sigma(X^{(i)} w) > 0.5 \\\\\n",
    "0 & \\text{o.w}\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwqwnFuokNXs"
   },
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Compute logistic regression loss (binary cross-entropy)\n",
    "def compute_loss(w, X, y):\n",
    "    z = X @ w\n",
    "    predictions = sigmoid(z)\n",
    "    loss = -np.mean(y * np.log(predictions) + (1 - y) * np.log(1 - predictions))\n",
    "    return loss\n",
    "\n",
    "# Compute gradient of the loss weights\n",
    "def compute_gradient(w, X, y):\n",
    "    z = X @ w\n",
    "    predictions = sigmoid(z)\n",
    "    errors = predictions - y\n",
    "    gradient = X.T @ errors / len(y)\n",
    "    return gradient\n",
    "\n",
    "# Evaluate validation accuracy\n",
    "def validation_accuracy(w, X_val, y_val):\n",
    "    probabilities = sigmoid(X_val @ w)\n",
    "    predictions = (probabilities > 0.5).astype(int)\n",
    "    accuracy = np.mean(predictions == y_val)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csgt1XYDLuqQ"
   },
   "source": [
    "Moving on, we implement gradient descent as the optimization algorithm that updates model weights iteratively. Starting with zeros, we repeatedly compute the gradient, adjust the weights, and monitor the loss and accuracy over time. The process logs progress every hundred steps and halts early if the improvement in loss becomes minimal, ensuring efficiency and stability during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qZdpfGukir-"
   },
   "outputs": [],
   "source": [
    "# Gradient descent for logistic regression\n",
    "def gradient_descent_logistic(X_train, y_train, X_val, y_val, learning_rate=0.1, n_steps=1000, tolerance=1e-6):\n",
    "    # Initialize weights\n",
    "    w = np.zeros(X_train.shape[1])\n",
    "    # Track loss, accuracy, and weights\n",
    "    loss_history = [compute_loss(w, X_train, y_train)]\n",
    "    val_accuracy_history = [validation_accuracy(w, X_val, y_val)]\n",
    "    weights_history = [w.copy()]\n",
    "\n",
    "    # Main training loop\n",
    "    for step in range(1, n_steps + 1):\n",
    "        grad = compute_gradient(w, X_train, y_train)\n",
    "        w -= learning_rate * grad  # Update weights\n",
    "\n",
    "        loss = compute_loss(w, X_train, y_train)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        acc = validation_accuracy(w, X_val, y_val)\n",
    "        val_accuracy_history.append(acc)\n",
    "\n",
    "        # Save weights every 10 steps\n",
    "        if step % 10 == 0:\n",
    "            weights_history.append(w.copy())\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.abs(loss_history[-2] - loss_history[-1]) < tolerance:\n",
    "            print(f'Converged at step {step}')\n",
    "            break\n",
    "\n",
    "        # Log progress every 100 steps\n",
    "        if step % 100 == 0:\n",
    "            print(f'Step {step}: Loss = {loss:.4f}, Validation Accuracy = {acc:.4f}')\n",
    "\n",
    "    return w, loss_history, val_accuracy_history, weights_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRxGMY1fL6ab"
   },
   "source": [
    "We set the **learning rate** and **number of training iterations**, run the gradient descent algorithm, and print the optimized weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmpMZkAUpQ4z",
    "outputId": "44446f69-7e3b-4b83-8ad3-71d1c92d723d"
   },
   "outputs": [],
   "source": [
    "# Set learning rate and number of steps\n",
    "learning_rate = 0.05\n",
    "n_steps = 800\n",
    "\n",
    "# Train logistic regression model with gradient descent\n",
    "w_opt, loss_history, val_accuracy_history, weights_history = gradient_descent_logistic(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    learning_rate=learning_rate,\n",
    "    n_steps=n_steps,\n",
    ")\n",
    "\n",
    "print(f'Optimized weights: {w_opt}')\n",
    "print(f'Decision rule: {w_opt[0]} * Mean Perimeter + {w_opt[1]} * Mean Smoothness + {w_opt[2]} > 0 : Benign')\n",
    "print(f'Decision rule: {w_opt[0]} * Mean Perimeter + {w_opt[1]} * Mean Smoothness + {w_opt[2]} < 0 : Malignant')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEIDFP0tDP80"
   },
   "source": [
    "We also visualize how the decision boundary evolves as the model learns. By plotting the decision line at different stages of training, with gradually increasing opacity, we illustrate how the classifier progressively refines its separation between malignant and benign samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "tNKxP5oQNxXT",
    "outputId": "bcdbe5e7-3ca4-420f-e39c-d69bb130cb76"
   },
   "outputs": [],
   "source": [
    "# Plot a single decision boundary for given weights\n",
    "def plot_decision_boundary(w, X, y, step, total_steps):\n",
    "    x_values = np.array([X[:, 0].min() - 1, X[:, 0].max() + 1])\n",
    "\n",
    "    # Compute corresponding y-values for the boundary\n",
    "    if w[1] != 0:\n",
    "        y_values = -(w[0] * x_values + w[2]) / w[1]\n",
    "        # Draw boundary with increasing opacity over steps\n",
    "        plt.plot(x_values, y_values, color='green',\n",
    "                 alpha=(0.20 + (step / total_steps) * 0.20))\n",
    "    else:\n",
    "        # Vertical line if w[1] == 0\n",
    "        plt.axvline(x=-w[2] / w[0], color='green')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "# Plot all decision boundaries throughout training\n",
    "def plot_decision_boundaries(weights_history, X, y, total_steps):\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot data points by class\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red', label='Malignant')\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', label='Benign')\n",
    "\n",
    "    # Set plot limits\n",
    "    plt.xlim(-2.5, 3)\n",
    "    plt.ylim(-3, 3)\n",
    "\n",
    "    # Plot decision boundaries for selected training steps\n",
    "    for i, w in enumerate(weights_history):\n",
    "        if i % 10 == 0:\n",
    "            step = i * 10\n",
    "            plot_decision_boundary(w, X, y, step, total_steps)\n",
    "\n",
    "    plt.title('Decision Boundaries during Gradient Descent')\n",
    "    plt.xlabel('Mean Perimeter (Standardized)')\n",
    "    plt.ylabel('Mean Smoothness (Standardized)')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_decision_boundaries(weights_history, X_train[:, :2], y_train, n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbbhFgl4s0re"
   },
   "source": [
    "The plot above shows that decision boundary is trying to classify data points better at each step. Let's visualize model performance using several metrics. <br> Finally, we evaluate the trained model’s performance on the validation set. Predicted probabilities are transformed into class labels, and we generate a detailed classification report summarizing **precision**, **recall**, and **F1-scores** for each class. We visualize the **confusion matrix** to see misclassifications clearly, then compute and plot the **ROC curve and the AUC (Area Under the Curve)** metric to measure the model’s ability to distinguish between classes. Altogether, these results give us a clear view of how effectively our logistic regression model performs in identifying cancer malignancy :\n",
    "<div align=\"center\">\n",
    "\n",
    "| Metric   | &nbsp; &nbsp;  &nbsp; &nbsp; ‌‌‌‌‌‌‌‌‌‌‌ Formula‌‌‌‌‌‌‌‌‌‌ &nbsp; &nbsp;&nbsp; &nbsp; | Focus | Typical Use-Case |\n",
    "|-----------|-------------|--------|------------------|\n",
    "| Accuracy  | <div align=\"center\">$\\frac{TP + TN}{TP + FP + FN + TN}$</div> | Overall correctness | Balanced classes |\n",
    "| Precision | <div align=\"center\">$\\frac{TP}{TP + FP}$</div> | False positive control | Spam detection, IR |\n",
    "| Recall    | <div align=\"center\">$\\frac{TP}{TP + FN}$</div> | False negative control | Medical diagnosis, anomaly detection |\n",
    "| F1-Score  | <div align=\"center\">$\\frac{2PR}{P + R}$</div> | Balance | Imbalanced or skewed datasets |\n",
    "</div>\n",
    "<br> <br>\n",
    "<img src=\"https://miro.medium.com/v2/0*P7ZXAWS1QJl9k7h1\" width=460 height=250>\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "<img src=\"https://www.mathworks.com/help/examples/nnet/win64/CompareDeepLearningModelsUsingROCCurvesExample_01.png\" width=340 height=250>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TZ2_Ch7XO2b4",
    "outputId": "3f1ccabf-8836-496f-93f2-6f2cf1771cbd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Compute model outputs and predictions on validation set\n",
    "z_val = X_val @ w_opt\n",
    "probabilities_val = sigmoid(z_val)\n",
    "predictions_val = (probabilities_val > 0.5).astype(int)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_val, predictions_val, target_names=['Malignant', 'Benign'], output_dict=True)\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "print(df_report)\n",
    "\n",
    "# Extract and print overall accuracy\n",
    "accuracy = report['accuracy']\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Compute and plot confusion matrix\n",
    "cm = confusion_matrix(y_val, predictions_val)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Malignant (Pred 0)', 'Benign (Pred 1)'],\n",
    "            yticklabels=['Malignant (True 0)', 'Benign (True 1)'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_val, probabilities_val)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(\"ROC Curve Analysis\")\n",
    "print(f\"Area Under the Curve (AUC): {roc_auc:.4f}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "         label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
    "         label='Random Classifier (AUC = 0.5)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebx9kaEpwpOd"
   },
   "source": [
    "#Multi-class logistic regression\n",
    "We develop a multi-class logistic regression model (softmax regression) to classify flowers from the Iris dataset into three species — setosa, versicolor, and virginica. Our approach covers the entire process, from data loading and feature selection to mathematical formulation, training, visualization of decision boundaries, and performance evaluation, all implemented from scratch using NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SExNRL8KPnkv"
   },
   "source": [
    "Now we start by loading the Iris dataset using Scikit-learn’s built-in load_iris() function. From the full set of four features, we select only petal length and petal width, as these two provide the clearest separation between the species. The selected features are standardized for consistent scaling across dimensions, and a bias term (a column of ones) is added to the data matrix to account for the intercept in the linear model. To visualize the dataset, we plot the standardized features in a scatter plot, where each class is shown in a different color, clearly illustrating how the three flower types are distributed in feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "Ik7JKRUCyOZ9",
    "outputId": "03e1a664-0c17-4b15-86b1-455ecce883f2"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Select two features (petal length and petal width)\n",
    "feature_indices = [2, 3]\n",
    "X = X[:, feature_indices]\n",
    "\n",
    "# Standardize selected features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Add bias term (column of ones)\n",
    "X_bias = np.hstack((X_scaled, np.ones((X_scaled.shape[0], 1))))\n",
    "\n",
    "# Plot standardized features by class\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['red', 'blue', 'green']\n",
    "labels = data.target_names\n",
    "\n",
    "for i in range(len(colors)):\n",
    "    plt.scatter(X_scaled[y == i, 0], X_scaled[y == i, 1], color=colors[i], label=labels[i])\n",
    "\n",
    "plt.xlabel('Petal Length (standardized)')\n",
    "plt.ylabel('Petal Width (standardized)')\n",
    "plt.title('Iris Dataset (Two Features)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7chgTFjJySBx"
   },
   "source": [
    "Let us define softmax and GD as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOWmF9hZLiXt",
    "outputId": "547a7937-3469-4c4b-dd7c-dc9de2c5a2bc"
   },
   "outputs": [],
   "source": [
    "# Softmax activation function\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "# Compute cross-entropy loss for multi-class classification\n",
    "def compute_loss_multiclass(w, X, y):\n",
    "    z = X @ w\n",
    "    predictions = softmax(z)\n",
    "\n",
    "    n_samples, n_classes = predictions.shape\n",
    "    # One-hot encode labels\n",
    "    y_onehot = np.zeros((n_samples, n_classes))\n",
    "    y_onehot[np.arange(n_samples), y] = 1\n",
    "\n",
    "    # Add small epsilon for numerical stability\n",
    "    epsilon = 1e-15\n",
    "    loss = -np.mean(np.sum(y_onehot * np.log(predictions + epsilon), axis=1))\n",
    "    return loss\n",
    "\n",
    "# Compute gradient of multi-class loss weights\n",
    "def compute_gradient_multiclass(w, X, y):\n",
    "    z = X @ w\n",
    "    predictions = softmax(z)\n",
    "    n_samples, n_classes = predictions.shape\n",
    "    y_onehot = np.zeros((n_samples, n_classes))\n",
    "    y_onehot[np.arange(n_samples), y] = 1\n",
    "    errors = predictions - y_onehot\n",
    "    gradient = X.T @ errors / len(y)\n",
    "    return gradient\n",
    "\n",
    "# Compute accuracy for multi-class classification\n",
    "def multiclass_accuracy(w, X, y):\n",
    "    probabilities = softmax(X @ w)\n",
    "    predictions = np.argmax(probabilities, axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "    return accuracy\n",
    "\n",
    "# Gradient descent for multi-class logistic regression (softmax regression)\n",
    "def gradient_descent_multiclass(X, y, learning_rate=0.1, n_steps=10000, tolerance=1e-6):\n",
    "    n_features = X.shape[1]\n",
    "    n_classes = np.max(y) + 1\n",
    "\n",
    "    # Initialize weights\n",
    "    w = np.zeros((n_features, n_classes))\n",
    "    loss_history = [compute_loss_multiclass(w, X, y)]\n",
    "    weights_history = [w.copy()]\n",
    "\n",
    "    # Training loop\n",
    "    for step in range(1, n_steps + 1):\n",
    "        grad = compute_gradient_multiclass(w, X, y)\n",
    "        w -= learning_rate * grad  # Update weights\n",
    "        loss = compute_loss_multiclass(w, X, y)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        # Save weights periodically\n",
    "        if step % 10 == 0:\n",
    "            weights_history.append(w.copy())\n",
    "\n",
    "        # Stop if loss change is below tolerance\n",
    "        if np.abs(loss_history[-2] - loss_history[-1]) < tolerance:\n",
    "            print(f'Converged at step {step}')\n",
    "            break\n",
    "\n",
    "        # Print progress every 1000 steps\n",
    "        if step % 1000 == 0:\n",
    "            acc = multiclass_accuracy(w, X, y)\n",
    "            print(f'Step {step}: Loss = {loss:.4f}, Training Accuracy = {acc:.4f}')\n",
    "\n",
    "    return w, loss_history, weights_history\n",
    "\n",
    "# Train model and evaluate\n",
    "w, loss_history, weights_history = gradient_descent_multiclass(X_bias, y)\n",
    "\n",
    "# Final accuracy on training data\n",
    "final_accuracy = multiclass_accuracy(w, X_bias, y)\n",
    "print(f'\\nFinal Training Accuracy: {final_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOdH8ZBMP2RQ"
   },
   "source": [
    "We visualize the decision boundaries produced by the trained softmax regression model. Using a dense grid of feature values, we apply the model to predict the most probable class for each point, creating a color-coded map that shows which regions of the feature space correspond to each flower species. On top of this map, we plot the actual data points, helping us see how well the learned boundaries separate the three classes. We also visualize the loss history over training iterations, which typically shows a smooth downward trend as the model converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zTw_8xvOP0OK",
    "outputId": "32891bb8-28bb-46fd-afc9-477219bc3cb4"
   },
   "outputs": [],
   "source": [
    "# Plot decision boundaries for multi-class softmax regression\n",
    "def plot_decision_boundaries_multiclass(X, y, w, target_names):\n",
    "    # Define grid limits\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "    X_grid = np.c_[xx.ravel(), yy.ravel(), np.ones(xx.ravel().shape[0])]\n",
    "    Z = np.argmax(softmax(X_grid @ w), axis=1)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot decision regions\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Plot data points\n",
    "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "\n",
    "    # Create legend with class labels\n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], marker='o', color='w', label=target_names[i],\n",
    "                   markerfacecolor=scatter.to_rgba(i), markersize=10)\n",
    "        for i in range(len(target_names))\n",
    "    ]\n",
    "\n",
    "    plt.xlabel('Petal Length (standardized)')\n",
    "    plt.ylabel('Petal Width (standardized)')\n",
    "    plt.title('Softmax Regression Decision Boundaries')\n",
    "    plt.legend(handles=legend_elements, title=\"Classes\")\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundaries_multiclass(X_scaled, y, w, data.target_names)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss_history, label='Loss')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss (Categorical Cross-Entropy)')\n",
    "plt.title('Loss History')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAelurvlQDTT"
   },
   "source": [
    "Finally, we evaluate the model’s performance more formally using a confusion matrix. By comparing predicted labels against true labels, we visualize which classes are being correctly identified and where the model makes mistakes. The matrix is displayed as a heatmap, with each axis labeled by the flower species, allowing us to easily assess strengths and weaknesses in the classifier’s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "LI_Apjn0sRFY",
    "outputId": "b2b45123-b670-4444-a4a9-59939dbae777"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix for multi-class softmax regression\n",
    "def plot_confusion_matrix_multiclass(w, X, y, target_names):\n",
    "    # Compute class probabilities and predictions\n",
    "    probabilities = softmax(X @ w)\n",
    "    predictions = np.argmax(probabilities, axis=1)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_names,\n",
    "                yticklabels=target_names)\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Softmax Regression Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix_multiclass(w, X_bias, y, data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rK2ukkrQtTGh"
   },
   "source": [
    "#Real-World Example: Pima Indians Diabetes\n",
    "In this section, we apply logistic regression with gradient descent to the Pima Indians Diabetes dataset, aiming to predict whether a person has diabetes based on diagnostic measurements. The workflow includes dataset loading, preprocessing, training, evaluation, and visualization of model performance metrics, all built upon a custom logistic regression implementation rather than Scikit-learn’s built-in estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K162e2lvQ96z"
   },
   "source": [
    "We begin by attempting to load the Pima Indians Diabetes dataset from OpenML. This dataset contains eight medical features — such as glucose level, BMI, and age — along with a binary target indicating diabetes presence. To ensure compatibility, we check whether the target labels are stored as strings and, if so, map them to numeric values (0 and 1). <br> In case of a loading or conversion error, we fall back to a randomly generated placeholder dataset for demonstration purposes. After loading, we print the dataset’s shape and feature names to confirm successful setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xF465U-isX6r",
    "outputId": "de75992a-9075-428e-d4b1-ce6c8e17ad80"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "try:\n",
    "    # Load the Pima Indians Diabetes dataset from OpenML\n",
    "    diabetes_data = fetch_openml(name='pima-indians-diabetes', version=1, as_frame=False)\n",
    "    X_new = diabetes_data.data\n",
    "    y_new = diabetes_data.target\n",
    "\n",
    "    # Convert string labels to binary (0/1) if necessary\n",
    "    if y_new.dtype == object or y_new.dtype.kind == 'U':\n",
    "        unique_labels = np.unique(y_new)\n",
    "        if len(unique_labels) == 2:\n",
    "            label_map = {unique_labels[0]: 0, unique_labels[1]: 1}\n",
    "            y_new = np.array([label_map[label] for label in y_new])\n",
    "        else:\n",
    "            raise ValueError(\"Labels are not clearly binary or mapping failed.\")\n",
    "\n",
    "# Handle data loading or conversion errors\n",
    "except Exception as e:\n",
    "    print(f\"Error encountered: {e}. Using a placeholder random dataset for demonstration.\")\n",
    "    X_new = np.random.rand(500, 8)\n",
    "    y_new = np.random.randint(0, 2, 500)\n",
    "\n",
    "print(f\"Dataset shape: X={X_new.shape}, y={y_new.shape}\")\n",
    "print(f\"Feature Names: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rvq7-XJiRGi5"
   },
   "source": [
    "Next, we explore the data visually by plotting glucose level against BMI, coloring the points by diabetes status. This scatter plot provides an intuitive first look at how these two features relate to the outcome. Individuals with higher glucose and BMI values often cluster in the diabetic group, while those with lower values tend to belong to the non-diabetic group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "rzlWFRsRvAnv",
    "outputId": "1a8d4853-f009-438d-c974-76dae37f0736"
   },
   "outputs": [],
   "source": [
    "# Scatter plot of Glucose vs BMI colored by diabetes status\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_new[y_new == 0, 1], X_new[y_new == 0, 5], color='blue', alpha=0.6, label='No Diabetes (0)')\n",
    "plt.scatter(X_new[y_new == 1, 1], X_new[y_new == 1, 5], color='red', alpha=0.6, label='Diabetes (1)')\n",
    "plt.xlabel('Glucose Level')\n",
    "plt.ylabel('BMI')\n",
    "plt.title('Initial Data Distribution (Glucose vs. BMI)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgMR8VeARNk5"
   },
   "source": [
    "Now we should handle data preprocessing and model training setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-OsBcPGubZd",
    "outputId": "12cc9350-f5f9-4675-dc50-4fa902a0c0f7"
   },
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler_new = StandardScaler()\n",
    "X_new = scaler_new.fit_transform(X_new)\n",
    "\n",
    "# Add bias term (column of ones)\n",
    "X_new_bias = np.hstack((X_new, np.ones((X_new.shape[0], 1))))\n",
    "\n",
    "# Split dataset into training and validation sets (75/25)\n",
    "X_train_new, X_val_new, y_train_new, y_val_new = train_test_split(\n",
    "    X_new_bias, y_new, test_size=0.25, random_state=42, stratify=y_new\n",
    ")\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate_new = 0.01\n",
    "n_steps_new = 3000\n",
    "lambda_reg_new = 0.1  # Regularization term (not used yet)\n",
    "\n",
    "# Train logistic regression model using gradient descent\n",
    "w_opt_new, loss_history_new, val_accuracy_history_new, weights_history_new = gradient_descent_logistic(\n",
    "    X_train_new, y_train_new, X_val_new, y_val_new,\n",
    "    learning_rate=learning_rate_new,\n",
    "    n_steps=n_steps_new,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvtL411PS2A2"
   },
   "source": [
    "Once training concludes, we evaluate the model’s performance on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ry5q5EnQud_L",
    "outputId": "4641f7c3-e1c7-436b-b525-0e5552181844"
   },
   "outputs": [],
   "source": [
    "# Compute predicted probabilities and class predictions on validation set\n",
    "final_probabilities_new = sigmoid(X_val_new @ w_opt_new)\n",
    "final_predictions_new = (final_probabilities_new > 0.5).astype(int)\n",
    "\n",
    "# Create confusion matrix and extract values\n",
    "cm_new = confusion_matrix(y_val_new, final_predictions_new)\n",
    "TN, FP, FN, TP = cm_new.ravel()\n",
    "\n",
    "# Calculate performance metrics\n",
    "final_accuracy_new = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision_new = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall_new = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1_score_new = 2 * (precision_new * recall_new) / (precision_new + recall_new) if (precision_new + recall_new) > 0 else 0\n",
    "\n",
    "print(\"Final Evaluation on Validation Set:\")\n",
    "print(f\"Optimized weights: {w_opt_new}\")\n",
    "print(f\"Final Accuracy: {final_accuracy_new:.4f}\")\n",
    "print(f\"Precision: {precision_new:.4f}\")\n",
    "print(f\"Recall: {recall_new:.4f}\")\n",
    "print(f\"F1 Score: {f1_score_new:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIHBJd-8TIHs"
   },
   "source": [
    "We then define visualization functions to analyze training dynamics and diagnostic performance.<br> The **plot_roc_auc** function generates a Receiver Operating Characteristic (ROC) curve, showing the trade-off between sensitivity and specificity across thresholds, and computes the Area Under the Curve (AUC) as a summary performance metric.<br> The **plot_training_loss** function charts the model’s loss over training iterations, helping us verify convergence, while **plot_validation_accuracy** illustrates how the validation accuracy evolves as learning progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7f7468b0"
   },
   "outputs": [],
   "source": [
    "# Plot ROC curve and compute AUC for binary classification\n",
    "def plot_roc_auc(w, X_val, y_val):\n",
    "    probabilities = sigmoid(X_val @ w)\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, probabilities)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Display AUC result\n",
    "    print(\"\\nROC Curve Analysis\")\n",
    "    print(f\"Area Under the Curve (AUC): {roc_auc:.4f}\")\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "             label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--',\n",
    "             label='Random Classifier (AUC = 0.5)')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity/Recall)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot training loss over iterations\n",
    "def plot_training_loss(loss_history):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(loss_history, label='Training Loss')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss (Binary Cross-Entropy)')\n",
    "    plt.title('Training Loss History')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot validation accuracy trend\n",
    "def plot_validation_accuracy(val_accuracy_history):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(val_accuracy_history, label='Validation Accuracy', color='green')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy History')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM7egVjkTc3G"
   },
   "source": [
    "Finally, we display a heatmap of the **confusion matrix** to visualize classification outcomes in a more interpretable form. The **ROC curve, training loss, and accuracy** trends are plotted to provide a comprehensive view of model behavior. To conclude the analysis, we print a classification report generated by Scikit-learn, which consolidates **precision, recall, F1-score, and overall accuracy**. Together, these results present a full diagnostic summary of the logistic regression model’s performance on the diabetes prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yY85lQE-ujID",
    "outputId": "110f2f0b-03ee-4ca8-f0d8-7a88482d35a9"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix for diabetes dataset\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_new, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Predicted 0 (No Diab)', 'Predicted 1 (Diab)'],\n",
    "            yticklabels=['Actual 0 (No Diab)', 'Actual 1 (Diab)'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix (Diabetes Dataset)')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_auc(w_opt_new, X_val_new, y_val_new)\n",
    "\n",
    "# Plot loss and accuracy histories\n",
    "plot_training_loss(loss_history_new)\n",
    "plot_validation_accuracy(val_accuracy_history_new)\n",
    "\n",
    "print(\"\\nComprehensive Classification Report (Scikit-learn):\")\n",
    "print(classification_report(y_val_new, final_predictions_new, target_names=['No Diabetes', 'Diabetes']))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
