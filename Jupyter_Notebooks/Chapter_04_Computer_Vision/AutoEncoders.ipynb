{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font>\n",
    "<!-- <img src=\"https://sina.sharif.edu/~m_salehi/images/logo_sharif.png\" alt=\"SUT logo\" width=300 height=300 align=left class=\"saturate\"> -->\n",
    "<div dir=ltr align=center>\n",
    "<img src=\"https://sina.sharif.edu/~m_salehi/images/logo_sharif.png\" width=160 height=180>\n",
    "<br>\n",
    "<font color=0F5298 size=6>\n",
    "Introduction to Machine Learning <br>\n",
    "<font color= 6C3BAA size=6>\n",
    "AutoEncoders <br>\n",
    "<font color=696880 size=5>\n",
    "<!-- <br> -->\n",
    "Computer Engineering Department\n",
    "<br>\n",
    "Sharif University of Technology\n",
    "\n",
    "<font color=696880 size=5>\n",
    "<br>\n",
    "CE 40477 - Fall 2025\n",
    "\n",
    "<font color=GREEN size=5>\n",
    "<br>\n",
    "Zahra Rahmani & Farzan Rahmani\n",
    "<!-- <br> -->\n",
    "\n",
    "____\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ecaqr9YkWpbL"
   },
   "source": [
    "# Table of Contents\n",
    "1. [Libraries and Imports](#Libraries-and-Imports)\n",
    "2. [Visualization Functions](#Visualization-Functions)\n",
    "3. [MNIST Dataset](#MNIST-Dataset)\n",
    "4. [Neural Network](#Neural-Network)\n",
    "</br>\n",
    "    4-1. [NN Helper Functions](#NN-Helper-Functions)\n",
    "\n",
    "5. [AutoEncoder](#AutoEncoder)\n",
    "</br>\n",
    "    5-1. [AutoEncoder helper functions](#AutoEncoder-helper-functions)</br>\n",
    "    5-2. [Latent Variable Space](#Latent-Variable-Space) </br>\n",
    "    5-3. [Denoising](#Denoising)</br>\n",
    "8. [Denoising AutoEncoder](#Denoising-AutoEncoder)\n",
    "\n",
    "\n",
    "## Notebook Objectives\n",
    "\n",
    "\n",
    "In this notebook, we begin by taking a deeper look at what neural networks learn. Next, we investigate AutoEncoders and their applications, and finally, we explore Denoising AutoEncoders.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "PqFOwWLZVPI0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import trange\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "yL8xbaQB6e5d"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    if 'train_acc' in history:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        ax1.plot(history['train_loss'], label='train')\n",
    "        ax1.plot(history['test_loss'], label='test')\n",
    "        ax1.set_xlabel('Epochs')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax2.plot(history['train_acc'], label='train')\n",
    "        ax2.plot(history['test_acc'], label='test')\n",
    "        ax2.set_xlabel('Epochs')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.legend()\n",
    "    else:\n",
    "        plt.plot(history['train_loss'], label='train')\n",
    "        plt.plot(history['test_loss'], label='test')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_conf_mat(model, dataloader, device=device):\n",
    "    total, correct = 0, 0\n",
    "    conf_mat = torch.zeros((10, 10))\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            total += pred.shape[0]\n",
    "            pred = torch.argmax(pred, axis=1)\n",
    "            correct += sum(pred == y).item()\n",
    "            for j in range(pred.shape[0]):\n",
    "                conf_mat[y[j], pred[j].item()] += 1\n",
    "    # calculate the normalized confusion matrix\n",
    "    norm_conf_mat = conf_mat / torch.sum(conf_mat, axis=1)\n",
    "    # plot the matrix\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(norm_conf_mat)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Labels')\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks(range(10))\n",
    "    plt.colorbar()\n",
    "    # put number of each cell in plot\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            c = conf_mat[j, i]\n",
    "            color = 'black' if c > 500 else 'white'\n",
    "            ax.text(i, j, str(int(c)), va='center', ha='center', color=color)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize(embedded, labels, title=''):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "    # get discrete colormap\n",
    "    cmap = plt.get_cmap('jet', 10) # virdis\n",
    "\n",
    "    # plot scatter points\n",
    "    scatter = ax.scatter(embedded[:, 0], embedded[:, 1], c=labels, cmap=cmap)\n",
    "\n",
    "    # add colorbar\n",
    "    cbar = plt.colorbar(scatter)\n",
    "\n",
    "    # set ticks locations\n",
    "    cbar.set_ticks((np.arange(10) + 0.5) * (10 - 1) / 10)\n",
    "\n",
    "    # set tick labels\n",
    "    cbar.set_ticklabels([str(i) for i in range(10)])\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_last_hidden_layer(model, dataloader, method='PCA'):\n",
    "    with torch.no_grad():\n",
    "        encoded_data, labels = [], []\n",
    "        for imgs, lbls in dataloader:\n",
    "            encoded = model.last_hidden_layer(imgs.to(device))\n",
    "            encoded_data.append(encoded.cpu().numpy())\n",
    "            labels.append(lbls.cpu().numpy())\n",
    "\n",
    "    # Concatenate the encoded representations and labels\n",
    "    encoded_data = np.concatenate(encoded_data, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    if method == 'PCA':\n",
    "        embedded = PCA(n_components=2).fit_transform(encoded_data)\n",
    "        title = 'Reduction of the Last Hidden Layer using PCA'\n",
    "    else:\n",
    "        embedded = TSNE(n_components=2, learning_rate='auto', init='random',\n",
    "                        perplexity=3).fit_transform(encoded_data)\n",
    "        title = 'Reduction of the Last Hidden Layer using t-SNE'\n",
    "\n",
    "    visualize(embedded, labels, title)\n",
    "\n",
    "\n",
    "def plot_autoencoder(model, dataloader, method='PCA', denoising=False):\n",
    "    with torch.no_grad():\n",
    "        encoded_data, labels = [], []\n",
    "        for imgs, lbls in dataloader:\n",
    "            encoded = model.encoder(imgs.to(device))\n",
    "            if denoising:\n",
    "                encoded = encoded.view(encoded.size(0), -1)\n",
    "            encoded_data.append(encoded.cpu().numpy())\n",
    "            labels.append(lbls.cpu().numpy())\n",
    "\n",
    "    # Concatenate the encoded representations and labels\n",
    "    encoded_data = np.concatenate(encoded_data, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    if encoded_data.shape[1] == 2:\n",
    "        embedded = encoded_data\n",
    "        title = 'Latent Space'\n",
    "    elif method == 'PCA':\n",
    "        embedded = PCA(n_components=2).fit_transform(encoded_data)\n",
    "        title = 'Reduction of the Latent Space using PCA'\n",
    "    else:\n",
    "        embedded = TSNE(n_components=2, learning_rate='auto', init='random',\n",
    "                        perplexity=3).fit_transform(encoded_data)\n",
    "        title = 'Reduction of the Latent Space using t-SNE'\n",
    "\n",
    "    visualize(embedded, labels, title)\n",
    "\n",
    "\n",
    "\n",
    "def plot_reconstruction(model, dataset, denoising=False, mask=False):\n",
    "    # Choose 10 random samples\n",
    "    random_indices = np.random.choice(len(dataset), size=10, replace=False)\n",
    "\n",
    "    # Get images and labels for the chosen samples\n",
    "    images = [dataset[i][0] for i in random_indices]\n",
    "    labels = [dataset[i][1] for i in random_indices]\n",
    "\n",
    "    is_grayscale = images[0].shape[0]==1\n",
    "    cmap = 'gray' if is_grayscale else None\n",
    "\n",
    "    if denoising:\n",
    "        noisy_images = [add_noise(image, mask=mask) for image in images]\n",
    "\n",
    "    # Reconstruct the images using the autoencoder\n",
    "    with torch.no_grad():\n",
    "        if denoising:\n",
    "            reconstructed_images = [model(noisy_image.unsqueeze(0).to(device)).squeeze().cpu() for noisy_image in noisy_images]\n",
    "        else:\n",
    "            reconstructed_images = [model(image.unsqueeze(0).to(device)).squeeze().cpu() for image in images]\n",
    "\n",
    "    if denoising:\n",
    "        # Display the original and reconstructed images\n",
    "        fig, axes = plt.subplots(3, 10, figsize=(15, 5))\n",
    "\n",
    "        # First row: Original images\n",
    "        for i, image in enumerate(images):\n",
    "            if is_grayscale:\n",
    "                axes[0, i].imshow(image.squeeze().numpy(), cmap=cmap)\n",
    "            else:\n",
    "                axes[0, i].imshow(image.permute(1,2,0).numpy(), cmap=cmap)\n",
    "            axes[0, i].set_title(f\"Original {classes[labels[i]]}\")\n",
    "            axes[0, i].axis('off')\n",
    "\n",
    "        # Second row: Noisy images\n",
    "        for i, image in enumerate(noisy_images):\n",
    "            if is_grayscale:\n",
    "                axes[1, i].imshow(image.squeeze().numpy(), cmap=cmap)\n",
    "            else:\n",
    "\n",
    "                axes[1, i].imshow(image.permute(1,2,0).numpy(), cmap=cmap)\n",
    "            axes[1, i].set_title(f\"Noisy {classes[labels[i]]}\")\n",
    "            axes[1, i].axis('off')\n",
    "\n",
    "        # Third row: Reconstructed images\n",
    "        for i, image in enumerate(reconstructed_images):\n",
    "            if is_grayscale:\n",
    "                axes[2, i].imshow(image.squeeze().numpy().reshape(28, 28), cmap=cmap)\n",
    "            else:\n",
    "                axes[2, i].imshow(image.permute(1,2,0).numpy(), cmap=cmap)\n",
    "            axes[2, i].set_title(f\"Reconstructed\")\n",
    "            axes[2, i].axis('off')\n",
    "\n",
    "    else:\n",
    "        # Display the original and reconstructed images\n",
    "        fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "\n",
    "        # First row: Original images\n",
    "        for i, image in enumerate(images):\n",
    "            if is_grayscale:\n",
    "                axes[0, i].imshow(image.squeeze().numpy(), cmap=cmap)\n",
    "            else:\n",
    "                axes[0, i].imshow(image.permute(1,2,0).numpy(), cmap=cmap)\n",
    "            axes[0, i].set_title(f\"Label: {classes[labels[i]]}\")\n",
    "            axes[0, i].axis('off')\n",
    "\n",
    "        # Second row: Reconstructed images\n",
    "        for i, image in enumerate(reconstructed_images):\n",
    "            if is_grayscale:\n",
    "                axes[1, i].imshow(image.detach().numpy().reshape(28, 28), cmap=cmap)\n",
    "            else:\n",
    "                axes[1, i].imshow(image.detach().numpy(), cmap=cmap)\n",
    "            axes[1, i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "WZKY38A-0-f3"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "trainset = MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvFUeXMNadnZ"
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KThKuK5DJHAH"
   },
   "source": [
    "First we will try to train a simple neural network. Our goal is to visualize datapoints from the last hidden layer of this network, so we create the `last_hidden_layer` function to access the output of this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HmznEXldEaI"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fe = nn.Sequential(nn.Linear(784, 256),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.Linear(256, 64),\n",
    "                                nn.ReLU(inplace=True))\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "\n",
    "    def last_hidden_layer(self, x):\n",
    "        x = torch.flatten(x, start_dim=1) / 255.\n",
    "        return self.fe(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.last_hidden_layer(x)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "iWv1183PVf5o"
   },
   "outputs": [],
   "source": [
    "def classifier_train_step(model, dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = model(images)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (logits.argmax(dim=1) == labels).sum().item()\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def classifier_test_step(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    test_acc = 0.\n",
    "    with torch.inference_mode():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = model(images)\n",
    "            loss = loss_fn(logits, labels)\n",
    "            test_loss += loss.item()\n",
    "            test_acc += (logits.argmax(dim=1) == labels).sum().item()\n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader.dataset)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "def train_classifier(model, train_dataloader, test_dataloader, n_epochs, device=device):\n",
    "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
    "    optimizer = Adam(model.parameters())\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    for _ in (pbar := trange(n_epochs)):\n",
    "        train_loss, train_acc = classifier_train_step(model, train_dataloader, loss_fn, optimizer, device)\n",
    "        history['train_loss'].append(train_loss), history['train_acc'].append(train_acc)\n",
    "        test_loss, test_acc = classifier_test_step(model, test_dataloader, loss_fn, device)\n",
    "        history['test_loss'].append(test_loss), history['test_acc'].append(test_acc)\n",
    "        pbar.set_description(f'Training Accuracy {100 * train_acc:.2f}% | Test Accuracy {100 * test_acc:.2f}% ')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "9YMl_fX-JHSK",
    "outputId": "d8052ba6-5c03-4757-a7ef-088ef49dcf5d"
   },
   "outputs": [],
   "source": [
    "net = Network().to(device)\n",
    "\n",
    "results = train_classifier(net, trainloader, testloader, n_epochs=30)\n",
    "plot_history(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eB1SjTeaJztY"
   },
   "source": [
    "To get a better sense of our training, we plot the confusion matrix for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "pF0DKJV_JRnh",
    "outputId": "45d58bd5-dbd7-4a6f-de8a-6a857a2959c6"
   },
   "outputs": [],
   "source": [
    "plot_conf_mat(net, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08aibrACJ_kr"
   },
   "source": [
    "If we pass all the images from the test dataset to network and obtain the output of the last hidden layer (the input of the final layer) and perform PCA on it here is what we see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "dHaTiE10HART",
    "outputId": "0d09e6b7-aab5-475b-c3da-38a4658a44c0"
   },
   "outputs": [],
   "source": [
    "plot_last_hidden_layer(net, testloader, method='PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsuMui_fLCWf"
   },
   "source": [
    "If we pass all the images from the test dataset to network and obtain the output of the last hidden layer (the input of the final layer) and perform t-SNE on it here is what we see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "cxGzqMybEGt-",
    "outputId": "719933a4-5897-4af2-8c91-7c439ae35cf8"
   },
   "outputs": [],
   "source": [
    "plot_last_hidden_layer(net, testloader, method='t-SNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaQZUpp1coQ1"
   },
   "source": [
    "Keep in mind in order to have high accuracy, the last hidden layer must make datapoints from different classees linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiX1y0vdv25O"
   },
   "source": [
    "# AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NxMU8NZbWr0"
   },
   "source": [
    "In this section we first create an AutoEncoder. An AutoEncoder has two networks, the encoder network which reduces the dimensionality of the data into its latent space representation, and the decoder network which increases the dimensionality and reconstructs the input from the latent space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGjDnQtpbWr0"
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # The Encoder Network\n",
    "        self.encoder = nn.Sequential(nn.Flatten(),\n",
    "                                     nn.Linear(28 * 28, 256),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     nn.Linear(256, 64),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     nn.Linear(64, 16),)\n",
    "        # The Decoder Network\n",
    "        self.decoder = nn.Sequential(nn.Linear(16, 64),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     nn.Linear(64, 256),\n",
    "                                     nn.ReLU(inplace=True),\n",
    "                                     nn.Linear(256, 28 * 28),\n",
    "                                     nn.Unflatten(1, (1, 28, 28)),\n",
    "                                     nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.decoder(self.encoder(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "x6Jzh-e1GHe3"
   },
   "outputs": [],
   "source": [
    "def mask_image(x, square_size=5, number_of_squares=3):\n",
    "    masked = x.clone()\n",
    "    for _ in range(number_of_squares):\n",
    "        start_i = torch.randint(0, x.shape[-2]-square_size, (1, ))\n",
    "        start_j = torch.randint(0, x.shape[-1]-square_size, (1, ))\n",
    "        masked[..., start_i:start_i+square_size, start_j:start_j+square_size]=0\n",
    "    return masked\n",
    "\n",
    "def add_noise(x, mask= False):\n",
    "    if mask:\n",
    "        return mask_image(x)\n",
    "\n",
    "    select_mode = np.random.uniform()\n",
    "\n",
    "    if select_mode <= 1/6: # gaussian noise\n",
    "        noisy = x + torch.randn_like(x) * 0.5\n",
    "\n",
    "    elif select_mode <= 2/6: # salt and pepper noise\n",
    "        noise = torch.rand_like(x)\n",
    "        noisy = x.clone()\n",
    "        noisy[noise < 0.1] = 0\n",
    "        noisy[noise > 0.9] = 1\n",
    "\n",
    "    elif select_mode <= 3/6: # speckle noise\n",
    "        noisy = x + x*torch.randn_like(x)\n",
    "\n",
    "    elif select_mode <= 4/6: # poisson\n",
    "        noisy = torch.poisson(x * 2)/2\n",
    "\n",
    "    elif select_mode <= 5/6: # square masking\n",
    "        noisy = mask_image(x, square_size=4, number_of_squares=4)\n",
    "\n",
    "    else: # bluring\n",
    "        noisy = transforms.GaussianBlur(5, sigma=(2,2))(x)\n",
    "\n",
    "    noisy[noisy < 0] = 0\n",
    "    noisy[noisy > 1] = 1\n",
    "    return noisy\n",
    "\n",
    "def autoencoder_train_step(model, dataloader, loss_fn, optimizer, denoising, mask, device):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    for images, _ in dataloader:\n",
    "        images = images.to(device)\n",
    "        if denoising: # Add noise to the images\n",
    "            noisy_images = add_noise(images, mask= mask)\n",
    "            recons = model(noisy_images)\n",
    "        else:\n",
    "            recons = model(images)\n",
    "        loss = loss_fn(recons, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def autoencoder_test_step(model, dataloader, loss_fn, denoising, mask, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    with torch.inference_mode():\n",
    "        for images, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            if denoising: # Add noise to the images\n",
    "                noisy_images = add_noise(images, mask=mask)\n",
    "                recons = model(noisy_images)\n",
    "            else:\n",
    "                recons = model(images)\n",
    "            loss = loss_fn(recons, images)\n",
    "            test_loss += loss.item()\n",
    "        test_loss /= len(dataloader)\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def train_autoencoder(model, train_dataloader, test_dataloader, n_epochs, denoising=False, mask=False, device=device):\n",
    "    history = {'train_loss': [], 'test_loss': []}\n",
    "    optimizer = Adam(model.parameters())\n",
    "    loss_fn = nn.MSELoss()\n",
    "    for _ in (pbar := trange(n_epochs)):\n",
    "        train_loss = autoencoder_train_step(model, train_dataloader, loss_fn, optimizer, denoising, mask, device)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        test_loss = autoencoder_test_step(model, test_dataloader, loss_fn, denoising, mask, device)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        pbar.set_description(f'Training Loss {train_loss:.3f} | Test Loss {test_loss:.3f} ')\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fv7UEn8gbWr1"
   },
   "source": [
    "Using the Mean Squared Error loss we can train the AutoEncoder to reconstruct images after encoding them using the encoder network and decoding the encoded representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "z7YLo9TsbWr1",
    "outputId": "64999cee-89d0-4f6a-c109-74ca919d1e93"
   },
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder().to(device)\n",
    "\n",
    "res = train_autoencoder(autoencoder, trainloader, testloader, n_epochs=30)\n",
    "plot_history(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5usAfmwpM4XO"
   },
   "source": [
    "We can reconstruct images from the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "DCkmwmUC9P4k",
    "outputId": "ba17fe22-ef36-4056-9a26-9e97798d6a86"
   },
   "outputs": [],
   "source": [
    "plot_reconstruction(autoencoder, trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lq22gUXxM-HN"
   },
   "source": [
    "Or we can reconstruct images from the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "D4Phh3J6CUrQ",
    "outputId": "cbd251db-f9a2-494f-d7ff-0f9ed19f77c1"
   },
   "outputs": [],
   "source": [
    "plot_reconstruction(autoencoder, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hiT_REKUvGh"
   },
   "source": [
    "## Latent Variable Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72-4v_PmbdCb"
   },
   "source": [
    "While it would have been possible to encode the inputs into a two dimensional latent space, the reconstruction loss would not have been so easy to reduce. Therefore we can use PCA to reduce the latent space dimensions to two for visualization purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "kLKpD0AD1rJo",
    "outputId": "d4a4ad76-c73d-4c81-f66c-5da1ab8e7986"
   },
   "outputs": [],
   "source": [
    "plot_autoencoder(autoencoder, testloader, method='PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3soIt9Nb2zV"
   },
   "source": [
    "We can also use t-SNE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "KktJ0hN46DEH",
    "outputId": "bd7518f4-1060-402b-c3f0-fe2504a0e5cd"
   },
   "outputs": [],
   "source": [
    "plot_autoencoder(autoencoder, testloader, method='t-SNE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq3BaUprN61y"
   },
   "source": [
    "## Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TgC80BPN_GG"
   },
   "source": [
    "Another application of AutoEncoders is denoising. Even without training the AutoEncoder to denoise the inputs, we can see decent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "ISM2ZR3r1aFb",
    "outputId": "4d69518b-43e2-4f6e-c8fd-eab667c9f2ec"
   },
   "outputs": [],
   "source": [
    "plot_reconstruction(autoencoder, testset, denoising=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1niJiNybOfxL"
   },
   "source": [
    "# Denoising AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOtPcg2EOU-X"
   },
   "source": [
    "To make the model further robust to noises we can train an AutoEncoder with noisy data as input and the original data as desired output to obtain a model that removes the noise from data! These type of AutoEncoders are called Denoising AutoEncoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "okOZJG5AO_aW",
    "outputId": "cc6d9b05-dbfc-4989-895a-e01c41536e81"
   },
   "outputs": [],
   "source": [
    "dae = AutoEncoder().to(device)\n",
    "\n",
    "res = train_autoencoder(dae, trainloader, testloader, n_epochs=30, denoising=True)\n",
    "plot_history(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8H83VVQtTHnv"
   },
   "source": [
    "We can compare the output of the denoising autoencoder to the normal autoencoder and see how much it has improved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "BMQ_OLseS8ZQ",
    "outputId": "ba747ae2-9878-4592-a0a0-94d98aeb4e6a"
   },
   "outputs": [],
   "source": [
    "plot_reconstruction(dae, testset, denoising=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPRpquDPZSNV"
   },
   "source": [
    "We can further apply the concept of Denoising AutoEncoders to repair damaged images or predict missing parts of an image. For this purpose, we use CIFAR-10, a more general dataset, to train a model that predicts the masked parts of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "FxVCVyjApla9"
   },
   "outputs": [],
   "source": [
    "# @title CIFAR10 dataset\n",
    "batch_size = 256\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IcSqM9dcI1v"
   },
   "source": [
    "In Denoising AutoEncoders, the latent feature dimensions do not need to be smaller because the input and output are different. This prevents the model from simply learning the identity function without capturing meaningful features. As our data has become more complex, we require a more sophisticated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hooitw4zhV_b"
   },
   "outputs": [],
   "source": [
    "class DenoisingAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # The Encoder Network\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1),  # (32x32x3) -> (16x16x64)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1),  # (16x16x64) -> (8x8x128)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1),  # (8x8x128) -> (4x4x256)\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # The Decoder Network\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1),  # (4x4x256) -> (8x8x128)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1),  # (8x8x128) -> (16x16x64)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=3, stride=2, padding=1, output_padding=1),  # (16x16x64) -> (32x32x3)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.decoder(self.encoder(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3bkj05dfGK6"
   },
   "source": [
    "We then train our Denoising AutoEncoder using masked data. Specifically, random squares of each input image are set to zero, and we expect the model to predict the content behind these masks in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "jOQ5BF9Ka6PJ",
    "outputId": "76ab9351-66c5-4d2d-ab47-b4b0210da095"
   },
   "outputs": [],
   "source": [
    "dae = DenoisingAutoEncoder().to(device)\n",
    "\n",
    "res = train_autoencoder(dae, trainloader, testloader, n_epochs=30, denoising=True, mask=True)\n",
    "plot_history(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiOOU_BUePPx"
   },
   "source": [
    "By reconstructing the output of Denoising AutoEncoder we see how model predicts the masked parts of unseen images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "8vaN5ynoXvY-",
    "outputId": "73768860-9dd7-44fa-9b40-e59515a6ffd1"
   },
   "outputs": [],
   "source": [
    "plot_reconstruction(dae, testset, denoising=True, mask=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Ecaqr9YkWpbL"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
