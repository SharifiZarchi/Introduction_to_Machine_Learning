You should work your way through the notebooks in the following order:

# [1. Clustering](https://github.com/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Unsupervised_Learning/Clustering/Clustering.ipynb)
In this notebook we implement the K-Means algorithm from scratch and see how clustering can be applied to unlabeled datasets.

**Warning!** If you want to run this notebook online, make sure you run the following code to download the dataset:

```
!mkdir -p ./assets
!wget -O ./assets/housing.csv https://github.com/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Unsupervised_Learning/Clustering/assets/housing.csv
!wget -O ./assets/players_22.csv https://github.com/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Unsupervised_Learning/Clustering/assets/players_22.csv
!wget -O ./assets/Mall_Customers.csv https://github.com/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Unsupervised_Learning/Clustering/assets/Mall_Customers.csv
!wget -O ./assets/PNG_transparency_demonstration_1.png https://github.com/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Unsupervised_Learning/Clustering/assets/PNG_transparency_demonstration_1.png
```

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Unsupervised_Learning/Clustering/Clustering.ipynb)
[![Open In kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/SharifiZarchi/Introduction_to_Machine_Learning/main/Jupyter_Notebooks/Chapter_02_Unsupervised_Learning/Clustering.ipynb)


# [2. Dimensionality Reduction](https://github.com/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Unsupervised_Learning/DimensionalityReduction.ipynb)
In this notebook we go over different Dimensionality Reduction algorithms such as Principal Component Analysis (PCA), t-Distributed Stochastic Neighbor Embedding (t-SNE) and Uniform Manifold Approximation and Projection (UMAP).

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SharifiZarchi/Introduction_to_Machine_Learning/blob/main/Jupyter_Notebooks/Chapter_02_Unsupervised_Learning/DimensionalityReduction.ipynb)
[![Open In kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/SharifiZarchi/Introduction_to_Machine_Learning/main/Jupyter_Notebooks/Chapter_02_Unsupervised_Learning/DimensionalityReduction.ipynb)

